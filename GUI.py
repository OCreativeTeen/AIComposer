import matplotlib
matplotlib.use('Agg')  # Must be at the TOP of main.py

import tkinter as tk
import tkinter.ttk as ttk
import tkinter.scrolledtext as scrolledtext
import tkinter.filedialog as filedialog
import tkinter.messagebox as messagebox
import os
import threading
import time
from datetime import datetime
import pygame
import uuid
from magic_workflow import MagicWorkflow
import config
from PIL import Image, ImageTk
from pathlib import Path
from project_manager import ProjectConfigManager, create_project_dialog
from gui.picture_in_picture_dialog import PictureInPictureDialog
from gui.video_review_dialog import VideoReviewDialog
from gui.background_selector_dialog import BackgroundSelectorDialog
from gui.animation_selector_dialog import show_animation_selector
from gui.raw_scenarios_editor import RawScenariosEditor
import cv2
import os
from utility.file_util import get_file_path, is_image_file, is_audio_file, is_video_file, copy_file
from gui.media_review_dialog import AVReviewDialog
from gui.enhanced_media_editor import show_enhanced_media_editor
from utility.minimax_speech_service import MinimaxSpeechService, EXPRESSION_STYLES
from gui.raw_scenarios_editor import RawScenariosEditor
from gui.wan_prompt_editor_dialog import show_wan_prompt_editor  # æ·»åŠ è¿™ä¸€è¡Œ
from gui.image_prompts_review_dialog import IMAGE_PROMPT_OPTIONS, NEGATIVE_PROMPT_OPTIONS
import tkinterdnd2 as TkinterDnD
from tkinterdnd2 import DND_FILES

import cv2


from moviepy import VideoFileClip
import moviepy
mp = moviepy  # Create an alias for compatibility


def askchoice(title, choices):
    """
    è‡ªå®šä¹‰çš„å¤šé€‰æ‹©å¯¹è¯æ¡†å‡½æ•°
    è¿”å›ç”¨æˆ·é€‰æ‹©çš„é€‰é¡¹å­—ç¬¦ä¸²
    """
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„é€‰æ‹©å¯¹è¯æ¡†
    root = tk.Toplevel()
    root.title(title)
    root.geometry("300x200")
    root.resizable(False, False)
    
    # å±…ä¸­æ˜¾ç¤º
    root.transient()
    root.grab_set()
    
    result = None
    
    def on_choice(choice):
        nonlocal result
        result = choice
        root.destroy()
    
    # æ·»åŠ æ ‡é¢˜
    label = tk.Label(root, text=title, font=("Arial", 12, "bold"))
    label.pack(pady=10)
    
    # æ·»åŠ é€‰æ‹©æŒ‰é’®
    for choice in choices:
        btn = tk.Button(root, text=choice, width=20, 
                       command=lambda c=choice: on_choice(c))
        btn.pack(pady=5)
    
    # æ·»åŠ å–æ¶ˆæŒ‰é’®
    cancel_btn = tk.Button(root, text="å–æ¶ˆ", width=20, 
                          command=lambda: root.destroy())
    cancel_btn.pack(pady=10)
    
    # ç­‰å¾…ç”¨æˆ·é€‰æ‹©
    root.wait_window()
    return result

# askchoiceå‡½æ•°å®šä¹‰å®Œæˆï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨



class WorkflowGUI:
    # Standardized framerate to match video processing
    STANDARD_FPS = 60  # Match FfmpegProcessor.STANDARD_FPS

    def __init__(self, root):
        # å¦‚æœæ‹–æ‹½æ”¯æŒå¯ç”¨ï¼Œåˆ™ä½¿ç”¨TkinterDnDæ ¹çª—å£
        self.root = TkinterDnD.Tk() if not isinstance(root, TkinterDnD.Tk) else root
        # å¦‚æœä¼ å…¥çš„rootä¸æ˜¯TkinterDnD.Tkï¼Œéœ€è¦é‡æ–°åˆ›å»º
        if root != self.root:
            root.destroy()
            
        self.root.title("é­”æ³•å·¥ä½œæµ GUI")
        try:
            self.root.state('zoomed') # Windowså…¨å±
        except:
            screen_width = self.root.winfo_screenwidth()
            screen_height = self.root.winfo_screenheight()
            self.root.geometry(f"{screen_width}x{screen_height}+0+0")

        try:
            pygame.mixer.init()
            self.pygame_mixer_available = True
        except Exception as e:
            self.pygame_mixer_available = False
        
        self.playing_delta = 0.0
        self.second_delta = 0.0

        # åˆå§‹åŒ–é…ç½®åŠ è½½æ ‡å¿—
        self._loading_config = False
        self.current_project_config = None
        self.current_scenario_index = 0

        # æ˜¾ç¤ºé¡¹ç›®é€‰æ‹©å¯¹è¯æ¡†
        if not self.show_project_selection():
            self.root.destroy()
            return
        
        # é¦–å…ˆåˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€è·Ÿè¸ª - å¢å¼ºç‰ˆ
        self.tasks = {}
        self.completed_tasks = []  # å­˜å‚¨å·²å®Œæˆçš„ä»»åŠ¡
        self.last_notified_tasks = set()  # è·Ÿè¸ªå·²é€šçŸ¥çš„ä»»åŠ¡
        self.status_update_timer_id = None  # çŠ¶æ€æ›´æ–°å®šæ—¶å™¨ID
        self.monitoring_scenarios = {}  # è·Ÿè¸ªæ­£åœ¨ç›‘æ§çš„åœºæ™¯ {scenario_index: {"found_files": [], "start_time": time}}
        self.processed_output_files = set()  # è·Ÿè¸ªå·²å¤„ç†çš„ X:\output æ–‡ä»¶
        
        # å•ä¾‹åå°æ£€æŸ¥çº¿ç¨‹æ§åˆ¶
        self.video_check_thread = None  # åå°æ£€æŸ¥çº¿ç¨‹
        self.video_check_running = False  # çº¿ç¨‹è¿è¡Œæ ‡å¿—
        self.video_check_stop_event = threading.Event()  # åœæ­¢äº‹ä»¶
        
        # æ·»åŠ è§†é¢‘æ•ˆæœé€‰æ‹©å­˜å‚¨
        self.effect_radio_vars = {}  # {scenario_index: tk.StringVar}
        
        # æ·»åŠ å½“å‰æ•ˆæœå’Œå›¾åƒç±»å‹é€‰æ‹©å˜é‡
        self.current_effect_var = tk.StringVar(value=config.SPECIAL_EFFECTS[0])
        self.scenario_second_animation = tk.StringVar(value=config.ANIMATE_TYPES[0])
        
        # åˆ›å»ºåŠ¨ç”»åç§°åˆ°æç¤ºè¯­çš„æ˜ å°„å­—å…¸ï¼ˆåŒå‘ï¼‰
        self.animation_name_to_prompt = {item["name"]: item["prompt"] for item in config.ANIMATION_PROMPTS}
        self.animation_prompt_to_name = {item["prompt"]: item["name"] for item in config.ANIMATION_PROMPTS}
        self.animation_names = [""] + list(self.animation_name_to_prompt.keys())
        
        # æ·»åŠ ç¬¬äºŒè½¨é“éŸ³é‡æ§åˆ¶å˜é‡
        self.track_volume_var = tk.DoubleVar(value=0.2)
        
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # åˆ›å»ºå…±äº«ä¿¡æ¯åŒºåŸŸ
        self.create_shared_info_area(main_frame)
        
        # åˆ›å»ºæ ‡ç­¾é¡µæ§ä»¶
        self.notebook = ttk.Notebook(main_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True, pady=(10, 0))
        
        # åˆ›å»ºå„ä¸ªæ ‡ç­¾é¡µ
        self.create_video_tab()
        self.create_promo_video_tab()
        
        self.setup_drag_and_drop()
        
        # ç»‘å®šæ ‡ç­¾é¡µåˆ‡æ¢äº‹ä»¶
        self.notebook.bind("<<NotebookTabChanged>>", self.on_tab_changed)
        
        # å¯åŠ¨ä»»åŠ¡çŠ¶æ€æ›´æ–°å®šæ—¶å™¨
        self.start_status_update_timer()
        
        # åŠ è½½ä¸Šæ¬¡ä¿å­˜çš„é…ç½®ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰æ§ä»¶åˆ›å»ºå®Œæˆåï¼Œåœ¨ç»‘å®šäº‹ä»¶ä¹‹å‰ï¼‰
        self.load_config()
        self.bind_config_change_events()
        
        # ç«‹å³åˆ›å»ºå·¥ä½œæµå®ä¾‹ï¼ˆä¸å†ä½¿ç”¨æ‡’åŠ è½½ï¼‰
        self.create_workflow_instance()
        
        # å¯åŠ¨å•ä¾‹åå°è§†é¢‘æ£€æŸ¥çº¿ç¨‹
        self.start_video_check_thread()
        
        # ç»‘å®šçª—å£å…³é—­äº‹ä»¶
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)


    def get_pid(self):
        return self.shared_pid.cget('text').strip() or ''
    

    def create_workflow_instance(self):
        """ç«‹å³åˆ›å»ºå·¥ä½œæµå®ä¾‹ï¼ˆéæ‡’åŠ è½½ï¼‰"""
        try:
            pid = self.get_pid()
            language = self.shared_language.cget('text')
            channel = self.shared_channel.cget('text')
            story_site = self.story_site_entry.get().strip()
            keywords = self.project_keywords.get().strip()
            
            self.workflow = MagicWorkflow(pid, language, channel, story_site)
            self.speech_service = MinimaxSpeechService(pid)
            
            current_gui_title = self.video_title.get().strip()
            self.workflow.post_init(current_gui_title, keywords)

            self.on_tab_changed(None)
            
            print(f"âœ… å·¥ä½œæµå®ä¾‹åˆ›å»ºå®Œæˆ - PID: {pid}")
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå·¥ä½œæµå®ä¾‹å¤±è´¥: {e}")
            self.workflow = None


    def get_current_scenario(self):
        if not hasattr(self, 'workflow') or self.workflow is None or not hasattr(self.workflow, 'scenarios') or self.workflow.scenarios is None:
            return None
            
        if self.workflow.scenarios and self.current_scenario_index >= 0 and self.current_scenario_index < len(self.workflow.scenarios):
            return self.workflow.scenarios[self.current_scenario_index]
        else:
            return None
    

    def get_previous_scenario(self):
        if self.workflow.scenarios and self.current_scenario_index > 0 and self.current_scenario_index < len(self.workflow.scenarios):
            return self.workflow.scenarios[self.current_scenario_index - 1]
        else:
            return None    


    def get_next_scenario(self):
        if self.workflow.scenarios and self.current_scenario_index >= 0 and self.current_scenario_index < len(self.workflow.scenarios)-1:
            return self.workflow.scenarios[self.current_scenario_index + 1]
        else:
            return None


    def get_previous_story_last_scenario(self):
        if self.workflow.scenarios and self.current_scenario_index > 0 and self.current_scenario_index < len(self.workflow.scenarios):
            # loop from self.current_scenario_index to 0,  
            for i in range(self.current_scenario_index, 0, -1):
                if self.workflow.scenarios[i]["id"]%10000 != self.workflow.scenarios[self.current_scenario_index]["id"]%10000:
                    return self.workflow.scenarios[i]
        return None    

    
    def show_project_selection(self):
        # ä½¿ç”¨æ–°çš„é¡¹ç›®ç®¡ç†å™¨
        result, selected_config = create_project_dialog(self.root)
        
        if result == 'cancel':
            return False
        elif result == 'new':
            # ä½¿ç”¨ä»æ–°é¡¹ç›®å¯¹è¯æ¡†è·å–çš„é…ç½®
            self.current_project_config = selected_config
            
            # ç«‹å³åˆ›å»ºProjectConfigManagerå¹¶ä¿å­˜æ–°é¡¹ç›®é…ç½®
            pid = selected_config.get('pid')
            if pid:
                try:
                    config_manager = ProjectConfigManager(pid)
                    config_manager.project_config = selected_config.copy()
                    config_manager.save_project_config()
                    print(f"âœ… æ–°é¡¹ç›®é…ç½®å·²ä¿å­˜: {pid}")
                except Exception as e:
                    print(f"âŒ ä¿å­˜æ–°é¡¹ç›®é…ç½®å¤±è´¥: {e}")
            
            return True
        elif result == 'open':
            # æ‰“å¼€ç°æœ‰é¡¹ç›®
            self.current_project_config = selected_config
            return True
        
        return False

   
    def create_default_config(self):
        """åˆ›å»ºé»˜è®¤é…ç½®"""
        return {
            'pid': '',
            'language': 'tw',
            'channel': 'strange_zh',
            'video_title': 'é»˜è®¤æ ‡é¢˜',

            'program_keywords': '',
            'story_site': '',
            'video_width': str(config.VIDEO_WIDTH),
            'video_height': str(config.VIDEO_HEIGHT)
        }
        
    def create_shared_info_area(self, parent):
        """åˆ›å»ºå…±äº«ä¿¡æ¯åŒºåŸŸ"""
        shared_frame = ttk.LabelFrame(parent, text="å…±äº«é…ç½®", padding=10)
        shared_frame.pack(fill=tk.X, pady=(0, 10))
        
        # ç¬¬ä¸€è¡Œï¼šåŸºæœ¬é¡¹ç›®é…ç½®
        row1_frame = ttk.Frame(shared_frame)
        row1_frame.pack(fill=tk.X, pady=(0, 5))
        
        scenario_nav_row = ttk.Frame(row1_frame)
        scenario_nav_row.pack(side=tk.LEFT, padx=(0, 10))

        ttk.Label(scenario_nav_row, text="åœºæ™¯:").pack(side=tk.LEFT)
        ttk.Button(scenario_nav_row, text="â—€", width=3, command=self.prev_scenario).pack(side=tk.LEFT, padx=2)
        self.scenario_label = ttk.Label(scenario_nav_row, text="0 / 0", width=7)
        self.scenario_label.pack(side=tk.LEFT, padx=2)
        ttk.Button(scenario_nav_row, text="â–¶", width=3, command=self.next_scenario).pack(side=tk.LEFT, padx=2)
        
        # åˆ†éš”ç¬¦
        ttk.Separator(row1_frame, orient='vertical').pack(side=tk.LEFT, fill=tk.Y, padx=10)
        ttk.Button(row1_frame, text="æ‹·è´å›¾",   command=self.copy_images_to_next).pack(side=tk.LEFT, padx=2)
        ttk.Button(row1_frame, text="åœºæ™¯äº¤æ¢", command=self.swap_scenario).pack(side=tk.LEFT, padx=2)

        ttk.Separator(row1_frame, orient='vertical').pack(side=tk.LEFT, fill=tk.Y, padx=10)
        ttk.Button(row1_frame, text="è§†é¢‘åˆæˆ", command=lambda:self.run_finalize_video(zero_audio_only=False)).pack(side=tk.LEFT, padx=2)
        ttk.Button(row1_frame, text="è§†èƒŒåˆæˆ", command=lambda:self.run_finalize_video(zero_audio_only=True)).pack(side=tk.LEFT, padx=2)
        ttk.Button(row1_frame, text="ä¸Šä¼ è§†é¢‘", command=self.run_upload_video).pack(side=tk.LEFT, padx=2)
        #ttk.Button(scenario_nav_row, text="æ‹¼æ¥è§†é¢‘", command=self.run_final_concat_video).pack(side=tk.LEFT, padx=2)

        ttk.Separator(row1_frame, orient='vertical').pack(side=tk.LEFT, fill=tk.Y, padx=10)
        pid_frame = ttk.Frame(row1_frame)
        pid_frame.pack(side=tk.LEFT, padx=(0, 10))
        ttk.Label(pid_frame, text="PID").pack(side=tk.LEFT)
        self.shared_pid = ttk.Label(pid_frame, width=20, relief="sunken", background="white")
        self.shared_pid.pack(side=tk.LEFT, padx=(5, 0))
        
        # è¯­è¨€ç»„ (åªè¯»)
        lang_frame = ttk.Frame(row1_frame)
        lang_frame.pack(side=tk.LEFT, padx=(0, 10))
        ttk.Label(lang_frame, text="è¯­è¨€").pack(side=tk.LEFT)
        self.shared_language = ttk.Label(lang_frame, width=5, relief="sunken", background="white")
        self.shared_language.pack(side=tk.LEFT, padx=(5, 0))
        
        # è§†é¢‘æ ‡é¢˜ç»„
        title_frame = ttk.Frame(row1_frame)
        title_frame.pack(side=tk.LEFT, padx=(0, 10))
        ttk.Label(title_frame, text="æ ‡é¢˜").pack(side=tk.LEFT)
        self.video_title = ttk.Entry(title_frame, width=20)
        self.video_title.pack(side=tk.LEFT)
        ttk.Label(title_frame, text="é¢‘é“").pack(side=tk.LEFT)
        self.shared_channel = ttk.Label(title_frame, width=15, relief="sunken", background="white")
        self.shared_channel.pack(side=tk.LEFT)
        ttk.Label(title_frame, text="åœºåœ°").pack(side=tk.LEFT)
        self.story_site_entry = ttk.Entry(title_frame, width=15)
        self.story_site_entry.pack(side=tk.LEFT)
        ttk.Label(title_frame, text="KEY").pack(side=tk.LEFT)
        self.project_keywords = ttk.Entry(title_frame, width=15)
        self.project_keywords.pack(side=tk.LEFT)
        
        # è§†é¢‘å°ºå¯¸ç»„
        size_frame = ttk.Frame(row1_frame)
        size_frame.pack(side=tk.LEFT, padx=(0, 10))
        ttk.Label(size_frame, text="å°ºå¯¸").pack(side=tk.LEFT)
        self.video_width = ttk.Entry(size_frame, width=5)
        self.video_width.pack(side=tk.LEFT)
        ttk.Label(size_frame, text="Ã—").pack(side=tk.LEFT)
        self.video_height = ttk.Entry(size_frame, width=5)
        self.video_height.pack(side=tk.LEFT)


        ttk.Separator(row1_frame, orient='vertical').pack(side=tk.LEFT, fill=tk.Y, padx=10)

        tool_frame = ttk.Frame(row1_frame)
        tool_frame.pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(tool_frame, text="Videoç”Ÿæˆ", command=self.start_video_gen_batch).pack(side=tk.LEFT) 
        ttk.Button(tool_frame, text="åª’ä½“æ¸…ç†",  command=self.clean_media).pack(side=tk.LEFT) 
        ttk.Button(tool_frame, text="WANæ¸…ç†",   command=self.clean_wan).pack(side=tk.LEFT) 
        ttk.Button(tool_frame, text="æ ‡è®°æ¸…ç†",  command=self.clean_media_mark).pack(side=tk.LEFT)

   
    def open_image_prompt_dialog(self, create_image_callback, scenario, image_mode):
        """æ‰“å¼€æç¤ºè¯å®¡æŸ¥å¯¹è¯æ¡†ï¼Œç”¨äºåœ¨åˆ›å»ºå›¾åƒå‰é¢„è§ˆå’Œç¼–è¾‘æç¤ºè¯"""
        from gui.image_prompts_review_dialog import ImagePromptsReviewDialog
        
        dialog = ImagePromptsReviewDialog(
            parent=self,
            workflow=self.workflow,
            create_image_callback=create_image_callback,
            scenario=scenario,
            track=image_mode
        )
        dialog.show()


    def swap_second(self):
        """äº¤æ¢ç¬¬ä¸€è½¨é“ä¸ç¬¬äºŒè½¨é“"""
        current_scenario = self.get_current_scenario()
        clip_video_path = get_file_path(current_scenario, 'clip')
        clip_audio_path = get_file_path(current_scenario, 'clip_audio')
        track_path = get_file_path(current_scenario, "second")
        if not track_path:
            messagebox.showwarning("è­¦å‘Š", "second è½¨é“è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return
        temp_track = self.workflow.ffmpeg_processor.add_audio_to_video(track_path, clip_audio_path)

        self.workflow.refresh_scenario_media(current_scenario, "second", '.mp4', clip_video_path)
        self.workflow.refresh_scenario_media(current_scenario, "second_audio", '.wav', clip_audio_path, True)

        self.workflow.refresh_scenario_media(current_scenario, 'clip', '.mp4', temp_track)
        self.refresh_gui_scenarios()


    def swap_zero(self):
        """äº¤æ¢ç¬¬ä¸€è½¨é“ä¸ç¬¬äºŒè½¨é“"""
        current_scenario = self.get_current_scenario()
        clip_video_path = get_file_path(current_scenario, 'clip')
        clip_audio_path = get_file_path(current_scenario, 'clip_audio')
        zero_path = get_file_path(current_scenario, "zero")
        if not zero_path:
            messagebox.showwarning("è­¦å‘Š", "zeroè½¨é“è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return

        self.workflow.refresh_scenario_media(current_scenario, "back", '.mp4', clip_video_path)

        start_time_in_story, clip_duration, story_duration, indx, count, is_story_last_clip = self.workflow.get_scenario_detail(current_scenario)
        end_time = start_time_in_story + clip_duration

        temp_track = self.workflow.ffmpeg_processor.resize_video(zero_path, None, None, start_time_in_story, end_time)
        temp_track = self.workflow.ffmpeg_processor.add_audio_to_video(temp_track, clip_audio_path)

        self.workflow.refresh_scenario_media(current_scenario, 'clip', '.mp4', temp_track)
        self.refresh_gui_scenarios()


    def track_recover(self):
        current_scenario = self.get_current_scenario()
        clip = current_scenario.get('clip', None)
        back = current_scenario.get('back', None)
        if not back:
            messagebox.showwarning("è­¦å‘Š", "èƒŒæ™¯è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return

        paths = back.split(',')
        back_path = None
        for i in range(len(paths)):
            back_path = paths[i]
            back = ','.join(paths[i+1:])
            if os.path.exists(back_path):
                break
            back_path = None
            if i == len(paths) - 1:
                back = ""

        if not back_path:
            return

        if clip:
            current_scenario['back'] = clip + "," + back

        self.workflow.refresh_scenario_media(current_scenario, 'clip', '.mp4', back_path)
        self.workflow.save_scenarios_to_json()
        self.refresh_gui_scenarios()


    def reset_second_track_playing_offset(self):
        self.second_track_offset, clip_duration, story_duration, indx, count, is_story_last_clip = self.workflow.get_scenario_detail(self.get_current_scenario())
        self.second_track_paused_time = None
        self.update_second_track_time_display()


    def fetch_second_clip(self, to_end, volume):
        current_scenario = self.get_current_scenario()
        second_track_path = get_file_path(current_scenario, 'second')
        second_audio_path = get_file_path(current_scenario, 'second_audio')
        if not second_track_path:
            messagebox.showwarning("è­¦å‘Š", "ç¬¬äºŒè½¨é“è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return
        
        second_track_duration = self.workflow.ffmpeg_processor.get_duration(second_track_path)

        if not self.second_track_cap:
            second_time = 0
        else:
            second_pos = self.second_track_cap.get(cv2.CAP_PROP_POS_FRAMES)
            second_time = second_pos / self.STANDARD_FPS

        if second_time <= 0:
            second_time, clip_duration, story_duration, indx, count, is_story_last_clip = self.workflow.get_scenario_detail(current_scenario)

        if second_track_duration < second_time:
            second_time = 0

        if to_end:
            second_v = self.workflow.ffmpeg_processor.resize_video(second_track_path, None, None, second_time, None, volume)
            second_a = self.workflow.ffmpeg_audio_processor.audio_cut_fade(second_audio_path, second_time, None, 1.0, 1.0,volume)
        else:
            clip_duration = self.workflow.find_clip_duration(current_scenario)
            second_v = self.workflow.ffmpeg_processor.resize_video(second_track_path, None, None, second_time, second_time+clip_duration, volume)
            second_a = self.workflow.ffmpeg_audio_processor.audio_cut_fade(second_audio_path, second_time, clip_duration, 1.0, 1.0, volume)

        return second_v, second_a


    def select_second_track(self, track_id):
       self.selected_second_track = track_id
       self.on_second_track_tab_changed()



    def pip_second_track(self):
        """å°†ç¬¬äºŒè½¨é“ä½œä¸ºç”»ä¸­ç”»å åŠ åˆ°ä¸»è½¨é“è§†é¢‘ä¸Š"""
        try:
            current_scenario = self.get_current_scenario()
            second_path = get_file_path(current_scenario, self.selected_second_track)
            second_audio = get_file_path(current_scenario, self.selected_second_track+'_audio')
            second_left = get_file_path(current_scenario, self.selected_second_track+'_left')
            second_right = get_file_path(current_scenario, self.selected_second_track+'_right')
            if not second_path or not second_audio:
                messagebox.showwarning("è­¦å‘Š", "ç¬¬äºŒè½¨é“è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                return

            clip_video = get_file_path(current_scenario, "clip")
            clip_audio = get_file_path(current_scenario, "clip_audio")
            start_time, clip_duration, story_duration, indx, count, is_story_last_clip = self.workflow.get_scenario_detail(current_scenario)
            start_time = start_time + self.second_delta

            if is_story_last_clip: 
                second_track_copy = self.workflow.ffmpeg_processor.resize_video(second_path, None, None, start_time, None)
                second_audio_copy = self.workflow.ffmpeg_audio_processor.audio_cut_fade(second_audio, start_time, None, 0, 0, 1.0)
            else:    
                second_track_copy = self.workflow.ffmpeg_processor.resize_video(second_path, None, None, start_time, start_time + clip_duration)
                second_audio_copy = self.workflow.ffmpeg_audio_processor.audio_cut_fade(second_audio, start_time, clip_duration, 0, 0, 1.0)
            print(f"ğŸ“º æ‰“å¼€ç”»ä¸­ç”»è®¾ç½®å¯¹è¯æ¡†...")
            
            # åˆ›å»ºç”»ä¸­ç”»è®¾ç½®å¯¹è¯æ¡†
            pip_dialog = PictureInPictureDialog(self.root, clip_video, second_track_copy, second_left, second_right)
            
            # ç­‰å¾…å¯¹è¯æ¡†å…³é—­
            self.root.wait_window(pip_dialog.dialog)
            
            # æ£€æŸ¥ç”¨æˆ·çš„é€‰æ‹©
            if pip_dialog.result:
                settings = pip_dialog.result
                print(f"ğŸ“º ç”¨æˆ·é€‰æ‹©çš„ç”»ä¸­ç”»è®¾ç½®: {settings}")

                back = current_scenario.get('back', '')
                current_scenario['back'] = clip_video + "," + back

                if settings['position'] == "full":
                    v = self.workflow.ffmpeg_processor.add_audio_to_video(second_track_copy, clip_audio)
                    self.workflow.refresh_scenario_media(current_scenario, 'clip', '.mp4', v)
                elif settings['position'] == "av":
                    self.workflow.refresh_scenario_media(current_scenario, 'clip', '.mp4', second_track_copy)
                    self.workflow.refresh_scenario_media(current_scenario, 'clip_audio', '.wav', second_audio_copy)
                else:
                    # å¤„ç†ç”»ä¸­ç”»
                    self.process_picture_in_picture(
                        background_audio=clip_audio,
                        background_video=clip_video,
                        overlay_video=second_track_copy,
                        overlay_audio=second_audio_copy,
                        overlay_left=second_left,
                        overlay_right=second_right,
                        settings=settings
                    )

                # æ›´æ–°æ˜¾ç¤º
                self.workflow.save_scenarios_to_json()
                self.refresh_gui_scenarios()
                messagebox.showinfo("æˆåŠŸ", f"ç”»ä¸­ç”»å¤„ç†å®Œæˆ")

            else:
                print("ğŸš« ç”¨æˆ·å–æ¶ˆäº†ç”»ä¸­ç”»è®¾ç½®")
                
        except Exception as e:
            error_msg = f"ç”»ä¸­ç”»å¤„ç†å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            messagebox.showerror("é”™è¯¯", error_msg)


    def process_picture_in_picture(self, background_video, background_audio, overlay_video, overlay_audio, overlay_left, overlay_right, settings):
        """å¤„ç†ç”»ä¸­ç”»è§†é¢‘ç”Ÿæˆ"""
        try:
            print(f"ğŸ¬ å¼€å§‹å¤„ç†ç”»ä¸­ç”»...")
            if not self.video_cap:
                current_time = 0
            else:
                current_frame = self.video_cap.get(cv2.CAP_PROP_POS_FRAMES)
                current_time = current_frame / self.STANDARD_FPS

            left_video = None
            right_video = None
            if settings['position'] == "left" and overlay_left:
                left_video = overlay_left
            elif settings['position'] == "right" and overlay_right:
                right_video = overlay_right
            elif settings['position'] == "center" and overlay_left and overlay_right:
                left_video = overlay_left
                right_video = overlay_right

            if left_video or right_video:
                #    background_audio=background_audio,
                output_video = self.workflow.ffmpeg_processor.add_left_right_picture_in_picture(
                                    background_video=background_video,
                                    overlay_video_left=left_video,
                                    overlay_video_right=right_video,
                                    ratio=settings['ratio'],
                                    delay_time=settings.get('delay_time', 0),
                                    edge_blur=0
                                )
            else:
                output_video = self.workflow.ffmpeg_processor.add_picture_in_picture(
                    background_video=background_video,
                    slide_in_video=overlay_video,
                    start_time=current_time,
                    ratio=settings['ratio'],
                    transition_duration=settings['transition_duration'],
                    position=settings['position'],
                    mask=settings['shape']
                )

            print(f"âœ… ç”»ä¸­ç”»å¤„ç†å®Œæˆ: {output_video}")

            output_audio = None
            if settings['audio_volume'] == 0.0:
                olda, output_audio = self.workflow.refresh_scenario_media(self.get_current_scenario(), "clip_audio", ".wav", background_audio, True)
                output_video = self.workflow.ffmpeg_processor.add_audio_to_video(output_video, background_audio)
                olda, output_video = self.workflow.refresh_scenario_media(self.get_current_scenario(), "clip", ".mp4", output_video, True)
            else:
                output_audio = background_audio
                if overlay_audio:
                    volume_main = 1
                    volume_overlay = 1
                    if settings['audio_volume'] > 0 :
                        volume_overlay = settings['audio_volume']
                        if volume_overlay > 0.9:
                            volume_overlay = 0.9
                    elif settings['audio_volume'] < 0:
                        volume_main = settings['audio_volume']
                        if volume_main < -0.9:
                            volume_main = -0.9
                        volume_main = 1+volume_main    

                    output_audio = self.workflow.ffmpeg_audio_processor.audio_mix(background_audio, volume_main, current_time, overlay_audio, volume_overlay)
                    olda, output_audio = self.workflow.refresh_scenario_media(self.get_current_scenario(), "clip_audio", ".wav", output_audio, True)

                    output_video = self.workflow.ffmpeg_processor.add_audio_to_video(output_video, output_audio)
                    olda, output_video = self.workflow.refresh_scenario_media(self.get_current_scenario(), "clip", ".mp4", output_video, True)
            
            return output_video, output_audio

        except Exception as e:
            error_msg = f"ç”»ä¸­ç”»å¤„ç†å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            messagebox.showerror("é”™è¯¯", error_msg)
            return None, None


    def upload_promo_video(self):
        task_id = str(uuid.uuid4())
        self.tasks[task_id] = {
            "type": "upload_promo_video",
            "status": "è¿è¡Œä¸­",
            "start_time": datetime.now(),
            "pid": self.workflow.pid
        }
        
        def run_task():
            try:
                print(f"ğŸ¬ ä¸Šä¼ å®£ä¼ è§†é¢‘...")
                title = self.video_title.get().strip()
                
                # è°ƒç”¨å·¥ä½œæµçš„æ–¹æ³•
                result_video_path = self.workflow.upload_promo_video(title, "")

                print(f"âœ… å®£ä¼ è§†é¢‘ä¸Šä¼ å®Œæˆ: {result_video_path}")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                self.tasks[task_id]["status"] = "å®Œæˆ"
                self.tasks[task_id]["result"] = f"å®£ä¼ è§†é¢‘å·²ä¸Šä¼ : {os.path.basename(result_video_path)}"
                
            except Exception as e:
                error_msg = f"ä¸Šä¼ å®£ä¼ è§†é¢‘å¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                
                # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                self.tasks[task_id]["status"] = "å¤±è´¥"
                self.tasks[task_id]["error"] = str(e)
                
                # é€šçŸ¥é”™è¯¯
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", error_msg))
        # å¯åŠ¨åå°ä»»åŠ¡
        thread = threading.Thread(target=run_task, daemon=True)
        thread.start()
        
        print(f"ğŸš€ ä¸Šä¼ å®£ä¼ è§†é¢‘ä»»åŠ¡å·²å¯åŠ¨ï¼Œä»»åŠ¡ID: {task_id}")
        


    def open_promo_video_gen_dialog(self):
        audio_file = config.get_media_path(self.get_pid()) + "/short.wav"
        if not os.path.exists(audio_file):
            messagebox.showerror("é”™è¯¯", f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
            return

        # read short.json, for each json item, read the 'content' field, concat them by \n, as srt_content
        srt_content = None
        if os.path.exists(config.get_project_path(self.get_pid()) + "/short.json"):
            # read short.json as text
            with open(config.get_project_path(self.get_pid()) + "/short.json", 'r', encoding='utf-8') as f:
                srt_content = f.read()

        start_duration=10
        image_duration=5
        
        task_id = str(uuid.uuid4())
        self.tasks[task_id] = {
            "type": "open_promo_video_gen_dialog",
            "status": "è¿è¡Œä¸­",
            "start_time": datetime.now(),
            "pid": self.workflow.pid
        }
        
        def run_task():
            try:
                print(f"ğŸ¬ å¼€å§‹ç”Ÿæˆé¢‘é“å®£ä¼ è§†é¢‘...")
                title = self.video_title.get().strip()
                
                # è°ƒç”¨å·¥ä½œæµçš„æ–¹æ³•
                result_video_path = self.workflow.create_channel_promote_video(audio_file, title, self.project_keywords.get().strip(), srt_content, start_duration, image_duration)

                print(f"âœ… é¢‘é“å®£ä¼ è§†é¢‘ç”Ÿæˆå®Œæˆ: {result_video_path}")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                self.tasks[task_id]["status"] = "å®Œæˆ"
                self.tasks[task_id]["result"] = f"å®£ä¼ è§†é¢‘å·²ç”Ÿæˆ: {os.path.basename(result_video_path)}"
                
            except Exception as e:
                error_msg = f"é¢‘é“å®£ä¼ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                
                # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                self.tasks[task_id]["status"] = "å¤±è´¥"
                self.tasks[task_id]["error"] = str(e)
                
                # é€šçŸ¥é”™è¯¯
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", error_msg))
        
        # å¯åŠ¨åå°ä»»åŠ¡
        thread = threading.Thread(target=run_task, daemon=True)
        thread.start()
        
        print(f"ğŸš€ é¢‘é“å®£ä¼ è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨ï¼Œä»»åŠ¡ID: {task_id}")



    def create_video_tab(self):
        """åˆ›å»ºè§†é¢‘ç”Ÿæˆæ ‡ç­¾é¡µ"""
        tab = ttk.Frame(self.notebook)
        self.notebook.add(tab, text="ç”Ÿæˆè§†é¢‘--")
        
        # ä¸»å†…å®¹åŒºåŸŸ
        main_content = ttk.Frame(tab)
        main_content.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        # å·¦ä¾§ï¼šè§†é¢‘é¢„è§ˆåŒºåŸŸ
        video_frame = ttk.LabelFrame(main_content, text="é¢„è§ˆ", padding=10)
        video_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=False, padx=(0, 5))
        # è®¾ç½®å·¦ä¾§é¢æ¿çš„æœ€å¤§å®½åº¦ï¼Œä¸ºå³ä¾§é¢æ¿ç•™å‡ºç©ºé—´
        video_frame.configure(width=1700)
        video_frame.pack_propagate(False)

        # åˆ›å»ºæ°´å¹³å¸ƒå±€æ¡†æ¶æ¥å¹¶æ’æ˜¾ç¤ºå›¾åƒæ ‡ç­¾å’Œè§†é¢‘ç”»å¸ƒ
        preview_frame = ttk.Frame(video_frame)
        preview_frame.pack(fill=tk.BOTH, expand=True)
        
        # å·¦ä¾§åŒºåŸŸï¼šèƒŒæ™¯è½¨é“å’Œç¬¬äºŒè½¨é“ï¼ˆå‡å°‘å®½åº¦ç»™video_canvasæ›´å¤šç©ºé—´ï¼‰
        left_frame = ttk.Frame(preview_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=False, padx=(0, 5))
        # è®¾ç½®å·¦ä¾§æ¡†æ¶çš„å®½åº¦ï¼Œä¸ºvideo_canvasç•™å‡ºæ›´å¤šç©ºé—´
        left_frame.configure(width=640)
        left_frame.pack_propagate(False)
        
        # è§’è‰²é€‰æ‹©ç»„åˆæ¡†æ¡†æ¶
        roles_frame = ttk.Frame(left_frame)
        roles_frame.pack(fill=tk.X, pady=(0, 5))
        
        # å›¾ç‰‡é¢„è§ˆåŒºåŸŸï¼ˆåŸzeroä½ç½®ï¼‰
        images_preview_frame = ttk.LabelFrame(left_frame, text="å›¾ç‰‡é¢„è§ˆ (æ”¯æŒæ‹–æ”¾)", padding=5)
        images_preview_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        
        # åˆ›å»º3ä¸ªå›¾ç‰‡é¢„è§ˆcanvas (clip_image, second_image, zero_image)
        images_container = ttk.Frame(images_preview_frame)
        images_container.pack(fill=tk.BOTH, expand=True)
        
        # Replace the images_preview_frame section (lines 794-859) with this enhanced version:
        # === Clip Image Canvas (clip_image + clip_image_last) ===
        clip_img_frame = ttk.Frame(images_container)
        clip_img_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 2))
        ttk.Label(clip_img_frame, text="Clip", anchor=tk.CENTER).pack()

        # Clip image container with two sub-canvases
        clip_canvas_container = ttk.Frame(clip_img_frame)
        clip_canvas_container.pack(fill=tk.BOTH, expand=True)

        # Top: clip_image
        self.clip_image_canvas = tk.Canvas(clip_canvas_container, bg='gray20', width=150, height=75, 
                                        highlightthickness=2, highlightbackground='blue')
        self.clip_image_canvas.pack(fill=tk.BOTH, expand=True, pady=(0, 1))
        self.clip_image_canvas.create_text(75, 37, text="Clip\nImage", fill="gray", font=("Arial", 8), 
                                        justify=tk.CENTER, tags="hint")
        try:
            self.clip_image_canvas.drop_target_register(DND_FILES)
            self.clip_image_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'clip_image'))
        except: pass
        self.clip_image_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('clip_image'))

        # Bottom: clip_image_last
        self.clip_image_last_canvas = tk.Canvas(clip_canvas_container, bg='gray20', width=150, height=75, 
                                                highlightthickness=2, highlightbackground='blue')
        self.clip_image_last_canvas.pack(fill=tk.BOTH, expand=True, pady=(1, 0))
        self.clip_image_last_canvas.create_text(75, 37, text="Clip\nLast", fill="gray", font=("Arial", 8), 
                                            justify=tk.CENTER, tags="hint")
        try:
            self.clip_image_last_canvas.drop_target_register(DND_FILES)
            self.clip_image_last_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'clip_image_last'))
        except: pass
        self.clip_image_last_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('clip_image_last'))

        # === Zero Image Canvas (zero_image + zero_image_last) ===
        zero_img_frame = ttk.Frame(images_container)
        zero_img_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=2)
        ttk.Label(zero_img_frame, text="Zero", anchor=tk.CENTER).pack()

        zero_canvas_container = ttk.Frame(zero_img_frame)
        zero_canvas_container.pack(fill=tk.BOTH, expand=True)

        # Top: zero_image
        self.zero_image_canvas = tk.Canvas(zero_canvas_container, bg='gray20', width=150, height=75, 
                                        highlightthickness=2, highlightbackground='orange')
        self.zero_image_canvas.pack(fill=tk.BOTH, expand=True, pady=(0, 1))
        self.zero_image_canvas.create_text(75, 37, text="Zero\nImage", fill="gray", font=("Arial", 8), 
                                        justify=tk.CENTER, tags="hint")
        try:
            self.zero_image_canvas.drop_target_register(DND_FILES)
            self.zero_image_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'zero_image'))
        except: pass
        self.zero_image_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('zero_image'))

        # Bottom: zero_image_last
        self.zero_image_last_canvas = tk.Canvas(zero_canvas_container, bg='gray20', width=150, height=75, 
                                                highlightthickness=2, highlightbackground='orange')
        self.zero_image_last_canvas.pack(fill=tk.BOTH, expand=True, pady=(1, 0))
        self.zero_image_last_canvas.create_text(75, 37, text="Zero\nLast", fill="gray", font=("Arial", 8), 
                                            justify=tk.CENTER, tags="hint")
        try:
            self.zero_image_last_canvas.drop_target_register(DND_FILES)
            self.zero_image_last_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'zero_image_last'))
        except: pass
        self.zero_image_last_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('zero_image_last'))

        # === One Image Canvas (one_image + one_image_last) ===
        one_img_frame = ttk.Frame(images_container)
        one_img_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=2)
        ttk.Label(one_img_frame, text="One", anchor=tk.CENTER).pack()

        one_canvas_container = ttk.Frame(one_img_frame)
        one_canvas_container.pack(fill=tk.BOTH, expand=True)

        # Top: one_image
        self.one_image_canvas = tk.Canvas(one_canvas_container, bg='gray20', width=150, height=75, 
                                        highlightthickness=2, highlightbackground='purple')
        self.one_image_canvas.pack(fill=tk.BOTH, expand=True, pady=(0, 1))
        self.one_image_canvas.create_text(75, 37, text="One\nImage", fill="gray", font=("Arial", 8), 
                                        justify=tk.CENTER, tags="hint")
        try:
            self.one_image_canvas.drop_target_register(DND_FILES)
            self.one_image_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'one_image'))
        except: pass
        self.one_image_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('one_image'))

        # Bottom: one_image_last
        self.one_image_last_canvas = tk.Canvas(one_canvas_container, bg='gray20', width=150, height=75, 
                                            highlightthickness=2, highlightbackground='purple')
        self.one_image_last_canvas.pack(fill=tk.BOTH, expand=True, pady=(1, 0))
        self.one_image_last_canvas.create_text(75, 37, text="One\nLast", fill="gray", font=("Arial", 8), 
                                            justify=tk.CENTER, tags="hint")
        try:
            self.one_image_last_canvas.drop_target_register(DND_FILES)
            self.one_image_last_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'one_image_last'))
        except: pass
        self.one_image_last_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('one_image_last'))

        # === Second Image Canvas (second_image + second_image_last) ===
        second_img_frame = ttk.Frame(images_container)
        second_img_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(2, 0))
        ttk.Label(second_img_frame, text="Second", anchor=tk.CENTER).pack()

        second_canvas_container = ttk.Frame(second_img_frame)
        second_canvas_container.pack(fill=tk.BOTH, expand=True)

        # Top: second_image
        self.second_image_canvas = tk.Canvas(second_canvas_container, bg='gray20', width=150, height=75, 
                                            highlightthickness=2, highlightbackground='green')
        self.second_image_canvas.pack(fill=tk.BOTH, expand=True, pady=(0, 1))
        self.second_image_canvas.create_text(75, 37, text="Second\nImage", fill="gray", font=("Arial", 8), 
                                            justify=tk.CENTER, tags="hint")
        try:
            self.second_image_canvas.drop_target_register(DND_FILES)
            self.second_image_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'second_image'))
        except: pass
        self.second_image_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('second_image'))

        # Bottom: second_image_last
        self.second_image_last_canvas = tk.Canvas(second_canvas_container, bg='gray20', width=150, height=75, 
                                                highlightthickness=2, highlightbackground='green')
        self.second_image_last_canvas.pack(fill=tk.BOTH, expand=True, pady=(1, 0))
        self.second_image_last_canvas.create_text(75, 37, text="Second\nLast", fill="gray", font=("Arial", 8), 
                                                justify=tk.CENTER, tags="hint")
        try:
            self.second_image_last_canvas.drop_target_register(DND_FILES)
            self.second_image_last_canvas.dnd_bind('<<Drop>>', lambda e: self.on_image_drop(e, 'second_image_last'))
        except: pass
        self.second_image_last_canvas.bind('<Double-Button-1>', lambda e: self.on_image_double_click('second_image_last'))
        

        # è§†é¢‘è½¨é“é¢„è§ˆåŒºåŸŸ - ä½¿ç”¨Tabæ§ä»¶ï¼ˆåŒ…å«secondå’Œzeroï¼‰
        track_video_frame = ttk.LabelFrame(left_frame, text="è½¨é“è§†é¢‘é¢„è§ˆ", padding=5)
        track_video_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        
        # åˆ›å»ºNotebook (Tabæ§ä»¶)
        self.second_notebook = ttk.Notebook(track_video_frame)
        self.second_notebook.pack(fill=tk.BOTH, expand=True)
        
        # === Tab 1: å®Œæ•´ç¬¬äºŒè½¨é“ ===
        tab_full_second = ttk.Frame(self.second_notebook)
        self.second_notebook.add(tab_full_second, text="å®Œæ•´è§†é¢‘")
        
        # ç¬¬äºŒè½¨é“è§†é¢‘ç”»å¸ƒ
        self.second_track_canvas = tk.Canvas(tab_full_second, bg='black', width=360, height=180)
        self.second_track_canvas.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        
        # ç¬¬äºŒè½¨é“æç¤ºæ–‡æœ¬
        self.second_track_canvas.create_text(160, 90, text="ç¬¬äºŒè½¨é“è§†é¢‘é¢„è§ˆ\né€‰æ‹©è§†é¢‘åæ’­æ”¾æ˜¾ç¤º", 
                                            fill="gray", font=("Arial", 10), justify=tk.CENTER, tags="hint")
        
        # === Tab 2: ç”»ä¸­ç”» Left & Right ===
        tab_pip_lr = ttk.Frame(self.second_notebook)
        self.second_notebook.add(tab_pip_lr, text="ç”»ä¸­ç”»L/R")
        
        # åˆ›å»ºå·¦å³å¹¶æ’çš„ç”»å¸ƒæ¡†æ¶
        pip_lr_frame = ttk.Frame(tab_pip_lr)
        pip_lr_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        
        # å·¦ä¾§è§†é¢‘ç”»å¸ƒ
        left_canvas_frame = ttk.Frame(pip_lr_frame)
        left_canvas_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 2))
        ttk.Label(left_canvas_frame, text="Left", anchor=tk.CENTER).pack()
        self.pip_left_canvas = tk.Canvas(left_canvas_frame, bg='black', width=175, height=180)
        self.pip_left_canvas.pack(fill=tk.BOTH, expand=True)
        self.pip_left_canvas.create_text(77, 80, text="Left\nç”»ä¸­ç”»å·¦ä¾§", fill="gray", font=("Arial", 9), justify=tk.CENTER, tags="hint")
        
        # å³ä¾§è§†é¢‘ç”»å¸ƒ
        right_canvas_frame = ttk.Frame(pip_lr_frame)
        right_canvas_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(2, 0))
        ttk.Label(right_canvas_frame, text="Right", anchor=tk.CENTER).pack()
        self.pip_right_canvas = tk.Canvas(right_canvas_frame, bg='black', width=175, height=180)
        self.pip_right_canvas.pack(fill=tk.BOTH, expand=True)
        self.pip_right_canvas.create_text(77, 80, text="Right\nç”»ä¸­ç”»å³ä¾§", fill="gray", font=("Arial", 9), justify=tk.CENTER, tags="hint")
        
        # è½¨é“è§†é¢‘æ§åˆ¶å™¨ï¼ˆåœ¨é¢„è§ˆåŒºåŸŸä¸‹æ–¹ï¼Œæ‰€æœ‰tabå…±ç”¨ï¼‰
        self.track_frame = ttk.Frame(left_frame)
        self.track_frame.pack(fill=tk.X, pady=5)
        
        # ç¬¬äºŒè½¨é“æ’­æ”¾æŒ‰é’®
        self.track_play_button = ttk.Button(self.track_frame, text="â–¶", command=self.toggle_track_playback,width=3)
        self.track_play_button.pack(side=tk.LEFT, padx=2)

        # add field to display current playing time / duration of second track, and 2 buttons to move forward and backward seconds
        self.track_time_label = ttk.Label(self.track_frame, text="00:00 / 00:00")
        self.track_time_label.pack(side=tk.LEFT, padx=2)
        
        #ttk.Button(self.second_track_frame, text="â—€", command=self.move_second_track_backward, width=3).pack(side=tk.LEFT, padx=2)
        #ttk.Button(self.second_track_frame, text="â–¶", command=self.move_second_track_forward, width=3).pack(side=tk.LEFT, padx=2)
        ttk.Button(self.track_frame, text="ğŸ“º", command=lambda:self.pip_second_track(), width=3).pack(side=tk.LEFT, padx=2)
        ttk.Button(self.track_frame, text="ğŸ’«", command=lambda:self.select_second_track('zero'), width=3).pack(side=tk.LEFT, padx=2)
        ttk.Button(self.track_frame, text="ğŸ’«", command=lambda:self.select_second_track('one'), width=3).pack(side=tk.LEFT, padx=2)
        ttk.Button(self.track_frame, text="ğŸ’«", command=lambda:self.select_second_track('second'), width=3).pack(side=tk.LEFT, padx=2)
        #ttk.Button(self.track_frame, text="ğŸ’«", command=self.swap_second, width=3).pack(side=tk.LEFT, padx=2)
        #ttk.Button(self.track_frame, text="âœ¨", command=self.swap_zero, width=3).pack(side=tk.LEFT, padx=2)
        #ttk.Button(self.track_frame, text="ğŸ”Š", command=self.pip_second_sound, width=3).pack(side=tk.LEFT, padx=2)
        ttk.Button(self.track_frame, text="ğŸ”„", command=self.reset_second_track_playing_offset, width=3).pack(side=tk.LEFT, padx=2)
        ttk.Button(self.track_frame, text="â±",  command=self.track_recover, width=3).pack(side=tk.LEFT, padx=2)
        
        # æ·»åŠ éŸ³é‡æ§åˆ¶æ»‘å—ï¼ˆå…±ç”¨ï¼Œæ ¹æ®å½“å‰tabè‡ªåŠ¨é€‰æ‹©ï¼‰
        ttk.Label(self.track_frame, text="éŸ³é‡:").pack(side=tk.LEFT, padx=(10, 2))
        self.volume_scale = ttk.Scale(self.track_frame, from_=0.0, to=1.5, 
                                     variable=self.track_volume_var, orient=tk.HORIZONTAL, length=60)
        self.volume_scale.pack(side=tk.LEFT, padx=2)
        self.volume_label = ttk.Label(self.track_frame, text="0.2")
        self.volume_label.pack(side=tk.LEFT, padx=2)

        ttk.Button(self.track_frame, text="ã€Šã€Š", command=lambda: self.adjust_second_delta(-0.5), width=3).pack(side=tk.LEFT, padx=1)
        self.second_delta_label = ttk.Label(self.track_frame, text="0.0s", width=4)
        self.second_delta_label.pack(side=tk.LEFT, padx=1)
        ttk.Button(self.track_frame, text="ã€‹ã€‹", command=lambda: self.adjust_second_delta(0.25), width=3).pack(side=tk.LEFT, padx=1)

        
        # ç»‘å®šéŸ³é‡å˜åŒ–äº‹ä»¶æ¥æ›´æ–°æ ‡ç­¾
        self.track_volume_var.trace('w', self.on_track_volume_change)
        
        # åˆå§‹åŒ–æ‰€æœ‰è½¨é“æ’­æ”¾ç›¸å…³å˜é‡
        # å›¾ç‰‡é¢„è§ˆå¼•ç”¨ï¼ˆé˜²æ­¢åƒåœ¾å›æ”¶ï¼‰
        self._clip_image_photo = None
        self._second_image_photo = None
        self._zero_image_photo = None
        
        # ç»‘å®štabåˆ‡æ¢äº‹ä»¶
        self.second_notebook.bind("<<NotebookTabChanged>>", self.on_second_track_tab_changed)

        # å³ä¾§åŒºåŸŸï¼šè§†é¢‘ç”»å¸ƒå’Œæ§åˆ¶æŒ‰é’®
        right_frame = ttk.Frame(preview_frame)
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=(5, 0))
        
        # è§†é¢‘é¢„è§ˆç”»å¸ƒï¼ˆç”¨äºæ˜¾ç¤ºè§†é¢‘å¸§ï¼‰
        self.video_canvas = tk.Canvas(right_frame, bg='black', height=480)
        self.video_canvas.pack(fill=tk.BOTH, expand=True)
        
        # æ·»åŠ æ‹–æ‹½æç¤ºæ–‡æœ¬ï¼ˆä½ç½®ä¼šåœ¨canvasé…ç½®ååŠ¨æ€è°ƒæ•´ï¼‰
        self.video_canvas.create_text(400, 180, text="æ‹–æ‹½MP4æ–‡ä»¶åˆ°æ­¤å¤„å¯æ›¿æ¢å½“å‰è§†é¢‘ç‰‡æ®µ\n\næ³¨æ„ï¼š\nâ€¢ è¾“å…¥è§†é¢‘ä¸èƒ½è¶…è¿‡å½“å‰åœºæ™¯æ—¶é•¿\nâ€¢ å¦‚æœè¾“å…¥è§†é¢‘è¾ƒçŸ­ï¼Œä¼šè‡ªåŠ¨å»¶é•¿", 
                                    fill="gray", font=("Arial", 12), justify=tk.CENTER, tags="drag_hint")
        
        # ç»‘å®šé…ç½®äº‹ä»¶æ¥åŠ¨æ€è°ƒæ•´æç¤ºæ–‡æœ¬ä½ç½®
        self.video_canvas.bind('<Configure>', self.on_video_canvas_configure)
        
        # è§†é¢‘æ§åˆ¶æŒ‰é’®æ¡†æ¶ï¼ˆåœ¨è§†é¢‘ç”»å¸ƒä¸‹æ–¹ï¼‰
        video_control_frame = ttk.Frame(right_frame)
        video_control_frame.pack(fill=tk.X, pady=5)
        
        # æ’­æ”¾/æš‚åœæŒ‰é’®
        self.video_play_button = ttk.Button(video_control_frame, text="â–¶", 
                                          command=self.toggle_video_playback, width=3)
        self.video_play_button.pack(side=tk.LEFT, padx=1)
        
        # åœæ­¢æŒ‰é’®
        self.video_stop_button = ttk.Button(video_control_frame, text="â¹", 
                                          command=self.stop_video_playback, width=3)
        self.video_stop_button.pack(side=tk.LEFT, padx=1)

        # ç¿»è½¬æŒ‰é’®
        ttk.Button(video_control_frame, text="ã€Šã€Š", command=lambda: self.move_video(-0.25), width=3).pack(side=tk.LEFT, padx=1)
        self.playing_delta_label = ttk.Label(video_control_frame, text="0.0s", width=4)
        self.playing_delta_label.pack(side=tk.LEFT, padx=1)
        ttk.Button(video_control_frame, text="ã€‹ã€‹", command=lambda: self.move_video(0.25), width=3).pack(side=tk.LEFT, padx=1)

        separator = ttk.Separator(video_control_frame, orient='vertical')
        separator.pack(side=tk.LEFT, fill=tk.Y, padx=5)

        ttk.Button(video_control_frame, text="åˆ†ç¦»", command=self.split_current_scenario, width=5).pack(side=tk.LEFT, padx=1) 
        ttk.Button(video_control_frame, text="ä¸‹ç§»", command=self.shift_forward, width=5).pack(side=tk.LEFT, padx=1)
        ttk.Button(video_control_frame, text="ä¸Šç§»", command=self.shift_before, width=5).pack(side=tk.LEFT, padx=1)
        ttk.Button(video_control_frame, text="å»¶ä¼¸", command=self.extend_scenario, width=5).pack(side=tk.LEFT, padx=1)
        ttk.Button(video_control_frame, text="åˆ åˆ", command=self.merge_or_delete, width=5).pack(side=tk.LEFT, padx=1)

        separator = ttk.Separator(video_control_frame, orient='vertical')
        separator.pack(side=tk.LEFT, fill=tk.Y, padx=5)

        ttk.Button(video_control_frame, text="äº¤æ¢", command=self.swap_with_next_image, width=5).pack(side=tk.LEFT, padx=1)
        ttk.Button(video_control_frame, text="åè½¬", command=self.reverse_video, width=5).pack(side=tk.LEFT, padx=1)
        ttk.Button(video_control_frame, text="é•œåƒ", command=self.mirror_video, width=5).pack(side=tk.LEFT, padx=1)
        ttk.Button(video_control_frame, text="æ ‡é¢˜", command=self.print_title, width=5).pack(side=tk.LEFT, padx=1)
        #ttk.Button(video_control_frame, text="èƒŒèµ·", command=self.zero_start, width=5).pack(side=tk.LEFT, padx=1)
        #ttk.Button(video_control_frame, text="èƒŒç»§", command=self.zero_continue, width=5).pack(side=tk.LEFT, padx=1)
        #ttk.Button(video_control_frame, text="èƒŒç»ˆ", command=self.zero_end, width=5).pack(side=tk.LEFT, padx=1)

        # åˆ†éš”ç¬¦
        separator = ttk.Separator(video_control_frame, orient='vertical')
        separator.pack(side=tk.LEFT, fill=tk.Y, padx=5)

        # å­˜å‚¨æŒ‰é’®å¼•ç”¨ä»¥ä¾¿åç»­æ§åˆ¶çŠ¶æ€
        self.insert_scenario_button = ttk.Button(video_control_frame, text="å‰æ’", command=self.insert_scenario, width=6)
        self.insert_scenario_button.pack(side=tk.LEFT, padx=1)

        self.append_scenario_button = ttk.Button(video_control_frame, text="åæ’", command=self.append_scenario, width=6)
        self.append_scenario_button.pack(side=tk.LEFT, padx=1)

        #ttk.Button(scenario_nav_row, text="æ™ºåˆ†åœºæ™¯", 
        #          command=self.split_smart_scenario).pack(side=tk.LEFT, padx=2) 

        # è§†é¢‘è¿›åº¦æ ‡ç­¾
        self.video_progress_label = ttk.Label(video_control_frame, text="00:00 / 00:00")
        self.video_progress_label.pack(side=tk.RIGHT, padx=1)
        
        # åˆå§‹åŒ–è§†é¢‘è¿›åº¦æ˜¾ç¤º
        self.update_video_progress_display()
        
        # è§†é¢‘æ’­æ”¾çŠ¶æ€
        self.video_playing = False
        self.video_cap = None
        self.video_after_id = None
        self.video_start_time = None
        self.video_pause_time = None  # è®°å½•æš‚åœæ—¶çš„ç´¯è®¡æ’­æ”¾æ—¶é—´
        
        # å³ä¾§ï¼šåœºæ™¯ä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
        video_edit_frame = ttk.LabelFrame(main_content, text="åœºæ™¯ä¿¡æ¯", padding=10)
        video_edit_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=(5, 0))
        # è®¾ç½®å³ä¾§é¢æ¿çš„å›ºå®šå®½åº¦ï¼Œé˜²æ­¢è¢«æŒ¤å‹
        video_edit_frame.configure(width=650)
        video_edit_frame.pack_propagate(False)
        
        # æŒç»­æ—¶é—´å’Œå®£ä¼ æ¨¡å¼åœ¨åŒä¸€è¡Œ
        duration_promo_frame = ttk.Frame(video_edit_frame)
        duration_promo_frame.grid(row=1, column=0, columnspan=2, sticky=tk.W+tk.E, pady=2)
        
        # æŒç»­æ—¶é—´ï¼ˆåªè¯»ï¼‰
        ttk.Label(duration_promo_frame, text="æŒç»­:").pack(side=tk.LEFT)
        self.scenario_duration = ttk.Entry(duration_promo_frame, width=12, state="readonly")
        self.scenario_duration.pack(side=tk.LEFT, padx=(2, 10))
        
        # å®£ä¼ æ¨¡å¼ï¼ˆå¯ç¼–è¾‘ï¼‰
        ttk.Label(duration_promo_frame, text="ä¸»åŠ¨ç”»:").pack(side=tk.LEFT, padx=(5, 5))
        self.scenario_main_animate = tk.StringVar(value="")
        self.main_animate_combobox = ttk.Combobox(duration_promo_frame, textvariable=self.scenario_main_animate, 
                                               values=config.ANIMATE_TYPES, 
                                               state="readonly", width=10)
        self.main_animate_combobox.pack(side=tk.LEFT)
        self.main_animate_combobox.bind('<<ComboboxSelected>>', self.on_video_clip_animation_change)


        ttk.Label(duration_promo_frame, text="æ¬¡åŠ¨ç”»:").pack(side=tk.LEFT, padx=(0, 5))
        self.second_animation_combobox = ttk.Combobox(duration_promo_frame, textvariable=self.scenario_second_animation,
                                               values=config.ANIMATE_TYPES, 
                                               state="readonly", width=10)
        self.second_animation_combobox.pack(side=tk.LEFT, padx=(0, 10))
        self.second_animation_combobox.bind('<<ComboboxSelected>>', self.on_image_type_change)

        # ç±»å‹ã€æƒ…ç»ªã€åŠ¨ä½œé€‰æ‹©ï¼ˆåœ¨åŒä¸€è¡Œï¼‰
        type_mood_action_frame = ttk.Frame(video_edit_frame)
        type_mood_action_frame.grid(row=2, column=0, columnspan=2, sticky=tk.W+tk.E, pady=2)

        ttk.Button(type_mood_action_frame, text="ç”Ÿåœºè§†é¢‘", width=8,  command=self.regenerate_scenario).pack(side=tk.LEFT)

        ttk.Button(type_mood_action_frame, text="ç”ŸåœºéŸ³é¢‘", width=8,  command=self.regenerate_audio).pack(side=tk.LEFT)



        action_frame = ttk.Frame(video_edit_frame)
        action_frame.grid(row=3, column=0, columnspan=2, sticky=tk.W+tk.E, pady=2)

        ttk.Button(action_frame, text="ç”Ÿä¸»å›¾ç‰‡", width=8, command=self.recreate_clip_image).pack(side=tk.LEFT, padx=2)

        ttk.Button(action_frame, text="ç”Ÿæ¬¡å›¾ç‰‡", width=8, command=self.recreate_second_image).pack(side=tk.LEFT, padx=2)

        ttk.Button(action_frame, text="ç”Ÿä¸»åŠ¨ç”»", width=8,  command=lambda: self.regenerate_video("clip")).pack(side=tk.LEFT)

        ttk.Button(action_frame, text="ç”Ÿæ¬¡åŠ¨ç”»", width=8,  command=lambda: self.regenerate_video(None)).pack(side=tk.LEFT)


        ttk.Label(video_edit_frame, text="æ•…äº‹:").grid(row=4, column=0, sticky=tk.NW, pady=2)
        self.scenario_story_expression = scrolledtext.ScrolledText(video_edit_frame, width=35, height=2)
        self.scenario_story_expression.grid(row=4, column=1, sticky=tk.W, padx=5, pady=2)
        
        # æ—¶ä»£æ—¶é—´
        ttk.Label(video_edit_frame, text="æ—¶ä»£:").grid(row=5, column=0, sticky=tk.NW, pady=2)
        self.scenario_era_time = scrolledtext.ScrolledText(video_edit_frame, width=35, height=1)
        self.scenario_era_time.grid(row=5, column=1, sticky=tk.W, padx=5, pady=2)
        
        # å…·ä½“åœ°ç‚¹
        ttk.Label(video_edit_frame, text="åœ°ç‚¹:").grid(row=6, column=0, sticky=tk.NW, pady=2)
        self.scenario_location = ttk.Entry(video_edit_frame, width=35)
        self.scenario_location.grid(row=6, column=1, sticky=tk.W, padx=5, pady=2)

        # é•œå¤´å…‰å½±
        ttk.Label(video_edit_frame, text="é•œå¤´:").grid(row=7, column=0, sticky=tk.NW, pady=2)
        self.scenario_camera_light = scrolledtext.ScrolledText(video_edit_frame, width=35, height=2)
        self.scenario_camera_light.grid(row=7, column=1, sticky=tk.W, padx=5, pady=2)

        # æ•…äº‹å†…å®¹
        ttk.Label(video_edit_frame, text="å†…å®¹:").grid(row=8, column=0, sticky=tk.NW, pady=2)
        self.scenario_story_content = scrolledtext.ScrolledText(video_edit_frame, width=35, height=2)
        self.scenario_story_content.grid(row=8, column=1, sticky=tk.W, padx=5, pady=2)

        # äººç‰©å…³ç³»
        ttk.Label(video_edit_frame, text="äººç‰©:").grid(row=9, column=0, sticky=tk.NW, pady=2)
        self.scenario_person_in_story = scrolledtext.ScrolledText(video_edit_frame, width=35, height=2)
        self.scenario_person_in_story.grid(row=9, column=1, sticky=tk.W, padx=5, pady=2)

        # åŠ¨ä½œæƒ…ç»ª
        ttk.Label(video_edit_frame, text="åŠ¨ä½œ:").grid(row=10, column=0, sticky=tk.NW, pady=2)
        self.scenario_speaker_action = scrolledtext.ScrolledText(video_edit_frame, width=35, height=2)
        self.scenario_speaker_action.grid(row=10, column=1, sticky=tk.W, padx=5, pady=2)

        # extra
        ttk.Label(video_edit_frame, text="FYI:").grid(row=11, column=0, sticky=tk.NW, pady=2)
        self.scenario_extra =  scrolledtext.ScrolledText(video_edit_frame, width=35, height=2)
        self.scenario_extra.grid(row=11, column=1, sticky=tk.W, padx=5, pady=2)

        ttk.Label(video_edit_frame, text="æƒ…ç»ª:").grid(row=13, column=0, sticky=tk.NW, pady=2)
        self.scenario_mood = ttk.Combobox(video_edit_frame, width=35, values=EXPRESSION_STYLES, state="readonly")
        self.scenario_mood.set("calm")  # è®¾ç½®é»˜è®¤å€¼
        self.scenario_mood.grid(row=13, column=1, sticky=tk.W, padx=5, pady=2)

        ttk.Label(video_edit_frame, text="è®²å‘˜:").grid(row=14, column=0, sticky=tk.NW, pady=2)
        self.scenario_speaker = ttk.Combobox(video_edit_frame, width=32, values=config.ROLES)
        self.scenario_speaker.grid(row=14, column=1, sticky=tk.W, padx=5, pady=2)

        ttk.Label(video_edit_frame, text="å·¦å³:").grid(row=15, column=0, sticky=tk.NW, pady=2)
        self.scenario_speaker_position = ttk.Combobox(video_edit_frame, width=32, values=config.SPEAKER_POSITIONS)
        self.scenario_speaker_position.grid(row=15, column=1, sticky=tk.W, padx=5, pady=2)

        # ç¬¬äºŒè½¨é“æ’­æ”¾çŠ¶æ€
        self.second_track_playing = False
        self.second_track_cap = None
        self.second_track_after_id = None
        
        # ç¬¬äºŒè½¨é“éŸ³é¢‘æ’­æ”¾çŠ¶æ€
        self.second_track_audio_playing = False
        self.second_track_audio_start_time = None
        
        # ç¬¬äºŒè½¨é“æš‚åœä½ç½®
        self.second_track_paused_time = None
        self.second_track_paused_audio_time = None
        self.second_track_cap = None
        self.second_track_after_id = None
        self.second_track_start_time = None

        self.second_track_playing = False
        self.second_track_offset = 0.0
        self.second_track_end_time = 0.0
        self.selected_second_track = "second"
        
        # PIP L/R (ç”»ä¸­ç”»å·¦å³)
        self.pip_lr_playing = False
        self.pip_left_cap = None
        self.pip_right_cap = None
        self.pip_lr_after_id = None
        self.pip_lr_start_time = None
        self.pip_lr_paused_time = None
        
        self.track_time_label.config(text="00:00 / 00:00")

        # åº•éƒ¨ï¼šæ—¥å¿—åŒºåŸŸ
        log_frame = ttk.LabelFrame(tab, text="æ“ä½œæ—¥å¿—", padding=10)
        log_frame.pack(fill=tk.X, padx=10, pady=5)
        
        self.video_output = scrolledtext.ScrolledText(log_frame, height=6)
        self.video_output.pack(fill=tk.BOTH, expand=True)
        
        # ç»‘å®šé…ç½®å˜åŒ–äº‹ä»¶
        # ç»‘å®šç¼–è¾‘äº‹ä»¶
        self.bind_edit_events()
        self.bind_config_change_events()

        
    def create_promo_video_tab(self):
        """Create promo video tab with drag & drop for MP3 files"""
        tab = ttk.Frame(self.notebook)
        self.notebook.add(tab, text="å®£ä¼ è§†é¢‘åˆ¶ä½œ333")

        # Instructions
        instruction_frame = ttk.Frame(tab)
        instruction_frame.pack(fill=tk.X, padx=10, pady=(10, 5))
        
        instruction_text = "å°†MP3éŸ³é¢‘æ–‡ä»¶æ‹–æ‹½åˆ°å·¦ä¾§åŒºåŸŸä»¥åˆ¶ä½œå®£ä¼ è§†é¢‘\nâ€¢ ç³»ç»Ÿå°†è‡ªåŠ¨ç”Ÿæˆå¸¦æœ‰éŸ³é¢‘çš„å®£ä¼ è§†é¢‘\nâ€¢ åœ¨å³ä¾§è¾“å…¥å­—å¹•è„šæœ¬ï¼ˆæ¯è¡Œä¸€å¥ï¼‰\nâ€¢ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨é¡¹ç›®çš„è¾“å‡ºç›®å½•ä¸­"
        ttk.Label(instruction_frame, text=instruction_text, font=('TkDefaultFont', 10), foreground='gray').pack()

        # Main content frame with three columns: drag area, story editor, and script area
        content_frame = ttk.Frame(tab)
        content_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

        # Middle: Story JSON Editor
        story_frame = ttk.LabelFrame(content_frame, text="æ•…äº‹JSONç¼–è¾‘å™¨", padding="10")
        story_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(5, 5))

        # Story JSON editor with undo/redo functionality
        self.promo_story_json_widget = scrolledtext.ScrolledText(story_frame, wrap=tk.WORD, font=('Consolas', 11), 
                                                               undo=True, maxundo=-1)
        self.promo_story_json_widget.pack(fill=tk.BOTH, expand=True)

        # Add undo/redo keyboard shortcuts for story editor
        self.promo_story_json_widget.bind('<Control-z>', self.promo_undo_action)
        self.promo_story_json_widget.bind('<Control-y>', self.promo_redo_action)
        self.promo_story_json_widget.bind('<Control-Shift-Z>', self.promo_redo_action)

        self.promo_load_story_content()

        # Right side: Script input area
        script_frame = ttk.LabelFrame(content_frame, text="å­—å¹•è„šæœ¬", padding="10")
        script_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(5, 5))

        # Script text area
        self.promo_script_text = scrolledtext.ScrolledText(script_frame, height=20, wrap=tk.WORD, font=('TkDefaultFont', 10))
        self.promo_script_text.pack(fill=tk.BOTH, expand=True)

        # Left side: Drop zone with wave image (reduced width)
        drop_frame = ttk.LabelFrame(content_frame, text="æ‹–æ‹½åŒºåŸŸ", padding="10")
        drop_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(5, 5))
        drop_frame.config(width=250)  # Fixed reduced width

        # Canvas for the wave image and drop zone
        self.promo_canvas = tk.Canvas(drop_frame, height=300, width=200, bg='white', relief=tk.RAISED, bd=2)
        self.promo_canvas.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # Load and display wave image
        self.load_promo_wave_image()

        # Setup drag and drop if available
        self.setup_promo_drag_drop()


        # Settings frame
        settings_frame = ttk.LabelFrame(tab, text="å®£ä¼ è§†é¢‘è®¾ç½®", padding="10")
        settings_frame.pack(fill=tk.X, padx=10, pady=5)

        # Settings display
        settings_info_frame = ttk.Frame(settings_frame)
        settings_info_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(settings_info_frame, text="å¼€å§‹æŒç»­æ—¶é—´: 10ç§’").pack(side=tk.LEFT, padx=(0, 20))
        ttk.Label(settings_info_frame, text="å›¾åƒæŒç»­æ—¶é—´: 5ç§’").pack(side=tk.LEFT, padx=(0, 20))
        ttk.Label(settings_info_frame, text="å­—å¹•: è‡ªåŠ¨ç”ŸæˆSRT").pack(side=tk.LEFT)

        # Voice and duration controls
        controls_frame = ttk.Frame(settings_frame)
        controls_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # æ—ç™½è¯­éŸ³ç»„
        narrator_frame = ttk.Frame(controls_frame)
        narrator_frame.pack(side=tk.LEFT, padx=(0, 15))
        ttk.Label(narrator_frame, text="æ—ç™½è¯­éŸ³").pack(side=tk.LEFT)
        narrator_controls = ttk.Frame(narrator_frame)
        narrator_controls.pack(side=tk.LEFT, padx=(5, 0))
        self.promo_actor_narrator = ttk.Combobox(narrator_controls, values=config.HOSTS, state="readonly", width=15)
        self.promo_actor_narrator.set(config.HOSTS[0])  # Default to voice1
        self.promo_actor_narrator.pack(side=tk.TOP)
        
        # add a text fields to keep the story scenarios duration, default to config.VIDEO_DURATION_DEFAULT
        duration_frame = ttk.Frame(controls_frame)
        duration_frame.pack(side=tk.LEFT, padx=(0, 15))
        ttk.Label(duration_frame, text="ç‰‡æ®µæ—¶é•¿").pack(side=tk.LEFT)
        duration_controls = ttk.Frame(duration_frame)
        duration_controls.pack(side=tk.LEFT, padx=(5, 0))
        self.promo_duration_entry = ttk.Entry(duration_controls, width=15)
        self.promo_duration_entry.insert(0, str(config.VIDEO_DURATION_DEFAULT))
        self.promo_duration_entry.pack(side=tk.TOP)

        # Action buttons frame
        action_frame = ttk.Frame(settings_frame)
        action_frame.pack(fill=tk.X, padx=5, pady=10)

        ttk.Button(action_frame, text="åŠ è½½æ•…äº‹", 
                  command=self.promo_load_story_content).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(action_frame, text="é‡æ–°ç”Ÿæˆå¯¹è¯", 
                  command=self.promo_on_regenerate_dialog).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(action_frame, text="ä¿å­˜JSON", 
                  command=self.promo_save_story_json_content).pack(side=tk.LEFT, padx=(0, 30))

        ttk.Button(action_frame, text="ç”ŸæˆéŸ³é¢‘", 
                  command=self.promo_on_generate_audio).pack(side=tk.LEFT, padx=(0, 30))

        ttk.Button(action_frame, text="ğŸ¬ å®£ä¼ çŸ­ç‰‡ç”Ÿæˆ", 
                  command=self.open_promo_video_gen_dialog, 
                  style="Accent.TButton").pack(side=tk.LEFT, padx=(0, 10))

        ttk.Button(action_frame, text="ğŸ¬ ä¸Šä¼ å®£ä¼ çŸ­ç‰‡", 
                  command=self.upload_promo_video, 
                  style="Accent.TButton").pack(side=tk.LEFT)

        # Output area
        output_frame = ttk.LabelFrame(tab, text="è¾“å‡ºæ—¥å¿—", padding="10")
        output_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

        self.promo_output = scrolledtext.ScrolledText(output_frame, height=10)
        self.promo_output.pack(fill=tk.BOTH, expand=True)

    def load_promo_wave_image(self):
        """Load and display the wave image in the promo canvas"""
        try:
            image_path = os.path.join(os.path.dirname(__file__), "media", "wave_sound.png")
            if os.path.exists(image_path):
                # Load and resize image to fit canvas
                pil_image = Image.open(image_path)
                # Calculate size to fit canvas while maintaining aspect ratio
                canvas_width = 400
                canvas_height = 250
                pil_image.thumbnail((canvas_width, canvas_height), Image.Resampling.LANCZOS)
                
                self.promo_wave_image = ImageTk.PhotoImage(pil_image)
                
                # Center image in canvas
                canvas_width_actual = self.promo_canvas.winfo_reqwidth() or 400
                canvas_height_actual = self.promo_canvas.winfo_reqheight() or 300
                x = canvas_width_actual // 2
                y = canvas_height_actual // 2
                
                self.promo_canvas.create_image(x, y, image=self.promo_wave_image, anchor=tk.CENTER)
                self.promo_canvas.create_text(x, y + 140, text="æ‹–æ‹½ MP3 éŸ³é¢‘æ–‡ä»¶åˆ°æ­¤å¤„", 
                                            font=('TkDefaultFont', 12, 'bold'), fill='gray')
            else:
                # Fallback if image not found
                self.promo_canvas.create_text(200, 150, text="æ‹–æ‹½ MP3 éŸ³é¢‘æ–‡ä»¶åˆ°æ­¤å¤„", 
                                            font=('TkDefaultFont', 14, 'bold'), fill='gray')
                self.promo_canvas.create_rectangle(50, 50, 350, 250, outline='gray', dash=(5, 5))
                
        except Exception as e:
            print(f"åŠ è½½æ³¢å½¢å›¾ç‰‡å¤±è´¥: {e}")
            # Fallback to text only
            self.promo_canvas.create_text(200, 150, text="æ‹–æ‹½ MP3 éŸ³é¢‘æ–‡ä»¶åˆ°æ­¤å¤„", 
                                        font=('TkDefaultFont', 14, 'bold'), fill='gray')
            self.promo_canvas.create_rectangle(50, 50, 350, 250, outline='gray', dash=(5, 5))

    def setup_promo_drag_drop(self):
        """Setup drag and drop functionality for the promo canvas and script text"""
        # Setup canvas drag & drop for audio files
        self.promo_canvas.drop_target_register(DND_FILES)
        self.promo_canvas.dnd_bind('<<Drop>>', self.on_promo_drop)
        self.promo_canvas.dnd_bind('<<DragEnter>>', self.on_promo_drag_enter)
        self.promo_canvas.dnd_bind('<<DragLeave>>', self.on_promo_drag_leave)
        
        # Setup script text drag & drop for text files
        self.promo_script_text.drop_target_register(DND_FILES)
        self.promo_script_text.dnd_bind('<<Drop>>', self.on_promo_script_drop)
        self.promo_script_text.dnd_bind('<<DragEnter>>', self.on_promo_script_drag_enter)
        self.promo_script_text.dnd_bind('<<DragLeave>>', self.on_promo_script_drag_leave)

    def on_promo_drag_enter(self, event):
        """Visual feedback when dragging enters promo canvas"""
        self.promo_canvas.configure(relief=tk.SUNKEN, bd=3)

    def on_promo_drag_leave(self, event):
        """Visual feedback when dragging leaves promo canvas"""
        self.promo_canvas.configure(relief=tk.RAISED, bd=2)

    def on_promo_click(self, event):
        """Fallback file selection when drag & drop not available"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©MP3éŸ³é¢‘æ–‡ä»¶",
            filetypes=(
                ("MP3éŸ³é¢‘æ–‡ä»¶", "*.mp3"),
                ("éŸ³é¢‘æ–‡ä»¶", "*.mp3 *.wav *.m4a *.flac *.aac"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            )
        )
        if file_path:
            self.process_promo_audio_file(file_path)

    def on_promo_script_drag_enter(self, event):
        """Visual feedback when dragging enters script text area"""
        self.promo_script_text.configure(relief=tk.SUNKEN, bd=2)

    def on_promo_script_drag_leave(self, event):
        """Visual feedback when dragging leaves script text area"""
        self.promo_script_text.configure(relief=tk.FLAT, bd=1)

    def on_promo_script_drop(self, event):
        """Handle text file drop event for script area"""
        files = event.data.split()
        if files:
            file_path = files[0]
            # Remove quotes if present
            if file_path.startswith('"') and file_path.endswith('"'):
                file_path = file_path[1:-1]
            self.process_promo_script_file(file_path)
        
        # Reset visual feedback
        self.promo_script_text.configure(relief=tk.FLAT, bd=1)


    def process_promo_script_file(self, file_path):
        """Process the dropped text file for script content"""
        if not os.path.exists(file_path):
            messagebox.showerror("é”™è¯¯", f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return

        # Check file extension for text files
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext not in ['.json', '.txt', '.srt', '.vtt', '.text', '.log']:
            messagebox.showerror("é”™è¯¯", f"ä¸æ”¯æŒçš„æ–‡æœ¬æ ¼å¼: {file_ext}\næ”¯æŒçš„æ ¼å¼: JSON, TXT, SRT, VTT, TEXT, LOG")
            return

        try:
            # Try different encodings
            encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin1']
            content = None
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                messagebox.showerror("é”™è¯¯", "æ— æ³•è¯»å–æ–‡ä»¶ï¼Œä¸æ”¯æŒçš„ç¼–ç æ ¼å¼")
                return
                
            # Ask user if they want to replace or append
            if self.promo_script_text.get(1.0, tk.END).strip():
                choice = messagebox.askyesnocancel("è„šæœ¬å†…å®¹", "å½“å‰å·²æœ‰è„šæœ¬å†…å®¹\n\næ˜¯ï¼šæ›¿æ¢ç°æœ‰å†…å®¹\nå¦ï¼šè¿½åŠ åˆ°æœ«å°¾\nå–æ¶ˆï¼šå–æ¶ˆæ“ä½œ")
                if choice is None:  # Cancel
                    return
                elif choice:  # Yes - Replace
                    self.promo_script_text.delete(1.0, tk.END)
                    self.promo_script_text.insert(1.0, content)
                else:  # No - Append
                    self.promo_script_text.insert(tk.END, "\n" + content)
            else:
                # Empty text area, just insert
                self.promo_script_text.insert(1.0, content)
                
            self.log_to_output(self.promo_output, f"ğŸ“ å·²åŠ è½½è„šæœ¬æ–‡ä»¶: {os.path.basename(file_path)}")
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")

    def load_promo_script_content(self):
        """è‡ªåŠ¨åŠ è½½å®£ä¼ è§†é¢‘è„šæœ¬å†…å®¹ä»promote SRTæ–‡ä»¶"""
        try:
            # è·å–promote SRTæ–‡ä»¶è·¯å¾„
            promote_srt_path = config.get_promote_srt_path(self.get_pid())
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(promote_srt_path):
                return
                
            # æ£€æŸ¥promo_script_textæ˜¯å¦å·²æœ‰å†…å®¹
            if self.promo_script_text.get(1.0, tk.END).strip():
                return  # å¦‚æœå·²æœ‰å†…å®¹ï¼Œä¸è‡ªåŠ¨è¦†ç›–
                
            # è¯»å–SRTæ–‡ä»¶å†…å®¹
            try:
                encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']
                content = None
                
                for encoding in encodings:
                    try:
                        with open(promote_srt_path, 'r', encoding=encoding) as f:
                            content = f.read()
                        break
                    except UnicodeDecodeError:
                        continue
                
                if content is None:
                    return
                    
                # ä»SRTå†…å®¹ä¸­æå–çº¯æ–‡æœ¬ï¼ˆå»é™¤æ—¶é—´æˆ³å’Œåºå·ï¼‰
                script_lines = []
                lines = content.split('\n')
                i = 0
                while i < len(lines):
                    line = lines[i].strip()
                    # è·³è¿‡ç©ºè¡Œ
                    if not line:
                        i += 1
                        continue
                    # è·³è¿‡æ•°å­—åºå·è¡Œ
                    if line.isdigit():
                        i += 1
                        continue
                    # è·³è¿‡æ—¶é—´æˆ³è¡Œ
                    if '-->' in line and ':' in line:
                        i += 1
                        continue
                    # è¿™æ˜¯å­—å¹•æ–‡æœ¬è¡Œ
                    if line:
                        script_lines.append(line)
                    i += 1
                
                if script_lines:
                    script_content = '\n'.join(script_lines)
                    self.promo_script_text.insert(1.0, script_content)
                    print(f"âœ… å·²è‡ªåŠ¨åŠ è½½å®£ä¼ è§†é¢‘è„šæœ¬å†…å®¹: {len(script_lines)} è¡Œ")
                    
            except Exception as e:
                print(f"âš ï¸ è¯»å–promote SRTæ–‡ä»¶å¤±è´¥: {e}")
                
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å®£ä¼ è§†é¢‘è„šæœ¬å†…å®¹å¤±è´¥: {e}")

    def on_promo_drop(self, event):
        """Handle file drop event for promo video"""
        files = event.data.split()
        if files:
            file_path = files[0]
            # Remove quotes if present
            if file_path.startswith('"') and file_path.endswith('"'):
                file_path = file_path[1:-1]
            self.process_promo_audio_file(file_path)
        
        # Reset visual feedback
        self.promo_canvas.configure(relief=tk.RAISED, bd=2)

    def process_promo_audio_file(self, file_path):
        """Process the dropped/selected audio file for promo video creation"""
        if not os.path.exists(file_path):
            messagebox.showerror("é”™è¯¯", f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return

        # Check file extension
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext not in ['.mp3', '.wav', '.m4a', '.flac', '.aac']:
            messagebox.showerror("é”™è¯¯", f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {file_ext}\næ”¯æŒçš„æ ¼å¼: MP3, WAV, M4A, FLAC, AAC")
            return

        # Get script text
        script_text = self.promo_script_text.get(1.0, tk.END).strip()
        has_subtitles = bool(script_text)

        # Confirm processing
        confirm_msg = f"ç¡®å®šè¦åˆ¶ä½œå®£ä¼ è§†é¢‘å—ï¼Ÿ\n\néŸ³é¢‘æ–‡ä»¶: {os.path.basename(file_path)}\nå¼€å§‹æŒç»­æ—¶é—´: 10ç§’\nå›¾åƒæŒç»­æ—¶é—´: 5ç§’\nå­—å¹•: {'æ˜¯' if has_subtitles else 'æ— '}"
        if script_text!="":
            # save script_text to config.get_promote_srt_path(self.get_pid())
            with open(config.get_promote_srt_path(self.get_pid()), 'w', encoding='utf-8') as f:
                f.write(script_text)

        if not messagebox.askyesno("ç¡®è®¤åˆ¶ä½œ", confirm_msg):
            return

        promo_duration = self.promo_duration_entry.get().strip()
        if promo_duration == "":
            promo_duration = None
        else:
            promo_duration = float(promo_duration)


        task_id = str(uuid.uuid4())
        self.tasks[task_id] = {
            "type": "create_promo_video",
            "status": "è¿è¡Œä¸­",
            "pid": self.get_pid(),
            "start_time": datetime.now()
        }

        def run_task():
            try:
                self.log_to_output(self.promo_output, f"ğŸ¬ å¼€å§‹åˆ¶ä½œå®£ä¼ è§†é¢‘...")
                self.log_to_output(self.promo_output, f"éŸ³é¢‘æ–‡ä»¶: {file_path}")
                self.log_to_output(self.promo_output, f"å¼€å§‹æŒç»­æ—¶é—´: 10ç§’")
                self.log_to_output(self.promo_output, f"å›¾åƒæŒç»­æ—¶é—´: 5ç§’")
                

                # Create promo video using workflow
                result = self.workflow.create_channel_promote_video(
                    promo_audio_path=file_path,
                    title=self.workflow.title,
                    program_keywords=self.project_keywords.get().strip(),
                    subtitle=script_text,
                    start_duration=10,
                    image_duration=5,
                    promo_duration=promo_duration
                )

                self.log_to_output(self.promo_output, f"âœ… å®£ä¼ è§†é¢‘åˆ¶ä½œå®Œæˆï¼")
                self.log_to_output(self.promo_output, f"è¾“å‡ºæ–‡ä»¶: {result}")
                self.tasks[task_id]["status"] = "å®Œæˆ"

                # Show success message
                success_msg = f"å®£ä¼ è§†é¢‘åˆ¶ä½œå®Œæˆï¼\n\nè¾“å‡ºæ–‡ä»¶: {result}"
                self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", success_msg))

            except Exception as e:
                error_msg = str(e)
                self.log_to_output(self.promo_output, f"âŒ å®£ä¼ è§†é¢‘åˆ¶ä½œå¤±è´¥: {error_msg}")
                self.tasks[task_id]["status"] = "å¤±è´¥"
                self.tasks[task_id]["error"] = error_msg
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"å®£ä¼ è§†é¢‘åˆ¶ä½œå¤±è´¥: {error_msg}"))

        # Run in separate thread
        thread = threading.Thread(target=run_task)
        thread.daemon = True
        thread.start()


    def log_to_output(self, output_widget, message):
        """å‘è¾“å‡ºæ§ä»¶å†™å…¥æ—¥å¿—ä¿¡æ¯"""
        if output_widget and hasattr(output_widget, 'insert'):
            timestamp = datetime.now().strftime("%H:%M:%S")
            output_widget.insert(tk.END, f"[{timestamp}] {message}\n")
            output_widget.see(tk.END)
            output_widget.update_idletasks()


    def start_status_update_timer(self):
        """å¯åŠ¨çŠ¶æ€æ›´æ–°å®šæ—¶å™¨"""
        # å¦‚æœå·²æœ‰å®šæ—¶å™¨ï¼Œå…ˆå–æ¶ˆ
        if self.status_update_timer_id is not None:
            self.root.after_cancel(self.status_update_timer_id)
        
        self.update_status_and_check_completion()
        # æ¯5ç§’æ›´æ–°ä¸€æ¬¡çŠ¶æ€ï¼Œå¹¶ä¿å­˜å®šæ—¶å™¨ID
        self.status_update_timer_id = self.root.after(5000, self.start_status_update_timer)


    def update_status_and_check_completion(self):
        """æ›´æ–°çŠ¶æ€å¹¶æ£€æŸ¥ä»»åŠ¡å®Œæˆæƒ…å†µ"""
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å®Œæˆçš„ä»»åŠ¡
        newly_completed = []
        for task_id, task_info in list(self.tasks.items()):
            if task_info["status"] in ["å®Œæˆ", "å¤±è´¥"] and task_id not in self.last_notified_tasks:
                newly_completed.append((task_id, task_info))
                self.last_notified_tasks.add(task_id)
                
                # å°†å®Œæˆçš„ä»»åŠ¡ç§»åˆ°å®Œæˆåˆ—è¡¨
                self.completed_tasks.append({
                    "id": task_id,
                    "info": task_info.copy(),
                    "completion_time": datetime.now()
                })
        
        # é€šçŸ¥æ–°å®Œæˆçš„ä»»åŠ¡
        for task_id, task_info in newly_completed:
            self.notify_task_completion(task_id, task_info)
        
        # æ£€æŸ¥ç”Ÿæˆçš„è§†é¢‘ï¼ˆåå°æŒç»­æ£€æŸ¥ï¼‰
        self.check_generated_videos_background()


    def start_video_check_thread(self):
        """å¯åŠ¨å•ä¾‹åå°è§†é¢‘æ£€æŸ¥çº¿ç¨‹"""
        if self.video_check_running:
            print("âš ï¸ åå°æ£€æŸ¥çº¿ç¨‹å·²åœ¨è¿è¡Œ")
            return
        
        self.video_check_running = True
        self.video_check_stop_event.clear()
        
        def video_check_loop():
            """å•ä¾‹åå°çº¿ç¨‹çš„ä¸»å¾ªç¯"""
            print("ğŸš€ å¯åŠ¨åå°è§†é¢‘æ£€æŸ¥çº¿ç¨‹")
            
            while not self.video_check_stop_event.is_set():
                try:
                    # æ‰§è¡Œæ£€æŸ¥ä»»åŠ¡
                    self._perform_video_check()
                    
                    # ç­‰å¾…5ç§’æˆ–ç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·
                    self.video_check_stop_event.wait(5)
                    
                except Exception as e:
                    print(f"âŒ åå°æ£€æŸ¥çº¿ç¨‹å‡ºé”™: {str(e)}")
                    # å‡ºé”™åç­‰å¾…5ç§’å†ç»§ç»­
                    self.video_check_stop_event.wait(5)
            
            print("ğŸ›‘ åå°è§†é¢‘æ£€æŸ¥çº¿ç¨‹å·²åœæ­¢")
            self.video_check_running = False
        
        # åˆ›å»ºå¹¶å¯åŠ¨daemonçº¿ç¨‹
        self.video_check_thread = threading.Thread(target=video_check_loop, daemon=True)
        self.video_check_thread.start()
    
    def stop_video_check_thread(self):
        """åœæ­¢åå°è§†é¢‘æ£€æŸ¥çº¿ç¨‹"""
        if self.video_check_running:
            print("ğŸ›‘ æ­£åœ¨åœæ­¢åå°è§†é¢‘æ£€æŸ¥çº¿ç¨‹...")
            self.video_check_stop_event.set()
            if self.video_check_thread:
                self.video_check_thread.join(timeout=2)
    

    def _perform_video_check(self):
        """æ‰§è¡Œè§†é¢‘æ£€æŸ¥ä»»åŠ¡ï¼ˆç”±å•ä¾‹çº¿ç¨‹è°ƒç”¨ï¼‰"""
        if not hasattr(self, 'workflow') or not self.workflow:
            return
        
        try:
            if not hasattr(self.workflow, 'scenarios') or not self.workflow.scenarios:
                return
            
            # éå†æ‰€æœ‰åœºæ™¯ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°ç”Ÿæˆçš„è§†é¢‘
            for scenario_index, scenario in enumerate(self.workflow.scenarios):
                if self.video_check_stop_event.is_set():
                    break
                
                try:
                    # 1. æ£€æŸ¥ /wan_video/output_mp4 ä¸­å·²å¢å¼ºçš„è§†é¢‘
                    self.workflow.check_generated_clip_video(scenario, "clip", "clip_audio")
                    self.workflow.check_generated_clip_video(scenario, "second", "second_audio")
                    self.workflow.check_generated_clip_video(scenario, "zero", "zero_audio")
                    
                    # 2. æ£€æŸ¥ X:\output ä¸­æ–°ç”Ÿæˆçš„åŸå§‹è§†é¢‘ï¼ˆç›‘æ§é€»è¾‘ï¼‰
                    #self._check_output_folder(scenario_index, scenario)
                except Exception as e:
                    # å¿½ç•¥å•ä¸ªåœºæ™¯çš„é”™è¯¯ï¼Œç»§ç»­æ£€æŸ¥å…¶ä»–åœºæ™¯
                    pass
        except Exception as e:
            # å¿½ç•¥æ•´ä½“é”™è¯¯
            pass
    
    def check_generated_videos_background(self):
        """å®šæ—¶å™¨è°ƒç”¨æ­¤æ–¹æ³•ï¼Œä½†ä¸å†åˆ›å»ºæ–°çº¿ç¨‹ï¼ˆå•ä¾‹çº¿ç¨‹å·²åœ¨è¿è¡Œï¼‰"""
        # æ£€æŸ¥å•ä¾‹çº¿ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œï¼Œå¦‚æœæ²¡æœ‰åˆ™é‡å¯
        if not self.video_check_running or not self.video_check_thread or not self.video_check_thread.is_alive():
            print("âš ï¸ æ£€æµ‹åˆ°åå°çº¿ç¨‹æœªè¿è¡Œï¼Œæ­£åœ¨é‡å¯...")
            self.start_video_check_thread()
    
    
    def _check_output_folder(self, scenario_index, scenario):
        """æ£€æŸ¥ X:\output æ–‡ä»¶å¤¹ä¸­çš„æ–°è§†é¢‘æ–‡ä»¶"""
        import glob
        import time
        
        clip_animation = scenario.get("clip_animation", "")
        if clip_animation not in ["S2V", "FS2V", "WS2V", "2I2V", "I2V", "AI2V"]:
            # ä¸éœ€è¦ç›‘æ§çš„åœºæ™¯ï¼Œæ¸…ç†ç›‘æ§è®°å½•
            if scenario_index in self.monitoring_scenarios:
                del self.monitoring_scenarios[scenario_index]
            return
        
        output_folder = "X:\\output"
        if not os.path.exists(output_folder):
            return
        
        scenario_id = scenario.get('id', '')
        
        # åˆå§‹åŒ–ç›‘æ§è®°å½•
        if scenario_index not in self.monitoring_scenarios:
            self.monitoring_scenarios[scenario_index] = {
                "found_files": [],
                "start_time": time.time()
            }
        
        monitor_info = self.monitoring_scenarios[scenario_index]
        
        # æŒç»­ç›‘æ§ï¼Œä¸è®¾ç½®è¶…æ—¶é™åˆ¶ï¼Œç›´åˆ°GUIé€€å‡ºæˆ–æ‰¾åˆ°æ–‡ä»¶
        
        try:
            if clip_animation in ["S2V", "FS2V", "PS2V", "I2V", "2I2V", "AI2V"]:
                # æŸ¥æ‰¾ä»¥åœºæ™¯IDå¼€å¤´çš„mp4æ–‡ä»¶
                if clip_animation == "I2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_I2V_*.mp4")
                elif clip_animation == "2I2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_2I2V_*.mp4")
                elif clip_animation == "S2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_S2V_*-audio.mp4")
                elif clip_animation == "FS2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_FS2V_*-audio.mp4")
                elif clip_animation == "PS2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_PS2V_*-audio.mp4")
                elif clip_animation == "AI2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_AI2V_*.mp4")

                left_files = glob.glob(pattern)
                
                if not monitor_info["found_files"]:
                    monitor_info["found_files"] = left_files
                    return
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶
                new_files = [f for f in left_files if f not in monitor_info["found_files"] and f not in self.processed_output_files]
                if new_files:
                    for file_path in new_files:
                        print(f"ğŸ¬ å‘ç°æ–°è§†é¢‘æ–‡ä»¶: {os.path.basename(file_path)}")
                        monitor_info["found_files"].append(file_path)
                        self.processed_output_files.add(file_path)
                    
                    # åœ¨ä¸»çº¿ç¨‹ä¸­å¤„ç†æ–‡ä»¶
                    self.root.after(0, lambda idx=scenario_index, files=new_files: 
                        self._process_output_files(idx, files, "single"))
                    
                    # å¤„ç†å®Œæˆï¼Œç§»é™¤ç›‘æ§
                    del self.monitoring_scenarios[scenario_index]
            
            elif clip_animation == "WS2V":
                pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_L_WS2V_*-audio.mp4")
                left_files = glob.glob(pattern)

                pattern = os.path.join(output_folder, f"{self.get_pid()}_{scenario_id}_R_WS2V_*-audio.mp4")
                right_files = glob.glob(pattern)
                
                # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ–‡ä»¶
                new_left_files = [f for f in left_files if f not in self.processed_output_files]
                new_right_files = [f for f in right_files if f not in self.processed_output_files]
                
                # æ£€æŸ¥æ˜¯å¦ä¸¤è¾¹éƒ½æœ‰æ–‡ä»¶
                if new_left_files and new_right_files:
                    # æ’åºç¡®ä¿é…å¯¹çš„ä¸€è‡´æ€§
                    new_left_files.sort()
                    new_right_files.sort()
                    
                    # å–æ¯ç»„çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶
                    left_file = new_left_files[0]
                    right_file = new_right_files[0]
                    
                    print(f"ğŸ¬ å‘ç°å·¦ä¾§è§†é¢‘: {os.path.basename(left_file)}")
                    print(f"ğŸ¬ å‘ç°å³ä¾§è§†é¢‘: {os.path.basename(right_file)}")
                    
                    # å°†è¿™ä¸¤ä¸ªæ–‡ä»¶æ”¾å…¥ found_files
                    files_to_process = [left_file, right_file]
                    
                    # æ ‡è®°æ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶ä¸ºå·²å¤„ç†ï¼ˆä¸ä»…æ˜¯é…å¯¹çš„ä¸¤ä¸ªï¼‰
                    for file_path in left_files + right_files:
                        self.processed_output_files.add(file_path)
                    
                    # åœ¨ä¸»çº¿ç¨‹ä¸­å¤„ç†æ–‡ä»¶
                    self.root.after(0, lambda idx=scenario_index, files=files_to_process: 
                        self._process_output_files(idx, files, "dual"))
                    
                    # å¤„ç†å®Œæˆï¼Œç§»é™¤ç›‘æ§
                    del self.monitoring_scenarios[scenario_index]
        
        except Exception as e:
            print(f"âŒ æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
    
    def _process_output_files(self, scenario_index, files, file_type):
        """å¤„ç†ä» X:\output å‘ç°çš„æ–‡ä»¶"""
        try:
            if scenario_index >= len(self.workflow.scenarios):
                return
            
            scenario = self.workflow.scenarios[scenario_index]
            
            if file_type == "single":
                self.workflow._process_single_files(scenario, files)
            elif file_type == "dual":
                self.workflow._process_dual_files(scenario, files)
            
            # å¤„ç†å®Œæˆååˆ·æ–°GUI
            self.root.after(0, lambda: self.refresh_gui_scenarios())
            
        except Exception as e:
            print(f"âŒ å¤„ç†è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    

    def notify_task_completion(self, task_id, task_info):
        """é€šçŸ¥ä»»åŠ¡å®Œæˆ"""
        task_type = task_info.get("type", "æœªçŸ¥ä»»åŠ¡")
        task_status = task_info.get("status", "æœªçŸ¥çŠ¶æ€")
        pid = task_info.get("pid", "")
        
        if task_status == "å®Œæˆ":
            title = "âœ… ä»»åŠ¡å®Œæˆ"
            message = f"ä»»åŠ¡ç±»å‹: {task_type}\né¡¹ç›®ID: {pid}\nçŠ¶æ€: æˆåŠŸå®Œæˆ"
            if "result" in task_info:
                message += f"\nç»“æœ: {task_info['result']}"
        else:
            title = "âŒ ä»»åŠ¡å¤±è´¥"
            message = f"ä»»åŠ¡ç±»å‹: {task_type}\né¡¹ç›®ID: {pid}\nçŠ¶æ€: æ‰§è¡Œå¤±è´¥"
            if "error" in task_info:
                message += f"\né”™è¯¯: {task_info['error']}"
        
        # æ˜¾ç¤ºé€šçŸ¥å¯¹è¯æ¡†
        messagebox.showinfo(title, message)


    def run_finalize_video(self, zero_audio_only):
        pid = self.get_pid()
        task_id = str(uuid.uuid4())
        self.tasks[task_id] = {
            "type": "video_finalize",
            "status": "è¿è¡Œä¸­",
            "start_time": datetime.now(),
            "pid": pid
        }

        def run_task():
            try:
                self.workflow.finalize_video(self.video_title.get().strip(), "", zero_audio_only) #self.program_keywords.get().strip())
                self.log_to_output(self.video_output, "âœ… æœ€ç»ˆè§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                self.tasks[task_id]["status"] = "å®Œæˆ"
            except Exception as e:
                self.log_to_output(self.video_output, f"âŒ æœ€ç»ˆè§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
                self.tasks[task_id]["status"] = "å¤±è´¥"
                self.tasks[task_id]["error"] = str(e)

        threading.Thread(target=run_task, daemon=True).start()


    def run_upload_video(self):
        """ä¸Šä¼ è§†é¢‘åˆ°YouTubeï¼ˆæˆ–å…¶ä»–å¹³å°ï¼‰"""
        pid = self.get_pid()
        title = self.video_title.get().strip()

        if not pid:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥é¡¹ç›®ID")
            return

        task_id = str(uuid.uuid4())
        self.tasks[task_id] = {
            "type": "upload_video",
            "status": "è¿è¡Œä¸­",
            "start_time": datetime.now(),
            "pid": pid
        }

        def run_task():
            try:
                self.log_to_output(self.video_output, f"å¼€å§‹ä¸Šä¼ è§†é¢‘ - PID: {pid}")
                workflow = self.workflow
                if workflow is None:
                    raise Exception("æ— æ³•è·å–å·¥ä½œæµå¯¹è±¡")

                workflow.upload_video(title)
                self.log_to_output(self.video_output, "âœ… è§†é¢‘ä¸Šä¼ å®Œæˆï¼")
                self.tasks[task_id]["status"] = "å®Œæˆ"
            except Exception as e:
                self.log_to_output(self.video_output, f"âŒ è§†é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}")
                self.tasks[task_id]["status"] = "å¤±è´¥"
                self.tasks[task_id]["error"] = str(e)

        threading.Thread(target=run_task, daemon=True).start()


    def _cleanup_video_before_switch(self):
        """åˆ‡æ¢åœºæ™¯å‰æ¸…ç†è§†é¢‘èµ„æº"""
        # åœæ­¢è§†é¢‘æ’­æ”¾
        if self.video_playing:
            self.stop_video_playback()
        
        # æ¸…ç†è§†é¢‘æ•è·å¯¹è±¡
        if self.video_cap:
            self.video_cap.release()
            self.video_cap = None
        
        # å–æ¶ˆå®šæ—¶å™¨
        if self.video_after_id:
            self.root.after_cancel(self.video_after_id)
            self.video_after_id = None
        
        # åœæ­¢éŸ³é¢‘
        self.stop_audio_playback()
        
        # é‡ç½®æ’­æ”¾çŠ¶æ€
        self.video_playing = False
        self.video_play_button.config(text="â–¶")
        
        # æ›´æ–°è§†é¢‘è¿›åº¦æ˜¾ç¤º
        self.update_video_progress_display()
        
        # æ¸…ç©ºç”»å¸ƒ
        self.video_canvas.delete("all")
        
        # é‡ç½®è§†é¢‘ç›¸å…³å˜é‡
        self.video_start_time = None
        self.video_pause_time = None
        
        # æ¸…ç†å›¾ç‰‡å¼•ç”¨ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        if hasattr(self, 'current_video_frame'):
            self.current_video_frame = None


    def clear_video_scenario_fields(self):
        self.scenario_duration.config(state="normal")
        self.scenario_duration.delete(0, tk.END)
        self.scenario_duration.config(state="readonly")
        
        self.clear_video_preview()


    def load_video_first_frame(self):
        self._cleanup_video_before_switch()

        current_scenario = self.get_current_scenario()
            
        video_path = get_file_path(current_scenario, "clip")
        if not video_path:
            return

        if not video_path:
            self.clear_video_preview()
            return
            
        try:
            self.video_canvas.delete("all")
            
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                cap.release()
                self.clear_video_preview()
                return
            
            ret, frame = cap.read()
            cap.release()
            
            if ret and frame is not None:
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                pil_image = Image.fromarray(frame_rgb)
                
                canvas_width = self.video_canvas.winfo_width()
                canvas_height = self.video_canvas.winfo_height()
                
                if canvas_width > 1 and canvas_height > 1:  # ç¡®ä¿ç”»å¸ƒå·²ç»åˆå§‹åŒ–
                    pil_image.thumbnail((canvas_width - 10, canvas_height - 10), Image.Resampling.LANCZOS)
                else:
                    pil_image.thumbnail((630, 350), Image.Resampling.LANCZOS)
                
                # è½¬æ¢ä¸ºTkinterå¯ç”¨çš„æ ¼å¼
                self.current_video_frame = ImageTk.PhotoImage(pil_image)
                
                # åœ¨ç”»å¸ƒä¸­å¤®æ˜¾ç¤ºå›¾åƒ
                self.video_canvas.delete("all")
                canvas_width = self.video_canvas.winfo_width() or 640
                canvas_height = self.video_canvas.winfo_height() or 360
                x = canvas_width // 2
                y = canvas_height // 2
                
                # ç¡®ä¿å›¾åƒå¯¹è±¡å­˜åœ¨åå†åˆ›å»ºç”»å¸ƒå›¾åƒ
                if self.current_video_frame:
                    try:
                        self.video_canvas.create_image(x, y, anchor=tk.CENTER, image=self.current_video_frame)
                    except tk.TclError as e:
                        # å¦‚æœå›¾åƒå¯¹è±¡æ— æ•ˆï¼Œé‡æ–°åˆ›å»º
                        print(f"âš ï¸ å›¾åƒå¯¹è±¡æ— æ•ˆï¼Œé‡æ–°åˆ›å»º: {e}")
                        self.current_video_frame = ImageTk.PhotoImage(pil_image)
                        self.video_canvas.create_image(x, y, anchor=tk.CENTER, image=self.current_video_frame)
                
                self.video_canvas.create_text(x, y + pil_image.height//2 + 20, 
                                            text="ç‚¹å‡» 'â–¶ æ’­æ”¾' å¼€å§‹æ’­æ”¾è§†é¢‘", 
                                            fill="white", font=("Arial", 12))
                
                self.video_canvas.create_text(x, y + pil_image.height//2 + 40, 
                                            text="ğŸ’¡ æ‹–æ‹½MP4æ–‡ä»¶å¯æ›¿æ¢æ­¤è§†é¢‘", 
                                            fill="gray", font=("Arial", 10))
            else:
                self.clear_video_preview()
                self.log_to_output(self.video_output, f"âŒ æ— æ³•è¯»å–è§†é¢‘ç¬¬ä¸€å¸§")
                
        except Exception as e:
            self.clear_video_preview()
            self.log_to_output(self.video_output, f"âŒ åŠ è½½è§†é¢‘é¢„è§ˆå¤±è´¥: {str(e)}")


    def clear_video_preview(self):
        """æ¸…ç©ºè§†é¢‘é¢„è§ˆ"""
        # å…ˆæ¸…ç†å›¾ç‰‡å¼•ç”¨ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        if hasattr(self, 'current_video_frame'):
            self.current_video_frame = None
        
        # æ¸…ç©ºç”»å¸ƒ
        self.video_canvas.delete("all")
        
        # æ˜¾ç¤ºæç¤ºæ–‡æœ¬
        canvas_width = self.video_canvas.winfo_width() or 640
        canvas_height = self.video_canvas.winfo_height() or 360
        x = canvas_width // 2
        y = canvas_height // 2
        
        self.video_canvas.create_text(x, y, text="é€‰æ‹©åœºæ™¯åä¼šæ˜¾ç¤ºè§†é¢‘é¢„è§ˆ\n\nğŸ’¡ å¯ä»¥æ‹–æ‹½MP4æ–‡ä»¶åˆ°æ­¤å¤„æ›¿æ¢è§†é¢‘ç‰‡æ®µ", fill="white", 
                                    font=("Arial", 12), justify=tk.CENTER, tags="no_video_hint")


    def toggle_video_playback(self):
        current_scenario = self.get_current_scenario()
        video_path = None
        if current_scenario:
            video_path = get_file_path(current_scenario, "clip")
            
        if not video_path:
            self.log_to_output(self.video_output, "âŒ æ²¡æœ‰å¯æ’­æ”¾çš„è§†é¢‘æ–‡ä»¶")
            return
            
        if self.video_playing:
            self.pause_video()
        else:
            # å¦‚æœæ˜¯ä»æš‚åœçŠ¶æ€æ¢å¤ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if self.video_cap is not None:
                self.video_playing = True
                self.video_play_button.config(text="â¸")
                # é‡æ–°è®¾ç½®å¼€å§‹æ—¶é—´ï¼Œè€ƒè™‘ä¹‹å‰æš‚åœçš„æ—¶é—´
                self.video_start_time = time.time()
                self.resume_audio_playback()
                print(f"â–¶ï¸ æ¢å¤æ’­æ”¾ï¼Œå·²æ’­æ”¾æ—¶é—´: {self.video_pause_time or 0:.2f}ç§’")
                self.play_next_frame()
            else:
                self.play_video()


    def play_video(self):
        """æ’­æ”¾è§†é¢‘"""
        current_scenario = self.get_current_scenario()
        video_path = None
        if current_scenario:
            video_path = get_file_path(current_scenario, "clip")
            
        if not video_path:
            return

        if self.video_cap is None:
            self.video_cap = cv2.VideoCapture(video_path)
            
        if not self.video_cap.isOpened():
            self.log_to_output(self.video_output, "âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            return
            
        self.video_playing = True
        self.video_play_button.config(text="â¸")
        
        # è®°å½•æ’­æ”¾å¼€å§‹æ—¶é—´ï¼Œé‡ç½®æš‚åœæ—¶é—´
        self.video_start_time = time.time()
        self.video_pause_time = None  # é‡ç½®æš‚åœæ—¶é—´
        
        # å¼€å§‹æ’­æ”¾éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
        self.start_audio_playback()
        
        self.play_next_frame()


    def start_audio_playback(self):
        clip = get_file_path(self.get_current_scenario(), "clip_audio")
        if not clip:
            return
        pygame.mixer.music.load(clip)
        pygame.mixer.music.play()

    def pause_audio_playback(self):
        pygame.mixer.music.pause()

    def resume_audio_playback(self):
        pygame.mixer.music.unpause()

    def stop_audio_playback(self):
        pygame.mixer.music.stop()
    

    def pause_video(self):
        """æš‚åœè§†é¢‘"""
        self.video_playing = False
        self.video_play_button.config(text="â–¶")
        if self.video_after_id:
            self.root.after_cancel(self.video_after_id)
            self.video_after_id = None
        
        # è®°å½•æš‚åœæ—¶å·²æ’­æ”¾çš„æ—¶é—´
        if self.video_start_time:
            elapsed = time.time() - self.video_start_time
            self.video_pause_time = (self.video_pause_time or 0) + elapsed
            
        # æš‚åœéŸ³é¢‘
        self.pause_audio_playback()
        print(f"â¸ï¸ è§†é¢‘æš‚åœï¼Œæ€»æ’­æ”¾æ—¶é—´: {self.video_pause_time or 0:.2f}ç§’")

    def stop_video_playback(self):
        """åœæ­¢è§†é¢‘æ’­æ”¾"""
        self.video_playing = False
        self.video_play_button.config(text="â–¶")
        
        if self.video_after_id:
            self.root.after_cancel(self.video_after_id)
            self.video_after_id = None
            
        if self.video_cap:
            self.video_cap.release()
            self.video_cap = None
            
        # åœæ­¢éŸ³é¢‘
        self.stop_audio_playback()
            
        # é‡ç½®æ—¶é—´ç›¸å…³å˜é‡
        self.video_start_time = None
        self.video_pause_time = None
            
        self.refresh_gui_scenarios()


    def play_next_frame(self):
        """æ’­æ”¾ä¸‹ä¸€å¸§"""
        if not self.video_playing or not self.video_cap:
            return
        
        # é¦–å…ˆæ£€æŸ¥éŸ³é¢‘æ˜¯å¦è¿˜åœ¨æ’­æ”¾
        audio_is_playing = pygame.mixer.music.get_busy()
        if not audio_is_playing:
            # éŸ³é¢‘æ’­æ”¾å®Œæ¯•ï¼Œåœæ­¢è§†é¢‘
            self.stop_video_playback()
            self.log_to_output(self.video_output, "âœ… éŸ³é¢‘æ’­æ”¾å®Œæ¯•ï¼Œè§†é¢‘åŒæ­¥åœæ­¢")
            return
            
        # è®¡ç®—åº”è¯¥æ’­æ”¾çš„å¸§ä½ç½®ä»¥ä¿æŒä¸éŸ³é¢‘åŒæ­¥
        total_frames = self.video_cap.get(cv2.CAP_PROP_FRAME_COUNT)
        
        if self.video_start_time:
            # è®¡ç®—å®é™…ç»è¿‡çš„æ—¶é—´
            elapsed_time = time.time() - self.video_start_time
            current_time = elapsed_time + (self.video_pause_time or 0)
            
            # è®¡ç®—åº”è¯¥åœ¨ç¬¬å‡ å¸§ (æ­£å¸¸1å€é€Ÿæ’­æ”¾)
            target_frame = int(current_time * self.STANDARD_FPS)
            current_frame = int(self.video_cap.get(cv2.CAP_PROP_POS_FRAMES))
            
            # å¦‚æœè§†é¢‘å¸§è½åäºéŸ³é¢‘è¿›åº¦ï¼Œè·³å¸§è¿½èµ¶
            if target_frame > current_frame + 2:  # å…è®¸2å¸§çš„å®¹é”™
                self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
        
        ret, frame = self.video_cap.read()
        
        if ret:
            # è½¬æ¢é¢œè‰²æ ¼å¼
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(frame_rgb)
            
            # è°ƒæ•´å›¾åƒå¤§å°
            canvas_width = self.video_canvas.winfo_width()
            canvas_height = self.video_canvas.winfo_height()
            
            if canvas_width > 1 and canvas_height > 1:
                pil_image.thumbnail((canvas_width - 10, canvas_height - 10), Image.Resampling.LANCZOS)
            else:
                pil_image.thumbnail((630, 350), Image.Resampling.LANCZOS)
            
            # æ›´æ–°ç”»å¸ƒ
            self.current_video_frame = ImageTk.PhotoImage(pil_image)
            self.video_canvas.delete("all")
            
            canvas_width = canvas_width or 640
            canvas_height = canvas_height or 360
            x = canvas_width // 2
            y = canvas_height // 2
            
            # ç¡®ä¿å›¾åƒå¯¹è±¡å­˜åœ¨åå†åˆ›å»ºç”»å¸ƒå›¾åƒ
            if self.current_video_frame:
                try:
                    self.video_canvas.create_image(x, y, anchor=tk.CENTER, image=self.current_video_frame)
                except tk.TclError as e:
                    # å¦‚æœå›¾åƒå¯¹è±¡æ— æ•ˆï¼Œé‡æ–°åˆ›å»º
                    print(f"âš ï¸ å›¾åƒå¯¹è±¡æ— æ•ˆï¼Œé‡æ–°åˆ›å»º: {e}")
                    self.current_video_frame = ImageTk.PhotoImage(pil_image)
                    self.video_canvas.create_image(x, y, anchor=tk.CENTER, image=self.current_video_frame)
            
            # æ›´æ–°è¿›åº¦æ˜¾ç¤º - ä½¿ç”¨éŸ³é¢‘å®é™…æ—¶é•¿
            if self.video_start_time:
                elapsed_time = time.time() - self.video_start_time
                current_time = elapsed_time + (self.video_pause_time or 0)
            else:
                current_frame = self.video_cap.get(cv2.CAP_PROP_POS_FRAMES)
                current_time = current_frame / self.STANDARD_FPS
            
            # è·å–éŸ³é¢‘å®é™…æ—¶é•¿
            current_scenario = self.get_current_scenario()
            total_time = self.workflow.find_clip_duration(current_scenario)
            if total_time <= 0:
                total_time = total_frames / self.STANDARD_FPS
            
            # ç¡®ä¿ä¸è¶…è¿‡æ€»æ—¶é•¿
            if current_time > total_time:
                current_time = total_time
            
            current_min = int(current_time // 60)
            current_sec = int(current_time % 60)
            total_min = int(total_time // 60)
            total_sec = int(total_time % 60)
            
            self.video_progress_label.config(text=f"{current_min:02d}:{current_sec:02d} / {total_min:02d}:{total_sec:02d}")
            
            # è®¡ç®—ä¸‹ä¸€å¸§çš„å»¶è¿Ÿæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰- æ­£å¸¸1å€æ’­æ”¾é€Ÿåº¦
            delay = int(1000 / self.STANDARD_FPS)  # æ­£å¸¸æ’­æ”¾é€Ÿåº¦
            self.video_after_id = self.root.after(delay, self.play_next_frame)

        else:
            # è§†é¢‘æ–‡ä»¶è¯»å–å®Œæ¯•ï¼Œä½†ä»éœ€ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ
            if audio_is_playing:
                # é‡æ–°å¼€å§‹è§†é¢‘å¾ªç¯æ’­æ”¾ä»¥é…åˆéŸ³é¢‘
                self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                self.video_after_id = self.root.after(33, self.play_next_frame)
                print("ğŸ”„ è§†é¢‘å¾ªç¯æ’­æ”¾ä»¥ç­‰å¾…éŸ³é¢‘å®Œæˆ")
            else:
                self.stop_video_playback()
                self.log_to_output(self.video_output, "âœ… è§†é¢‘æ’­æ”¾å®Œæ¯•")


    def refresh_gui_scenarios(self):
        """åˆ·æ–°åœºæ™¯åˆ—è¡¨"""
        # self.workflow.load_scenarios()
        if self.current_scenario_index >= len(self.workflow.scenarios) :
            self.current_scenario_index = 0

        # æ¸…ç†æ‰€æœ‰è½¨é“çš„ VideoCaptureï¼ˆé¿å…ä½¿ç”¨æ—§åœºæ™¯çš„è§†é¢‘ï¼‰
        self.cleanup_track_video_captures()

        # æ£€æŸ¥ç°æœ‰å›¾åƒ
        self.update_scenario_display()
        
        # æ›´æ–°è§†é¢‘è¿›åº¦æ˜¾ç¤º
        self.update_video_progress_display()

        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        self.update_scenario_buttons_state()

        self.reset_second_track_playing_offset()

        # å»¶è¿ŸåŠ è½½ç¬¬ä¸€å¸§ï¼Œç¡®ä¿canvaså·²å®Œå…¨æ¸²æŸ“
        self.root.after(100, self.load_all_first_frames)


    
    def cleanup_track_video_captures(self):
        if hasattr(self, 'second_track_cap') and self.second_track_cap:
            try:
                self.second_track_cap.release()
            except:
                pass
            self.second_track_cap = None
        
        # é‡ç½®ç¬¬äºŒè½¨é“çš„æ’­æ”¾çŠ¶æ€
        if hasattr(self, 'second_track_playing'):
            self.second_track_playing = False
        if hasattr(self, 'second_track_after_id') and self.second_track_after_id:
            try:
                self.root.after_cancel(self.second_track_after_id)
            except:
                pass
            self.second_track_after_id = None
        
        # æ¸…ç† PIP å·¦å³è½¨é“
        if hasattr(self, 'pip_left_cap') and self.pip_left_cap:
            try:
                self.pip_left_cap.release()
            except:
                pass
            self.pip_left_cap = None
            
        if hasattr(self, 'pip_right_cap') and self.pip_right_cap:
            try:
                self.pip_right_cap.release()
            except:
                pass
            self.pip_right_cap = None
        
        # é‡ç½® PIP çš„æ’­æ”¾çŠ¶æ€
        if hasattr(self, 'pip_lr_playing'):
            self.pip_lr_playing = False
        if hasattr(self, 'pip_lr_after_id') and self.pip_lr_after_id:
            try:
                self.root.after_cancel(self.pip_lr_after_id)
            except:
                pass
            self.pip_lr_after_id = None


    def load_all_first_frames(self):
        """åŠ è½½æ‰€æœ‰è½¨é“çš„ç¬¬ä¸€å¸§"""
        self.load_video_first_frame()
        
        # åŠ è½½æ‰€æœ‰å›¾ç‰‡é¢„è§ˆ
        if hasattr(self, 'clip_image_canvas'):
            self.load_all_images_preview()
        
        # æ ¹æ®å½“å‰é€‰ä¸­çš„tabåŠ è½½è½¨é“è§†é¢‘é¢„è§ˆ
        current_tab_index = self.second_notebook.index(self.second_notebook.select())
        if current_tab_index == 0:
            self.load_second_track_first_frame()
        elif current_tab_index == 1:
            self.load_pip_lr_first_frame()


    def load_second_track_first_frame(self):
        track_path = get_file_path(self.get_current_scenario(), self.selected_second_track)

        """åŠ è½½ç¬¬äºŒè½¨é“è§†é¢‘çš„ç¬¬ä¸€å¸§åˆ°ç”»å¸ƒ"""
        try:
            self.second_track_canvas.delete("all")

            if not track_path:
                # æ¸…é™¤ç”»å¸ƒæ˜¾ç¤ºæç¤ºä¿¡æ¯
                self.second_track_canvas.create_text(160, 90, text="ç¬¬äºŒè½¨é“è§†é¢‘é¢„è§ˆ\né€‰æ‹©è§†é¢‘åæ’­æ”¾æ˜¾ç¤º",
                                                   fill='white', font=('Arial', 12), 
                                                   justify=tk.CENTER, tags="hint")
                self.track_time_label.config(text="00:00 / 00:00")
                return
            
            # æ‰“å¼€è§†é¢‘æ–‡ä»¶è·å–ç¬¬ä¸€å¸§
            temp_cap = cv2.VideoCapture(track_path)
            if not temp_cap.isOpened():
                print(f"âŒ æ— æ³•æ‰“å¼€ç¬¬äºŒè½¨é“è§†é¢‘æ–‡ä»¶: {track_path}")
                return
            
            ret, frame = temp_cap.read()
            if ret:
                # æ˜¾ç¤ºç¬¬ä¸€å¸§åˆ°Canvas
                from PIL import Image, ImageTk
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(frame_rgb)
                
                # è°ƒæ•´å›¾åƒå¤§å°é€‚åº”Canvas
                canvas_width = self.second_track_canvas.winfo_width()
                canvas_height = self.second_track_canvas.winfo_height()
                
                if canvas_width > 1 and canvas_height > 1:
                    pil_image.thumbnail((canvas_width - 10, canvas_height - 10), Image.Resampling.LANCZOS)
                else:
                    pil_image.thumbnail((310, 170), Image.Resampling.LANCZOS)
                
                # æ›´æ–°ç”»å¸ƒæ˜¾ç¤ºç¬¬ä¸€å¸§
                self.current_second_track_frame = ImageTk.PhotoImage(pil_image)
                
                canvas_width = canvas_width or 320
                canvas_height = canvas_height or 180
                x = canvas_width // 2
                y = canvas_height // 2
                self.second_track_canvas.create_image(x, y, anchor=tk.CENTER, image=self.current_second_track_frame)
                
            # æ›´æ–°æ—¶é—´æ˜¾ç¤º
            total_frames = temp_cap.get(cv2.CAP_PROP_FRAME_COUNT)
            total_duration = total_frames / self.STANDARD_FPS
            total_str = f"{int(total_duration // 60):02d}:{int(total_duration % 60):02d}"
            self.track_time_label.config(text=f"00:00 / {total_str}")
            
            temp_cap.release()
            print(f"âœ… å·²åŠ è½½ç¬¬äºŒè½¨é“è§†é¢‘ç¬¬ä¸€å¸§: {os.path.basename(track_path)}")

        except Exception as e:
            print(f"âŒ åŠ è½½ç¬¬äºŒè½¨é“è§†é¢‘ç¬¬ä¸€å¸§å¤±è´¥: {e}")
            self.second_track_canvas.delete("all")
            self.second_track_canvas.create_text(160, 90, text="ç¬¬äºŒè½¨é“è§†é¢‘é¢„è§ˆ\né€‰æ‹©è§†é¢‘åæ’­æ”¾æ˜¾ç¤º",
                                               fill='white', font=('Arial', 12), 
                                               justify=tk.CENTER, tags="hint")


    def update_scenario_display(self):
        """æ›´æ–°åœºæ™¯æ˜¾ç¤º"""
        if len(self.workflow.scenarios) == 0:
            self.scenario_label.config(text="0 / 0")
            self.clear_scenario_fields()
            self.clear_video_scenario_fields()
            return
            
        self.scenario_label.config(text=f"{self.current_scenario_index + 1} / {len(self.workflow.scenarios)}")
        scenario_data = self.get_current_scenario()
        if not scenario_data:
            return
        
        # æ˜¾ç¤ºæŒç»­æ—¶é—´
        self.scenario_duration.config(state="normal")
        self.scenario_duration.delete(0, tk.END)
        duration = self.workflow.find_clip_duration(scenario_data)
        self.scenario_duration.insert(0, f"{duration:.2f} ç§’")
        self.scenario_duration.config(state="readonly")
        
        # è®¾ç½®å®£ä¼ å¤é€‰æ¡†çŠ¶æ€
        clip_animation = scenario_data.get("clip_animation", "")
        self.scenario_main_animate.set(clip_animation)
        
        # åŠ è½½å½“å‰åœºæ™¯çš„æ•ˆæœè®¾ç½® - ç›´æ¥ä»scenarios JSONä¸­è¯»å–
        current_effect = scenario_data.get("effect", config.SPECIAL_EFFECTS[0])
        self.current_effect_var.set(current_effect)
        
        # åŠ è½½å½“å‰åœºæ™¯çš„å›¾åƒç±»å‹è®¾ç½®
        current_image_type = scenario_data.get("second_animation", config.ANIMATE_TYPES[0])
        self.scenario_second_animation.set(current_image_type)
        
        self.scenario_story_expression.delete("1.0", tk.END)
        self.scenario_story_expression.insert("1.0", scenario_data.get("story_expression", ""))
        
        self.scenario_era_time.delete("1.0", tk.END)
        self.scenario_era_time.insert("1.0", scenario_data.get("era_time", ""))
        
        self.scenario_location.delete(0, tk.END)
        self.scenario_location.insert(0, scenario_data.get("location", ""))

        self.scenario_person_in_story.delete("1.0", tk.END)
        self.scenario_person_in_story.insert("1.0", scenario_data.get("person_in_story_action", ""))
        
        self.scenario_speaker_action.delete("1.0", tk.END)
        self.scenario_speaker_action.insert("1.0", scenario_data.get("speaker_action", ""))

        self.scenario_extra.delete("1.0", tk.END)   
        self.scenario_extra.insert("1.0", scenario_data.get("extra", ""))

        # scenario_moodå­—æ®µç”¨äºè¯­éŸ³åˆæˆæƒ…ç»ª
        self.scenario_speaker.set(scenario_data.get("speaker", ""))
        self.scenario_speaker_position.set(scenario_data.get("speaker_position", ""))
        voice_synthesis_mood = scenario_data.get("mood", "calm")
        if voice_synthesis_mood in EXPRESSION_STYLES:
            self.scenario_mood.set(voice_synthesis_mood)
        else:
            self.scenario_mood.set("calm")
        
        self.scenario_camera_light.delete("1.0", tk.END)
        self.scenario_camera_light.insert("1.0", scenario_data.get("camera_light", ""))
        
        self.scenario_story_content.delete("1.0", tk.END)
        self.scenario_story_content.insert("1.0", scenario_data.get("content", ""))


    def update_video_progress_display(self):
        """æ›´æ–°è§†é¢‘è¿›åº¦æ˜¾ç¤ºï¼ˆæœªæ’­æ”¾æ—¶æ˜¾ç¤ºæ€»æ—¶é•¿ï¼‰"""
        if not hasattr(self, 'workflow'):
            return

        try:
            current_scenario = self.get_current_scenario()
            if current_scenario:
                clip_video = get_file_path(current_scenario, "clip")
                if clip_video:
                    total_duration = self.workflow.ffmpeg_processor.get_duration(clip_video)
                else:
                    total_duration = 0.0
                
                total_min = int(total_duration // 60)
                total_sec = int(total_duration % 60)
                
                if self.video_playing:
                    pass
                else:
                    self.video_progress_label.config(text=f"00:00 / {total_min:02d}:{total_sec:02d}")
            else:
                self.video_progress_label.config(text="00:00 / 00:00")
                
        except Exception as e:
            self.video_progress_label.config(text="00:00 / 00:00")
            print(f"âš ï¸ æ›´æ–°è§†é¢‘è¿›åº¦æ˜¾ç¤ºå¤±è´¥: {e}")


    def clear_scenario_fields(self):
        self.scenario_duration.config(state="normal")
        self.scenario_duration.delete(0, tk.END)
        self.scenario_duration.config(state="readonly")
        
        self.scenario_main_animate.set("")
        
        self.scenario_story_expression.delete("1.0", tk.END)
        self.scenario_era_time.delete("1.0", tk.END)
        self.scenario_location.delete(0, tk.END)
        self.scenario_person_in_story.delete("1.0", tk.END)
        self.scenario_speaker_action.delete("1.0", tk.END)
        self.scenario_extra.delete("1.0", tk.END)
        self.scenario_speaker.set("")
        self.scenario_speaker_position.set("")
        self.scenario_mood.set("calm")
        self.scenario_camera_light.delete("1.0", tk.END)
        self.scenario_story_content.delete("1.0", tk.END)


    def prev_scenario(self):
        """ä¸Šä¸€ä¸ªåœºæ™¯"""
        self.update_current_scenario()
        
        self.current_scenario_index -= 1
        if self.current_scenario_index < 0:
            self.current_scenario_index = len(self.workflow.scenarios) - 1

        self.refresh_gui_scenarios()


    def next_scenario(self):
        """ä¸‹ä¸€ä¸ªåœºæ™¯"""
        self.update_current_scenario()
        
        self.current_scenario_index += 1
        if self.current_scenario_index >= len(self.workflow.scenarios):
            self.current_scenario_index = 0

        self.refresh_gui_scenarios()


    def split_current_scenario(self):
        """åˆ†ç¦»å½“å‰åœºæ™¯"""      
        position = pygame.mixer.music.get_pos() / 1000.0
        self.workflow.split_scenario_at_position(self.current_scenario_index, position+self.playing_delta)
        self.playing_delta = 0.0
        self.playing_delta_label.config(text=f"{self.playing_delta:.1f}s")
        self.refresh_gui_scenarios()


    def clean_media_mark(self):
        """æ ‡è®°æ¸…ç†"""
        for scenario in self.workflow.scenarios:
            scenario["clip_animation"] = ""

        self.workflow.save_scenarios_to_json()
        messagebox.showinfo("æˆåŠŸ", "æ ‡è®°æ¸…ç†æˆåŠŸï¼")


    def start_video_gen_batch(self):
        """å¯åŠ¨WANæ‰¹ç”Ÿæˆ"""
        current_scenario = self.get_current_scenario()
        previous_scenario = self.get_previous_scenario()
        next_scenario = self.get_next_scenario()

        ss = self.workflow.scenarios_in_story(current_scenario)
        for scenario in ss:
            self.generate_video(scenario, previous_scenario, next_scenario, "clip")
            self.generate_video(scenario, previous_scenario, next_scenario, "second")

        self.refresh_gui_scenarios()
        messagebox.showinfo("æˆåŠŸ", "WANè§†é¢‘æ‰¹é‡ç”ŸæˆæˆåŠŸï¼")


    def clean_wan(self):
        self.workflow.clean_folder("/wan_video/interpolated")
        self.workflow.clean_folder("/wan_video/enhanced")
        self.workflow.clean_folder("/wan_video/original")


    def clean_media(self):
        """åª’ä½“æ¸…ç†"""
        self.workflow.clean_media()
        self.workflow.save_scenarios_to_json()
        messagebox.showinfo("æˆåŠŸ", "åª’ä½“æ¸…ç†æˆåŠŸï¼")


    def adjust_second_delta(self, delta):
        self.second_delta = self.second_delta + delta
        if self.second_delta < -10:
            self.second_delta = -10
        if self.second_delta > 10:
            self.second_delta = 10
        
        self.second_delta_label.config(text=f"{self.second_delta:.1f}s")


    def move_video(self, delta):
        self.playing_delta = self.playing_delta + delta
        if self.playing_delta < -1.5:
            self.playing_delta = -1.5
        if self.playing_delta > 1.5:
            self.playing_delta = 1.5
        
        self.playing_delta_label.config(text=f"{self.playing_delta:.1f}s")


    def insert_scenario(self):
        self.update_scenario_buttons_state()
        current_scenario = self.get_current_scenario()
        if current_scenario and not self.workflow.first_scenario_of_story(current_scenario):
            return
        self.add_root_scenario(False)


    def append_scenario(self):
        self.update_scenario_buttons_state()
        current_scenario = self.get_current_scenario()
        if current_scenario and not self.workflow.last_scenario_of_story(current_scenario):
            return
        self.add_root_scenario(True)


    def add_root_scenario(self, is_append):
        """å¢åŠ åœºæ™¯"""
        #dialog = BackgroundSelectorDialog(self, self.workflow, new_clip_image)
        #self.root.wait_window(dialog.dialog)

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ç¡®è®¤äº†é€‰æ‹©
        #if dialog.result and dialog.result.get('confirmed'):

        #background_images = dialog.result.get('background_images')  # è·å–å›¾ç‰‡åˆ—è¡¨
        #background_music = dialog.result.get('background_music')

        background_images = [self.workflow.find_default_background_image()]  # ä¼ é€’å›¾ç‰‡åˆ—è¡¨
        background_music = self.workflow.find_default_background_music()
        background_video = self.workflow.find_default_background_video()

        # åˆ›å»ºæ–°åœºæ™¯
        self.workflow.add_root_scenario(
            self.current_scenario_index,
            self.story_site_entry.get(), 
            background_images[0],  # ä¼ é€’å›¾ç‰‡åˆ—è¡¨
            background_music,
            background_video,
            is_append
        )
        self.refresh_gui_scenarios()
        
        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
        image_names = ", ".join([os.path.basename(img) for img in background_images])
        messagebox.showinfo("æˆåŠŸ", f"åœºæ™¯å·²æ·»åŠ \nèƒŒæ™¯å›¾ç‰‡ ({len(background_images)} å¼ ): {image_names}\nèƒŒæ™¯éŸ³ä¹: {os.path.basename(background_music)}")
        #else:
        #    # ç”¨æˆ·å–æ¶ˆäº†æ“ä½œ
        #    messagebox.showinfo("å–æ¶ˆ", "æœªæ·»åŠ æ–°åœºæ™¯")


    def reverse_video(self):
        """ç¿»è½¬è§†é¢‘"""
        current_scenario = self.get_current_scenario()
        oldv, newv = self.workflow.refresh_scenario_media(current_scenario, "clip", ".mp4")
        os.replace(self.workflow.ffmpeg_processor.reverse_video(oldv), newv)
        self.workflow.save_scenarios_to_json()
        self.refresh_gui_scenarios()


    def get_current_playback_position(self):
        """
        è·å–å½“å‰ä¸»åœºæ™¯çš„æ’­æ”¾ä½ç½®ï¼ˆè€Œä¸æ˜¯å…¶ä»–è½¨é“çš„ä½ç½®ï¼‰
        ä¼˜å…ˆçº§ï¼šæš‚åœä½ç½® > å®æ—¶æ’­æ”¾ä½ç½® > 0
        """
        # è°ƒè¯•ä¿¡æ¯
        has_pause_time = hasattr(self, 'video_pause_time')
        pause_time_value = self.video_pause_time if has_pause_time else "å±æ€§ä¸å­˜åœ¨"
        is_playing = self.video_playing if hasattr(self, 'video_playing') else False
        
        # 1. å¦‚æœæœ‰æš‚åœä½ç½®ï¼Œä½¿ç”¨å®ƒï¼ˆæœ€å‡†ç¡®ï¼‰
        if has_pause_time and self.video_pause_time is not None and self.video_pause_time > 0:
            print(f"ğŸ¬ ä½¿ç”¨ä¸»è§†é¢‘æš‚åœä½ç½®: {self.video_pause_time:.2f}s")
            return self.video_pause_time
        
        # 2. å¦‚æœæ­£åœ¨æ’­æ”¾ï¼ŒåŸºäºæ—¶é—´è®¡ç®—å½“å‰ä½ç½®
        if is_playing and hasattr(self, 'video_start_time') and self.video_start_time:
            try:
                elapsed = time.time() - self.video_start_time
                # å¦‚æœæœ‰ç´¯ç§¯çš„æš‚åœæ—¶é—´ï¼ŒåŠ ä¸Šå®ƒ
                total_time = elapsed + (self.video_pause_time if self.video_pause_time else 0)
                print(f"ğŸ¬ ä½¿ç”¨ä¸»è§†é¢‘æ’­æ”¾ä½ç½®ï¼ˆå®æ—¶è®¡ç®—ï¼‰: {total_time:.2f}s (å½“å‰ç‰‡æ®µ: {elapsed:.2f}s, ç´¯ç§¯æš‚åœ: {self.video_pause_time or 0:.2f}s)")
                return total_time
            except:
                pass
        
        # 3. é»˜è®¤è¿”å› 0
        print(f"ğŸ¬ ä¸»è§†é¢‘æœªæ’­æ”¾æˆ–æ— æš‚åœä½ç½®ï¼Œè¿”å› 0")
        print(f"    è°ƒè¯•: video_pause_time={pause_time_value}, video_playing={is_playing}")
        return 0.0


    def mirror_video(self):
        """é•œåƒè§†é¢‘"""
        current_scenario = self.get_current_scenario()
        oldv, newv = self.workflow.refresh_scenario_media(current_scenario, "clip", ".mp4")
        os.replace(self.workflow.ffmpeg_processor.mirror_video(oldv), newv)
        self.workflow.save_scenarios_to_json()
        self.refresh_gui_scenarios()


    def print_title(self):
        """æ‰“å°æ ‡é¢˜"""
        current_scenario = self.update_current_scenario()
        title = current_scenario['content']
        if not title or title.strip() == "":
            messagebox.showinfo("æ ‡é¢˜", "æ ‡é¢˜ä¸ºç©º")
            return
        clip_video = get_file_path(current_scenario, "clip")
        if not clip_video:
            messagebox.showinfo("æ ‡é¢˜", "è§†é¢‘ä¸ºç©º")
            return
       
        title = self.workflow.transcriber.translate_text(title, self.workflow.language, self.workflow.language)
        current_scenario["keywords"] = title

        position = "footer"
        font_size = 105
        if title.startswith("h_"):
            position = "header"
            title = title[2:]   
        elif title.startswith("b_"):
            position = "body"
            title = title[2:]
        elif title.startswith("f_"):
            position = "footer"
            title = title[2:]
        if title.startswith("hl_"):
            font_size = 190
            position = "header"
            title = title[2:]   
        elif title.startswith("bl_"):
            font_size = 190
            position = "body"
            title = title[2:]
        elif title.startswith("fl_"):
            font_size = 190
            position = "footer"
            title = title[2:]
        elif title.startswith("hm_"):
            position = "header"
            font_size = 80
            title = title[3:]
        elif title.startswith("bm_"):
            position = "body"
            font_size = 80
            title = title[3:]
        elif title.startswith("fm_"):
            position = "footer"
            font_size = 80
            title = title[3:]
        elif title.startswith("hs_"):
            position = "header"
            font_size = 60
            title = title[3:]
        elif title.startswith("bs_"):
            position = "body"
            font_size = 60
            title = title[3:]
        elif title.startswith("fs_"):
            position = "footer"
            font_size = 60
            title = title[3:]

        v = self.workflow.ffmpeg_processor.add_script_to_video(clip_video, title, self.workflow.font_video, font_size, position)
        back = current_scenario.get('back', '')
        current_scenario['back'] = clip_video + "," + back
        self.workflow.refresh_scenario_media(current_scenario, "clip", ".mp4", v)

        self.workflow.save_scenarios_to_json()
        self.refresh_gui_scenarios()


    def toggle_track_playback(self):
        # æ£€æŸ¥å½“å‰é€‰ä¸­çš„tab
        current_tab_index = self.second_notebook.index(self.second_notebook.select())

        if current_tab_index == 1:
            if self.pip_lr_playing:
                self.pause_pip_lr() 
            else:
                self.play_pip_lr()
        else:
            if self.second_track_playing:
                self.pause_second_track()
            else:
                self.play_second_track()


    def play_second_track(self):
        """æ’­æ”¾ç¬¬äºŒè½¨é“è§†é¢‘çš„å½“å‰åœºæ™¯æ—¶é—´æ®µï¼ˆæ”¯æŒä»æš‚åœçŠ¶æ€å’Œåç§»ä½ç½®æ¢å¤ï¼‰"""
        second_video_path = get_file_path(self.get_current_scenario(), self.selected_second_track)
        second_audio_path = get_file_path(self.get_current_scenario(), self.selected_second_track+'_audio')
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä»æš‚åœçŠ¶æ€æ¢å¤
            is_resuming = (self.second_track_cap and self.second_track_paused_time)

            #elif self.second_track_paused_time:
            #    play_start_time = self.second_track_paused_time
            #    print(f"â–¶ï¸ ä»æš‚åœä½ç½® {self.second_track_paused_time:.1f}s æ¢å¤æ’­æ”¾")
            #else:
            #    print(f"â–¶ï¸ ä»å¤´å¼€å§‹æ’­æ”¾ç¬¬äºŒè½¨é“")
            
            if is_resuming:
                play_start_time = self.second_track_paused_time
                # === ä»æš‚åœçŠ¶æ€æ¢å¤ï¼ˆä½†æ²¡æœ‰è®¾ç½®åç§»ï¼‰ ===
                self.second_track_start_time = time.time()
                self.second_track_playing = True
                self.track_play_button.config(text="â¸")
                if self.second_track_cap:
                    self.second_track_cap.set(cv2.CAP_PROP_POS_FRAMES, int(self.second_track_paused_time * self.STANDARD_FPS))
                try:
                    pygame.mixer.music.unpause()
                    print("â–¶ï¸ ç¬¬äºŒè½¨é“éŸ³é¢‘å·²æ¢å¤")
                except Exception as e:
                    print(f"âŒ æ¢å¤ç¬¬äºŒè½¨é“éŸ³é¢‘å¤±è´¥: {e}")
                    self.play_second_track_audio(second_audio_path)
                
            else:
                play_start_time = self.second_track_offset + self.second_delta
                # === å…¨æ–°å¼€å§‹æ’­æ”¾æˆ–ä»åç§»ä½ç½®æ’­æ”¾ ===
                if self.second_track_cap:
                    self.second_track_cap.release()
                self.second_track_cap = cv2.VideoCapture(second_video_path)
                if not self.second_track_cap.isOpened():
                    return

                self.second_track_cap.set(cv2.CAP_PROP_POS_FRAMES, int(play_start_time * self.STANDARD_FPS))
                
                self.second_track_end_time = self.workflow.ffmpeg_audio_processor.get_duration(second_video_path)
                
                self.second_track_playing = True
                self.track_play_button.config(text="â¸")
                
                self.second_track_start_time = time.time()
                self.second_track_paused_time = None
                
                self.play_second_track_audio(second_audio_path)
                
                print(f"â–¶ å¼€å§‹æ’­æ”¾ç¬¬äºŒè½¨é“è§†é¢‘ç‰‡æ®µ: {play_start_time:.1f}s - {self.second_track_end_time:.1f}s")
            
            # === é€šç”¨å¤„ç† - å¼€å§‹æ’­æ”¾å¾ªç¯
            self.play_second_track_frame()
            
            # æ›´æ–°æ—¶é—´æ˜¾ç¤º
            self.update_second_track_time_display()
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾ç¬¬äºŒè½¨é“è§†é¢‘å¤±è´¥: {e}")


    def play_second_track_audio(self, audio_path):
        """æ’­æ”¾ç¬¬äºŒè½¨é“éŸ³é¢‘ï¼ˆæ”¯æŒä»åç§»ä½ç½®å¼€å§‹ï¼‰"""
        try:
            # åˆå§‹åŒ–pygame mixerï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
            if not pygame.mixer.get_init():
                pygame.mixer.init()
            
            # åœæ­¢ä»»ä½•æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
            pygame.mixer.music.stop()
            
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            pygame.mixer.music.load(audio_path)
            
            # ç¡®å®šéŸ³é¢‘å¼€å§‹æ’­æ”¾çš„åç§»æ—¶é—´
            audio_start_offset = self.second_track_offset + self.second_delta
            if self.second_track_paused_time:
                audio_start_offset = self.second_track_paused_time
            
            try:
                if audio_start_offset > 0:
                    pygame.mixer.music.play(start=audio_start_offset)
                else:
                    pygame.mixer.music.play()
            except TypeError:
                print("âš ï¸ å½“å‰pygameç‰ˆæœ¬ä¸æ”¯æŒä»æŒ‡å®šä½ç½®æ’­æ”¾éŸ³é¢‘ï¼Œå°†ä»å¤´æ’­æ”¾")
                pygame.mixer.music.play()
            
            # è®¾ç½®éŸ³é¢‘æ’­æ”¾çŠ¶æ€
            self.second_track_audio_playing = True
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾ç¬¬äºŒè½¨é“éŸ³é¢‘å¤±è´¥: {e}")


    def stop_second_track_audio(self):
        """åœæ­¢ç¬¬äºŒè½¨é“éŸ³é¢‘æ’­æ”¾"""
        try:
            if self.second_track_audio_playing:
                pygame.mixer.music.stop()
                self.second_track_audio_playing = False
                self.second_track_audio_start_time = None
                print(f"â¹ ç¬¬äºŒè½¨é“éŸ³é¢‘æ’­æ”¾åœæ­¢")
        except Exception as e:
            print(f"âŒ åœæ­¢ç¬¬äºŒè½¨é“éŸ³é¢‘å¤±è´¥: {e}")


    def play_second_track_frame(self):
        """æ’­æ”¾ç¬¬äºŒè½¨é“è§†é¢‘çš„ä¸‹ä¸€å¸§ï¼ˆå¸¦åŒæ­¥æœºåˆ¶ï¼‰"""
        if not self.second_track_playing or not self.second_track_cap:
            return
            
        try:
            # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦è¿˜åœ¨æ’­æ”¾
            audio_is_playing = pygame.mixer.music.get_busy()
            if not audio_is_playing:
                # éŸ³é¢‘æ’­æ”¾å®Œæ¯•ï¼Œåœæ­¢è§†é¢‘
                self.stop_second_track()
                print("âœ… ç¬¬äºŒè½¨é“éŸ³é¢‘æ’­æ”¾å®Œæ¯•ï¼Œè§†é¢‘åŒæ­¥åœæ­¢")
                return
            
            if self.second_track_start_time:
                # è®¡ç®—å®é™…ç»è¿‡çš„æ—¶é—´
                current_time = (time.time() - self.second_track_start_time) + self.second_track_offset + self.second_delta
                
                # è®¡ç®—åº”è¯¥åœ¨ç¬¬å‡ å¸§
                target_frame = int(current_time * self.STANDARD_FPS)
                current_frame = int(self.second_track_cap.get(cv2.CAP_PROP_POS_FRAMES))
                
                # å¦‚æœè§†é¢‘å¸§è½åäºéŸ³é¢‘è¿›åº¦ï¼Œè·³å¸§è¿½èµ¶
                if target_frame > current_frame + 2:  # å…è®¸2å¸§çš„å®¹é”™
                    self.second_track_cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡äº†è§†é¢‘ç»“æŸæ—¶é—´
                if current_time >= self.second_track_end_time:
                    self.stop_second_track()
                    return
            
            ret, frame = self.second_track_cap.read()
            if not ret:
                # è§†é¢‘ç»“æŸï¼Œåœæ­¢æ’­æ”¾
                self.stop_second_track()
                return
            
            # æ˜¾ç¤ºè§†é¢‘å¸§åˆ°Canvas
            from PIL import Image, ImageTk
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(frame_rgb)
            
            # è°ƒæ•´å›¾åƒå¤§å°é€‚åº”Canvas
            canvas_width = self.second_track_canvas.winfo_width()
            canvas_height = self.second_track_canvas.winfo_height()
            
            if canvas_width > 1 and canvas_height > 1:
                pil_image.thumbnail((canvas_width - 10, canvas_height - 10), Image.Resampling.LANCZOS)
            else:
                pil_image.thumbnail((310, 170), Image.Resampling.LANCZOS)
            
            # æ›´æ–°ç”»å¸ƒ
            self.current_second_track_frame = ImageTk.PhotoImage(pil_image)
            self.second_track_canvas.delete("all")
            
            canvas_width = canvas_width or 320
            canvas_height = canvas_height or 180
            x = canvas_width // 2
            y = canvas_height // 2
            self.second_track_canvas.create_image(x, y, anchor=tk.CENTER, image=self.current_second_track_frame)
            
            # æ›´æ–°æ—¶é—´æ˜¾ç¤º
            self.update_second_track_time_display()
            
            # å®‰æ’ä¸‹ä¸€å¸§æ’­æ”¾
            delay = max(1, int(1000 / self.STANDARD_FPS))  # æ¯«ç§’
            self.second_track_after_id = self.root.after(delay, self.play_second_track_frame)
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾ç¬¬äºŒè½¨é“è§†é¢‘å¸§å¤±è´¥: {e}")
            self.stop_second_track()


    def pause_second_track(self):
        if not self.second_track_playing:
            return

        """æš‚åœç¬¬äºŒè½¨é“è§†é¢‘æ’­æ”¾"""
        self.second_track_playing = False
        self.track_play_button.config(text="â–¶")
        
        # è®¡ç®—å¹¶ä¿å­˜å½“å‰æ’­æ”¾åç§»æ—¶é—´ï¼ˆå…³é”®ï¼ä¸æ–°çš„åŒæ­¥æœºåˆ¶å…¼å®¹ï¼‰
        if self.second_track_start_time:
            try:
                self.second_track_paused_time = (time.time() - self.second_track_start_time) + self.second_track_offset + self.second_delta
                print(f"â¸ ä¿å­˜ç¬¬äºŒè½¨é“æš‚åœä½ç½®: {self.second_track_paused_time:.1f}s")
            except Exception as e:
                print(f"âŒ ä¿å­˜æš‚åœä½ç½®å¤±è´¥: {e}")
        
        # æš‚åœéŸ³é¢‘æ’­æ”¾
        try:
            pygame.mixer.music.pause()
            print("â¸ ç¬¬äºŒè½¨é“éŸ³é¢‘å·²æš‚åœ")
        except Exception as e:
            print(f"âŒ æš‚åœç¬¬äºŒè½¨é“éŸ³é¢‘å¤±è´¥: {e}")
        
        if self.second_track_after_id:
            self.root.after_cancel(self.second_track_after_id)
            self.second_track_after_id = None
            
        # æ›´æ–°æ—¶é—´æ˜¾ç¤º
        self.update_second_track_time_display()
    

    def stop_second_track(self):
        """åœæ­¢ç¬¬äºŒè½¨é“è§†é¢‘æ’­æ”¾"""
        self.second_track_playing = False
        self.track_play_button.config(text="â–¶")
        
        # åœæ­¢éŸ³é¢‘æ’­æ”¾
        self.stop_second_track_audio()
        
        if self.second_track_after_id:
            self.root.after_cancel(self.second_track_after_id)
            self.second_track_after_id = None
            
        if self.second_track_cap:
            self.second_track_cap.release()
            self.second_track_cap = None
            
        # æ¸…é™¤æ‰€æœ‰çŠ¶æ€å˜é‡
        self.second_track_paused_time = None
        self.second_track_paused_audio_time = None
        self.second_track_start_time = None
        self.reset_second_track_playing_offset() # self.second_track_pause_offset
        
        print("â¹ æ¸…é™¤ç¬¬äºŒè½¨é“æ‰€æœ‰çŠ¶æ€")
            
        self.second_track_canvas.delete("all")
        self.second_track_canvas.create_text(160, 90, text="ç¬¬äºŒè½¨é“è§†é¢‘é¢„è§ˆ\né€‰æ‹©è§†é¢‘åæ’­æ”¾æ˜¾ç¤º", 
                                            fill="gray", font=("Arial", 10), justify=tk.CENTER, tags="hint")
        
        # æ›´æ–°æ—¶é—´æ˜¾ç¤º
        self.update_second_track_time_display()


    # ========== PIP L/R æ’­æ”¾æ§åˆ¶å‡½æ•° ==========
    
    def play_pip_lr(self):
        """åŒæ­¥æ’­æ”¾ second_left å’Œ second_right è§†é¢‘ï¼ˆæ”¯æŒä»æš‚åœæ¢å¤ï¼‰"""
        try:
            current_scenario = self.get_current_scenario()
            if not current_scenario:
                return
            
            # è·å–è§†é¢‘è·¯å¾„
            left_path = current_scenario.get('second_left')
            right_path = current_scenario.get('second_right')
            audio_path = current_scenario.get('clip_audio')
            
            if not left_path or not right_path:
                messagebox.showwarning("æç¤º", "å½“å‰åœºæ™¯æ²¡æœ‰ second_left æˆ– second_right è§†é¢‘")
                return
            
            if not os.path.exists(left_path) or not os.path.exists(right_path):
                messagebox.showerror("é”™è¯¯", "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                return
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä»æš‚åœçŠ¶æ€æ¢å¤
            is_resuming = (self.pip_left_cap and hasattr(self, 'pip_lr_paused_time') and self.pip_lr_paused_time is not None)
            
            if is_resuming:
                # ä»æš‚åœæ¢å¤
                self.pip_lr_playing = True
                self.pip_lr_start_time = time.time() - self.pip_lr_paused_time
                self.track_play_button.config(text="â¸")
                
                # æ¢å¤éŸ³é¢‘æ’­æ”¾
                if audio_path and os.path.exists(audio_path):
                    try:
                        pygame.mixer.music.unpause()
                        print(f"â–¶ï¸ ä»æš‚åœä½ç½® {self.pip_lr_paused_time:.1f}s æ¢å¤æ’­æ”¾ PIP L/R")
                    except:
                        pass
                
                # æ¸…é™¤æš‚åœæ ‡è®°
                self.pip_lr_paused_time = None
                
                # ç»§ç»­æ’­æ”¾
                self.play_pip_lr_frame()
                
            else:
                # å…¨æ–°å¼€å§‹æ’­æ”¾
                # æ‰“å¼€è§†é¢‘æ–‡ä»¶
                self.pip_left_cap = cv2.VideoCapture(left_path)
                self.pip_right_cap = cv2.VideoCapture(right_path)
                
                if not self.pip_left_cap.isOpened() or not self.pip_right_cap.isOpened():
                    messagebox.showerror("é”™è¯¯", "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
                    return
                
                # æ’­æ”¾éŸ³é¢‘
                if audio_path and os.path.exists(audio_path):
                    try:
                        pygame.mixer.music.load(audio_path)
                        pygame.mixer.music.set_volume(self.track_volume_var.get())
                        pygame.mixer.music.play()
                        print(f"ğŸ”Š æ’­æ”¾éŸ³é¢‘: {audio_path}")
                    except Exception as e:
                        print(f"âŒ æ’­æ”¾éŸ³é¢‘å¤±è´¥: {e}")
                
                # è®¾ç½®æ’­æ”¾çŠ¶æ€
                self.pip_lr_playing = True
                self.pip_lr_start_time = time.time()
                self.pip_lr_paused_time = None
                self.track_play_button.config(text="â¸")
                
                # å¼€å§‹æ’­æ”¾å¸§
                self.play_pip_lr_frame()
                
                print("â–¶ï¸ å¼€å§‹æ’­æ”¾ PIP L/R è§†é¢‘")
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾ PIP L/R å¤±è´¥: {e}")
            self.stop_pip_lr()
    
    def play_pip_lr_frame(self):
        """æ’­æ”¾ PIP L/R çš„ä¸‹ä¸€å¸§ï¼ˆå¸¦éŸ³è§†é¢‘åŒæ­¥æœºåˆ¶ï¼‰"""
        try:
            if not self.pip_lr_playing:
                return
            
            if not self.pip_left_cap or not self.pip_right_cap:
                self.stop_pip_lr()
                return
            
            # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦è¿˜åœ¨æ’­æ”¾
            try:
                audio_is_playing = pygame.mixer.music.get_busy()
                if not audio_is_playing:
                    # éŸ³é¢‘æ’­æ”¾å®Œæ¯•ï¼Œåœæ­¢è§†é¢‘
                    self.stop_pip_lr()
                    print("âœ… PIP L/R éŸ³é¢‘æ’­æ”¾å®Œæ¯•ï¼Œè§†é¢‘åŒæ­¥åœæ­¢")
                    return
            except:
                pass
            
            # è®¡ç®—åº”è¯¥æ’­æ”¾çš„å¸§ä½ç½®ä»¥ä¿æŒä¸éŸ³é¢‘åŒæ­¥
            if hasattr(self, 'pip_lr_start_time') and self.pip_lr_start_time:
                # è®¡ç®—å®é™…ç»è¿‡çš„æ—¶é—´
                elapsed_time = time.time() - self.pip_lr_start_time
                
                # è®¡ç®—åº”è¯¥åœ¨ç¬¬å‡ å¸§
                target_frame = int(elapsed_time * self.STANDARD_FPS)
                current_frame_left = int(self.pip_left_cap.get(cv2.CAP_PROP_POS_FRAMES))
                current_frame_right = int(self.pip_right_cap.get(cv2.CAP_PROP_POS_FRAMES))
                
                # å¦‚æœè§†é¢‘å¸§è½åäºéŸ³é¢‘è¿›åº¦ï¼Œè·³å¸§è¿½èµ¶ï¼ˆå…è®¸2å¸§çš„å®¹é”™ï¼‰
                if target_frame > current_frame_left + 2:
                    self.pip_left_cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
                
                if target_frame > current_frame_right + 2:
                    self.pip_right_cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            
            # è¯»å–å·¦å³è§†é¢‘å¸§
            ret_left, frame_left = self.pip_left_cap.read()
            ret_right, frame_right = self.pip_right_cap.read()
            
            if not ret_left or not ret_right:
                # è§†é¢‘ç»“æŸ
                self.stop_pip_lr()
                return
            
            # æ˜¾ç¤ºå·¦ä¾§è§†é¢‘
            self.display_pip_frame(frame_left, self.pip_left_canvas)
            
            # æ˜¾ç¤ºå³ä¾§è§†é¢‘
            self.display_pip_frame(frame_right, self.pip_right_canvas)
            
            # æ›´æ–°æ—¶é—´æ˜¾ç¤º
            elapsed = time.time() - self.pip_lr_start_time
            total_frames_left = self.pip_left_cap.get(cv2.CAP_PROP_FRAME_COUNT)
            total_duration = total_frames_left / fps
            
            current_str = f"{int(elapsed // 60):02d}:{int(elapsed % 60):02d}"
            total_str = f"{int(total_duration // 60):02d}:{int(total_duration % 60):02d}"
            self.track_time_label.config(text=f"{current_str} / {total_str}")
            
            # å®‰æ’ä¸‹ä¸€å¸§
            delay = max(1, int(1000 / fps))
            self.pip_lr_after_id = self.root.after(delay, self.play_pip_lr_frame)
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾ PIP L/R å¸§å¤±è´¥: {e}")
            self.stop_pip_lr()
    
    def display_pip_frame(self, frame, canvas):
        """åœ¨canvasä¸Šæ˜¾ç¤ºä¸€å¸§"""
        try:
            from PIL import Image, ImageTk
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(frame_rgb)
            
            # è°ƒæ•´å›¾åƒå¤§å°
            canvas_width = canvas.winfo_width()
            canvas_height = canvas.winfo_height()
            
            if canvas_width > 1 and canvas_height > 1:
                pil_image.thumbnail((canvas_width - 4, canvas_height - 4), Image.Resampling.LANCZOS)
            else:
                pil_image.thumbnail((150, 150), Image.Resampling.LANCZOS)
            
            # æ›´æ–°ç”»å¸ƒ
            photo = ImageTk.PhotoImage(pil_image)
            canvas.delete("all")
            
            canvas_width = canvas_width or 155
            canvas_height = canvas_height or 160
            x = canvas_width // 2
            y = canvas_height // 2
            canvas.create_image(x, y, anchor=tk.CENTER, image=photo)
            
            # ä¿å­˜å¼•ç”¨é˜²æ­¢è¢«åƒåœ¾å›æ”¶
            if canvas == self.pip_left_canvas:
                self.current_pip_left_frame = photo
            else:
                self.current_pip_right_frame = photo
                
        except Exception as e:
            print(f"âŒ æ˜¾ç¤º PIP å¸§å¤±è´¥: {e}")
    
    
    def pause_pip_lr(self):
        if not self.pip_lr_playing:
            return

        """æš‚åœ PIP L/R æ’­æ”¾"""
        self.pip_lr_playing = False
        self.track_play_button.config(text="â–¶")
        
        # ä¿å­˜æš‚åœæ—¶é—´ç‚¹
        if hasattr(self, 'pip_lr_start_time') and self.pip_lr_start_time:
            self.pip_lr_paused_time = time.time() - self.pip_lr_start_time
            print(f"â¸ æš‚åœ PIP L/R æ’­æ”¾ï¼Œä½ç½®: {self.pip_lr_paused_time:.1f}s")
        
        # æš‚åœéŸ³é¢‘
        try:
            if pygame.mixer.music.get_busy():
                pygame.mixer.music.pause()
        except:
            pass
        
        # å–æ¶ˆä¸‹ä¸€å¸§è°ƒåº¦
        if self.pip_lr_after_id:
            self.root.after_cancel(self.pip_lr_after_id)
            self.pip_lr_after_id = None
    

    def stop_pip_lr(self):
        """åœæ­¢ PIP L/R æ’­æ”¾"""
        self.pip_lr_playing = False
        self.track_play_button.config(text="â–¶")
        
        # åœæ­¢éŸ³é¢‘
        try:
            if pygame.mixer.music.get_busy():
                pygame.mixer.music.stop()
        except:
            pass
        
        # å–æ¶ˆè°ƒåº¦
        if self.pip_lr_after_id:
            self.root.after_cancel(self.pip_lr_after_id)
            self.pip_lr_after_id = None
        
        # é‡Šæ”¾è§†é¢‘
        if self.pip_left_cap:
            self.pip_left_cap.release()
            self.pip_left_cap = None
        
        if self.pip_right_cap:
            self.pip_right_cap.release()
            self.pip_right_cap = None
        
        # æ¸…é™¤æ’­æ”¾çŠ¶æ€
        self.pip_lr_start_time = None
        self.pip_lr_paused_time = None
        
        # æ¸…ç©ºç”»å¸ƒ
        self.pip_left_canvas.delete("all")
        self.pip_left_canvas.create_text(77, 80, text="Left\nç”»ä¸­ç”»å·¦ä¾§", 
                                         fill="gray", font=("Arial", 9), justify=tk.CENTER, tags="hint")
        
        self.pip_right_canvas.delete("all")
        self.pip_right_canvas.create_text(77, 80, text="Right\nç”»ä¸­ç”»å³ä¾§", 
                                          fill="gray", font=("Arial", 9), justify=tk.CENTER, tags="hint")
        
        # é‡ç½®æ—¶é—´æ˜¾ç¤º
        self.track_time_label.config(text="00:00 / 00:00")
        
        print("â¹ åœæ­¢ PIP L/R æ’­æ”¾")

    
    def on_second_track_tab_changed(self, event=None):
        """tabåˆ‡æ¢æ—¶åœæ­¢æ­£åœ¨æ’­æ”¾çš„è§†é¢‘"""
        self.pause_second_track()
        self.pause_pip_lr()
        
        current_tab_index = self.second_notebook.index(self.second_notebook.select())
        if current_tab_index == 0:
            self.load_second_track_first_frame()
        elif current_tab_index == 1:
            self.load_pip_lr_first_frame()

    
    def load_pip_lr_first_frame(self):
        """åŠ è½½ PIP L/R è§†é¢‘çš„ç¬¬ä¸€å¸§"""
        try:
            current_scenario = self.get_current_scenario()
            if not current_scenario:
                return
            
            left_path = current_scenario.get(self.selected_second_track+'_left')
            right_path = current_scenario.get(self.selected_second_track+'_right')
            
            if not left_path or not right_path:
                # æ¸…ç©ºç”»å¸ƒæ˜¾ç¤ºæç¤º
                self.pip_left_canvas.delete("all")
                self.pip_left_canvas.create_text(77, 80, text="Left\nç”»ä¸­ç”»å·¦ä¾§\næœªç”Ÿæˆ", 
                                                 fill='gray', font=('Arial', 9), justify=tk.CENTER, tags="hint")
                self.pip_right_canvas.delete("all")
                self.pip_right_canvas.create_text(77, 80, text="Right\nç”»ä¸­ç”»å³ä¾§\næœªç”Ÿæˆ", 
                                                  fill='gray', font=('Arial', 9), justify=tk.CENTER, tags="hint")
                self.track_time_label.config(text="00:00 / 00:00")
                return
            
            if not os.path.exists(left_path) or not os.path.exists(right_path):
                print(f"âŒ PIP L/R è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                return
            
            # æ‰“å¼€å·¦ä¾§è§†é¢‘è·å–ç¬¬ä¸€å¸§
            temp_cap_left = cv2.VideoCapture(left_path)
            if temp_cap_left.isOpened():
                ret, frame = temp_cap_left.read()
                if ret:
                    self.display_pip_frame(frame, self.pip_left_canvas)
                
                # è·å–æ€»æ—¶é•¿
                total_frames = temp_cap_left.get(cv2.CAP_PROP_FRAME_COUNT)
                total_duration = total_frames / self.STANDARD_FPS
                total_str = f"{int(total_duration // 60):02d}:{int(total_duration % 60):02d}"
                self.track_time_label.config(text=f"00:00 / {total_str}")
                
                temp_cap_left.release()
            
            # æ‰“å¼€å³ä¾§è§†é¢‘è·å–ç¬¬ä¸€å¸§
            temp_cap_right = cv2.VideoCapture(right_path)
            if temp_cap_right.isOpened():
                ret, frame = temp_cap_right.read()
                if ret:
                    self.display_pip_frame(frame, self.pip_right_canvas)
                temp_cap_right.release()
            
            print(f"âœ… å·²åŠ è½½ PIP L/R ç¬¬ä¸€å¸§")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ PIP L/R ç¬¬ä¸€å¸§å¤±è´¥: {e}")
    
    
    def on_image_drop(self, event, image_type):
        """å¤„ç†å›¾ç‰‡æ‹–æ”¾äº‹ä»¶
        
        Args:
            event: æ‹–æ”¾äº‹ä»¶
            image_type: 'clip_image', 'second_image', æˆ– 'zero_image'
        """
        file_path = event.data.strip('{}').strip('"')
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶
        if not (file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.webp'))):
            messagebox.showerror("é”™è¯¯", "è¯·æ‹–æ”¾å›¾ç‰‡æ–‡ä»¶ (PNG, JPG, WEBPç­‰)")
            return
        
        if not os.path.exists(file_path):
            messagebox.showerror("é”™è¯¯", "æ–‡ä»¶ä¸å­˜åœ¨")
            return
        
        try:
            # è·å–å½“å‰åœºæ™¯
            current_scenario = self.get_current_scenario()
            if not current_scenario:
                messagebox.showerror("é”™è¯¯", "æ²¡æœ‰é€‰ä¸­åœºæ™¯")
                return
            
            # å¤åˆ¶å›¾ç‰‡åˆ°é¡¹ç›®ç›®å½•
            self.workflow.refresh_scenario_media(current_scenario, image_type, ".webp", file_path, True)
            
            # åˆ·æ–°æ˜¾ç¤º
            self.display_image_on_canvas_for_track(image_type)
            
            self.workflow.save_scenarios_to_json()
            print(f"âœ… å·²æ›´æ–° {image_type}: {os.path.basename(file_path)}")
            messagebox.showinfo("æˆåŠŸ", f"å·²æ›´æ–° {image_type.replace('_', ' ')}")
            
        except Exception as e:
            error_msg = f"æ›´æ–°å›¾ç‰‡å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            messagebox.showerror("é”™è¯¯", error_msg)


    def display_image_on_canvas_for_track(self, image_type):
        try:
            current_scenario = self.get_current_scenario()
            if not current_scenario:
                return
            
            image_path = current_scenario.get(image_type)
            if not image_path or not os.path.exists(image_path):
                return
            
            canvas_mapping = {
                'clip_image': (self.clip_image_canvas, "Clip\nImage", '_clip_image_photo'),
                'clip_image_last': (self.clip_image_last_canvas, "Clip\nLast", '_clip_image_last_photo'),
                'second_image': (self.second_image_canvas, "Second\nImage", '_second_image_photo'),
                'second_image_last': (self.second_image_last_canvas, "Second\nLast", '_second_image_last_photo'),
                'zero_image': (self.zero_image_canvas, "Zero\nImage", '_zero_image_photo'),
                'zero_image_last': (self.zero_image_last_canvas, "Zero\nLast", '_zero_image_last_photo'),
                'one_image': (self.one_image_canvas, "One\nImage", '_one_image_photo'),
                'one_image_last': (self.one_image_last_canvas, "One\nLast", '_one_image_last_photo'),
            }
            
            if image_type not in canvas_mapping:
                return
            
            canvas, label, photo_attr = canvas_mapping[image_type]
            
            from PIL import Image, ImageTk
            img = Image.open(image_path)
            
            canvas.delete("all")
            
            canvas.update_idletasks()
            canvas_width = canvas.winfo_width()
            canvas_height = canvas.winfo_height()
            
            if canvas_width <= 1 or canvas_height <= 1:
                canvas_width, canvas_height = 150, 75
            
            img_width, img_height = img.size
            aspect_ratio = img_width / img_height
            
            margin = 5
            available_width = canvas_width - margin
            available_height = canvas_height - margin
            
            if available_width / available_height > aspect_ratio:
                new_height = available_height
                new_width = int(new_height * aspect_ratio)
            else:
                new_width = available_width
                new_height = int(new_width / aspect_ratio)
            
            img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            photo = ImageTk.PhotoImage(img_resized)
            
            x = canvas_width // 2
            y = canvas_height // 2
            canvas.create_image(x, y, image=photo, anchor=tk.CENTER, tags="image")
            
            setattr(self, photo_attr, photo)
            
            print(f"âœ… å·²æ˜¾ç¤º  {image_type}: {os.path.basename(image_path)}")
            
        except Exception as e:
            print(f"âŒ æ˜¾ç¤ºå›¾ç‰‡å¤±è´¥ ({image_type}): {e}")



    def load_all_images_preview(self):
        """åŠ è½½æ‰€æœ‰å›¾ç‰‡é¢„è§ˆ"""
        self.display_image_on_canvas_for_track('clip_image')
        self.display_image_on_canvas_for_track('clip_image_last')
        self.display_image_on_canvas_for_track('second_image')
        self.display_image_on_canvas_for_track('second_image_last')
        self.display_image_on_canvas_for_track('zero_image')
        self.display_image_on_canvas_for_track('zero_image_last')
        self.display_image_on_canvas_for_track('one_image')
        self.display_image_on_canvas_for_track('one_image_last')

    
    def on_image_double_click(self, image_type):
        """å¤„ç†å›¾ç‰‡åŒå‡»äº‹ä»¶ - ä½¿ç”¨OpenAIæè¿°å›¾ç‰‡"""
        try:
            current_scenario = self.get_current_scenario()
            if not current_scenario:
                messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªåœºæ™¯")
                return
            
            # è·å–å¯¹åº”çš„å›¾ç‰‡è·¯å¾„
            from utility.file_util import get_file_path
            image_path = get_file_path(current_scenario, image_type)
            
            if not image_path or not os.path.exists(image_path):
                messagebox.showwarning("è­¦å‘Š", f"æœªæ‰¾åˆ° {image_type} å›¾ç‰‡")
                return
            
            # ç¡®å®šè¦ä¿å­˜æè¿°çš„å­—æ®µå
            if image_type == 'clip_image':
                extra_field = 'clip_extra'
                display_name = "åœºæ™¯å›¾ç‰‡"
            elif image_type == 'second_image':
                extra_field = 'second_extra'
                display_name = "ç¬¬äºŒè½¨é“å›¾ç‰‡"
            elif image_type == 'zero_image':
                extra_field = 'zero_extra'
                display_name = "èƒŒæ™¯è½¨é“å›¾ç‰‡"
            else:
                return
            
            # æ˜¾ç¤ºå¤„ç†ä¸­çš„æç¤º
            print(f"ğŸ” æ­£åœ¨ä½¿ç”¨ OpenAI æè¿° {display_name}...")
            
            # åœ¨åå°çº¿ç¨‹ä¸­è°ƒç”¨ OpenAI API
            def describe_in_background():
                try:
                    # è°ƒç”¨ OpenAI æè¿°å›¾ç‰‡
                    description = self.workflow.sd_processor.describe_image_openai(image_path)
                    
                    # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°åœºæ™¯æ•°æ®
                    def update_scenario():
                        current_scenario[extra_field] = description
                        self.workflow.save_scenarios_to_json()
                        print(f"âœ… {display_name} æè¿°å·²ä¿å­˜åˆ° {extra_field}")
                        print(f"ğŸ“ æè¿°å†…å®¹: {description[:100]}..." if len(description) > 100 else f"ğŸ“ æè¿°å†…å®¹: {description}")
                        messagebox.showinfo("æˆåŠŸ", f"{display_name} æè¿°å·²ä¿å­˜åˆ° {extra_field}\n\n{description[:200]}..." if len(description) > 200 else f"{display_name} æè¿°å·²ä¿å­˜åˆ° {extra_field}\n\n{description}")
                    
                    self.root.after(0, update_scenario)
                    
                except Exception as e:
                    error_msg = f"æè¿°å›¾ç‰‡å¤±è´¥: {str(e)}"
                    print(f"âŒ {error_msg}")
                    self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", error_msg))
            
            # å¯åŠ¨åå°çº¿ç¨‹
            import threading
            thread = threading.Thread(target=describe_in_background, daemon=True)
            thread.start()
            
        except Exception as e:
            error_msg = f"å¤„ç†åŒå‡»äº‹ä»¶å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            messagebox.showerror("é”™è¯¯", error_msg)


    def on_track_volume_change(self, *args):
        """éŸ³é‡å˜åŒ–å¤„ç†ï¼ˆå…±ç”¨ï¼‰"""
        volume = self.track_volume_var.get()
        self.volume_label.config(text=f"{volume:.2f}")

        if hasattr(pygame.mixer, 'music') and pygame.mixer.music.get_busy():
            pygame.mixer.music.set_volume(volume)

    
    def update_second_track_time_display(self):
        """æ›´æ–°ç¬¬äºŒè½¨é“æ’­æ”¾æ—¶é—´æ˜¾ç¤º"""
        try:
            if not hasattr(self, 'second_track_cap') or not self.second_track_cap:
                self.track_time_label.config(text="00:00 / 00:00")
                return
            
            # è·å–è§†é¢‘æ€»æ—¶é•¿
            total_frames = self.second_track_cap.get(cv2.CAP_PROP_FRAME_COUNT)
            total_duration = total_frames / self.STANDARD_FPS
            
            # ç¡®å®šå½“å‰æ’­æ”¾æ—¶é—´
            current_time = 0.0
            if self.second_track_playing and self.second_track_start_time:
                # æ’­æ”¾çŠ¶æ€ï¼šæ ¹æ®å®é™…ç»è¿‡æ—¶é—´è®¡ç®—
                current_time = (time.time() - self.second_track_start_time) + self.second_track_offset + self.second_delta
            elif self.second_track_paused_time:
                # æš‚åœçŠ¶æ€ï¼šä½¿ç”¨æš‚åœæ—¶é—´
                current_time = self.second_track_paused_time
            elif self.second_track_offset:
                # ä½¿ç”¨åç§»ä½ç½®
                current_time = self.second_track_offset + self.second_delta
            else:
                # é»˜è®¤ï¼šä»è§†é¢‘å¸§ä½ç½®è®¡ç®—
                current_pos = self.second_track_cap.get(cv2.CAP_PROP_POS_FRAMES)
                current_time = current_pos / self.STANDARD_FPS
            
            # ç¡®ä¿æ—¶é—´åœ¨åˆç†èŒƒå›´å†…
            current_time = max(0, min(current_time, total_duration))
            
            # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º (MM:SS æ ¼å¼)
            current_str = f"{int(current_time // 60):02d}:{int(current_time % 60):02d}"
            total_str = f"{int(total_duration // 60):02d}:{int(total_duration % 60):02d}"
            
            self.track_time_label.config(text=f"{current_str} / {total_str}")
            
        except Exception as e:
            print(f"âŒ æ›´æ–°ç¬¬äºŒè½¨é“æ—¶é—´æ˜¾ç¤ºå¤±è´¥: {e}")
            self.track_time_label.config(text="00:00 / 00:00")


    def move_second_track_forward(self):
        """ç¬¬äºŒè½¨é“å‰è¿›1ç§’"""
        try:
            if not hasattr(self, 'second_track_cap') or not self.second_track_cap:
                return
                
            # è·å–å½“å‰æ’­æ”¾ä½ç½®
            current_pos = self.second_track_cap.get(cv2.CAP_PROP_POS_FRAMES)
            current_time = current_pos / self.STANDARD_FPS
            
            # å‰è¿›1ç§’
            new_time = current_time + 1.0
            
            # è·å–è§†é¢‘æ€»æ—¶é•¿
            total_frames = self.second_track_cap.get(cv2.CAP_PROP_FRAME_COUNT)
            total_duration = total_frames / self.STANDARD_FPS
            
            # ç¡®ä¿ä¸è¶…è¿‡è§†é¢‘æ€»æ—¶é•¿
            if new_time >= total_duration:
                new_time = total_duration - 0.1
                
            # è·³è½¬åˆ°æ–°ä½ç½®
            self.second_track_cap.set(cv2.CAP_PROP_POS_FRAMES, int(new_time * self.STANDARD_FPS))
            
            # æ›´æ–°æ—¶é—´æ˜¾ç¤º
            self.update_second_track_time_display()
            
            print(f"â© ç¬¬äºŒè½¨é“å‰è¿›1ç§’: {current_time:.1f}s -> {new_time:.1f}s")
            
        except Exception as e:
            print(f"âŒ ç¬¬äºŒè½¨é“å‰è¿›å¤±è´¥: {e}")


    def move_second_track_backward(self):
        """ç¬¬äºŒè½¨é“åé€€1ç§’"""
        try:
            if not hasattr(self, 'second_track_cap') or not self.second_track_cap:
                return
            # è·å–å½“å‰æ’­æ”¾ä½ç½®
            current_pos = self.second_track_cap.get(cv2.CAP_PROP_POS_FRAMES)
            # åé€€1ç§’
            new_time = current_pos / self.STANDARD_FPS - 1.0
            if new_time < 0:
                new_time = 0
                
            # è·³è½¬åˆ°æ–°ä½ç½®
            self.second_track_cap.set(cv2.CAP_PROP_POS_FRAMES, int(new_time * self.STANDARD_FPS))
            
            # æ›´æ–°æ—¶é—´æ˜¾ç¤º
            self.update_second_track_time_display()
            
            print(f"âª ç¬¬äºŒè½¨é“åé€€1ç§’")
            
        except Exception as e:
            print(f"âŒ ç¬¬äºŒè½¨é“åé€€å¤±è´¥: {e}")
    

    def shift_forward(self):
        """å‰ç§»å½“å‰åœºæ™¯"""
        position = pygame.mixer.music.get_pos() / 1000.0
        self.workflow.shift_scenario(self.current_scenario_index, self.current_scenario_index+1, position+self.playing_delta)
        self.playing_delta = 0.0

        self.refresh_gui_scenarios()


    def shift_before(self):
        """ä¸‹ç§»å½“å‰åœºæ™¯"""
        position = pygame.mixer.music.get_pos() / 1000.0
        self.workflow.shift_scenario(self.current_scenario_index, self.current_scenario_index-1, position+self.playing_delta)
        self.playing_delta = 0.0

        self.refresh_gui_scenarios()


    def extend_scenario(self):
        """æ‰©å±•å½“å‰åœºæ™¯"""
        if self.playing_delta <= 0:
            messagebox.showinfo("è­¦å‘Š", "âš ï¸ å½“å‰åœºæ™¯æ— æ³•æ‰©å±• - " + str(self.playing_delta))
            return
        self.workflow.extend_scenario(self.current_scenario_index, self.playing_delta)
        self.refresh_gui_scenarios()


    def merge_or_delete(self):
        """åˆå¹¶å½“å‰å›¾ç‰‡ä¸ä¸‹ä¸€å¼ å›¾ç‰‡"""
        if len(self.workflow.scenarios) == 0:
            messagebox.showinfo("è­¦å‘Š", "âš ï¸ æ— åœºæ™¯")
            return

        current_scenario = self.get_current_scenario()
        ss = self.workflow.scenarios_in_story(current_scenario)
        if len(ss) <= 1:
            result = messagebox.askyesno("è­¦å‘Š", "âš ï¸ åˆ é™¤å”¯ä¸€åœºæ™¯?")
            if result:
                ss = self.workflow.replace_scenario(self.current_scenario_index)
        else:
            if ss[-1] == current_scenario:
                result = messagebox.askyesno("è­¦å‘Š", "âš ï¸ åˆ é™¤å½“å‰åœºæ™¯?")
                if result:
                    ss = self.workflow.replace_scenario(self.current_scenario_index)
            else:
                result = messagebox.askyesno("è­¦å‘Š", "âš ï¸ åˆå¹¶è¿˜æ˜¯åˆ é™¤åœºæ™¯\nYes: åˆå¹¶\nNo: åˆ é™¤")
                if result:
                    self.workflow.merge_scenario(self.current_scenario_index, self.current_scenario_index+1)
                else:
                    result = messagebox.askyesno("è­¦å‘Š", "âš ï¸ åˆ é™¤å½“å‰åœºæ™¯?")
                    if result:
                        ss = self.workflow.replace_scenario(self.current_scenario_index)
            
        self.refresh_gui_scenarios()
        messagebox.showinfo("åˆå¹¶åœºæ™¯", "å®Œæˆ")


    def swap_with_next_image(self):
        """äº¤æ¢å½“å‰å›¾ç‰‡ä¸ä¸‹ä¸€å¼ å›¾ç‰‡"""
        current_index = self.current_scenario_index
        current_scenario = self.workflow.scenarios[current_index]

        ss = self.workflow.scenarios_in_story(current_scenario)
        if len(ss) <= 1 or current_scenario == ss[-1]:
            messagebox.showinfo("è­¦å‘Š", "âš ï¸ å½“å‰åœºæ™¯æ— æ³•äº¤æ¢")
            return
        
        next_index = current_index + 1
        next_scenario = self.workflow.scenarios[next_index]

        # æŸ¥æ‰¾å½“å‰åœºæ™¯å’Œä¸‹ä¸€ä¸ªåœºæ™¯çš„å›¾åƒæ–‡ä»¶
        temp_image = current_scenario["clip_image"]
        current_scenario["clip_image"] = next_scenario["clip_image"]
        next_scenario["clip_image"] = temp_image

        # self.workflow._generate_video_from_image(current_scenario)
        # self.workflow._generate_video_from_image(next_scenario)
        
        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
        messagebox.showinfo("æˆåŠŸ", f"å·²æˆåŠŸäº¤æ¢åœºæ™¯ {current_index + 1} å’Œåœºæ™¯ {next_index + 1} çš„å›¾ç‰‡ï¼")


    def swap_scenario(self):
        """äº¤æ¢å½“å‰åœºæ™¯ä¸ä¸‹ä¸€å¼ åœºæ™¯"""
        self.workflow.swap_scenario(self.current_scenario_index, self.current_scenario_index+1)
        self.refresh_gui_scenarios()


    def regenerate_scenario(self):
        self.workflow.refresh_scenario( self.get_current_scenario() )
        self.refresh_gui_scenarios()


    def copy_images_to_next(self):
        current_scenario = self.get_current_scenario()
        next_scenario = self.workflow.next_scenario_of_story(current_scenario)
        if current_scenario and next_scenario:
            clip_image_split = current_scenario.get("clip_image_split", "")
            clip_animation = current_scenario.get("clip_animation", "")
            second_animation = current_scenario.get("second_animation", "")

            next_scenario["clip_image_split"] = clip_image_split
            next_scenario["clip_animation"] =  clip_animation
            next_scenario["second_animation"] = second_animation

            clip_image = current_scenario.get("clip_image", "")
            clip_image_last = current_scenario.get("clip_image_last", "")
            if clip_image:
                self.workflow.refresh_scenario_media(next_scenario, "clip_image", ".webp", clip_image, True)
            if clip_image_last:
                self.workflow.refresh_scenario_media(next_scenario, "clip_image_last", ".webp", clip_image_last, True)

            second_image = current_scenario.get("second_image", "")
            second_image_last = current_scenario.get("second_image_last", "")
            if second_image:
                self.workflow.refresh_scenario_media(next_scenario, "second_image", ".webp", second_image, True)
            if second_image_last:
                self.workflow.refresh_scenario_media(next_scenario, "second_image_last", ".webp", second_image_last, True)

            self.workflow.save_scenarios_to_json()
            self.refresh_gui_scenarios()


    def recreate_second_image(self):
        """é‡æ–°åˆ›å»ºæ¬¡å›¾ï¼Œå…ˆæ‰“å¼€å¯¹è¯æ¡†è®©ç”¨æˆ·å®¡æŸ¥å’Œç¼–è¾‘æç¤ºè¯"""
        scenario = self.get_current_scenario()
        # å®šä¹‰åˆ›å»ºå›¾åƒçš„å›è°ƒå‡½æ•°
        def create_second_image(edited_positive, edited_negative):
            oldi, newi = self.workflow.refresh_scenario_media(scenario, "second_image", ".webp")
            self.workflow._create_image(self.workflow.sd_processor.gen_config["Story"], 
                                        newi,
                                        None,
                                        edited_positive,
                                        edited_negative,
                                        int(time.time())
                                    )
            self.workflow.save_scenarios_to_json()
            self.refresh_gui_scenarios()
            print("âœ… æ¬¡å›¾å·²é‡æ–°åˆ›å»º")
        
        # æ„å»ºæ­£é¢æç¤ºè¯é¢„è§ˆ
        self.open_image_prompt_dialog(create_second_image, scenario, "second")


    def recreate_clip_image(self):
        """é‡æ–°åˆ›å»ºä¸»å›¾ï¼Œå…ˆæ‰“å¼€å¯¹è¯æ¡†è®©ç”¨æˆ·å®¡æŸ¥å’Œç¼–è¾‘æç¤ºè¯"""
        scenario = self.get_current_scenario()
        
        # å®šä¹‰åˆ›å»ºå›¾åƒçš„å›è°ƒå‡½æ•°
        def create_clip_image(edited_positive, edited_negative):
            oldi, newi = self.workflow.refresh_scenario_media(scenario, "clip_image", ".webp")
            self.workflow._create_image(self.workflow.sd_processor.gen_config["Story"], 
                                        newi,
                                        None,
                                        newi,
                                        edited_positive,
                                        edited_negative,
                                        int(time.time())
                                    )
            self.workflow.save_scenarios_to_json()
            self.refresh_gui_scenarios()
            print("âœ… ä¸»å›¾å·²é‡æ–°åˆ›å»º")
        
        # æ„å»ºæ­£é¢æç¤ºè¯é¢„è§ˆ
        self.open_image_prompt_dialog(create_clip_image, scenario, "clip")


    def update_current_scenario(self):
        scenario = self.get_current_scenario()
        scenario.update({
            "story_expression": self.scenario_story_expression.get("1.0", tk.END).strip(),
            "era_time": self.scenario_era_time.get("1.0", tk.END).strip(),
            "location": self.scenario_location.get(),
            "person_in_story_action": self.scenario_person_in_story.get("1.0", tk.END).strip(),
            "speaker_action": self.scenario_speaker_action.get("1.0", tk.END).strip(),
            "extra": self.scenario_extra.get("1.0", tk.END).strip(),
            "speaker": self.scenario_speaker.get(),
            "speaker_position": self.scenario_speaker_position.get(),  # æ·»åŠ è®²å‘˜ä½ç½®å­—æ®µ
            "mood": self.scenario_mood.get(),         # è¯­éŸ³åˆæˆæƒ…ç»ª
            "camera_light": self.scenario_camera_light.get("1.0", tk.END).strip(),
            "clip_animation": self.scenario_main_animate.get(),
            "content": self.scenario_story_content.get("1.0", tk.END).strip()
        })
        self.workflow.save_scenarios_to_json()
        return scenario


    def load_config(self):
        """åŠ è½½å½“å‰é¡¹ç›®çš„é…ç½®"""
        try:
            # ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨ä¿å­˜ï¼Œé¿å…åŠ è½½è¿‡ç¨‹ä¸­è§¦å‘ä¿å­˜
            self._loading_config = True
            config_loaded = False
            
            if self.current_project_config:
                # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®åº”ç”¨æ–¹æ³•
                self.apply_config_to_gui(self.current_project_config)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆPID
                saved_pid = self.current_project_config.get('pid', '')
                if saved_pid:
                    config_loaded = True
                    
                # åŒæ­¥æ ‡é¢˜åˆ°workflow
                saved_video_title = self.current_project_config.get('video_title', 'é»˜è®¤æ ‡é¢˜')
                if saved_video_title and saved_video_title != 'é»˜è®¤æ ‡é¢˜':
                    self.video_title.delete(0, tk.END)
                    self.video_title.insert(0, saved_video_title)
                    # åªåœ¨workflowå·²åˆ›å»ºæ—¶è®¾ç½®æ ‡é¢˜
                    if hasattr(self, 'workflow') and self.workflow is not None:
                        self.workflow.set_title(saved_video_title)

                if config_loaded:
                    saved_language = self.current_project_config.get('language', 'tw')
                    saved_channel = self.current_project_config.get('channel', 'strange_zh')
                    saved_video_width = self.current_project_config.get('video_width', str(config.VIDEO_WIDTH))
                    saved_video_height = self.current_project_config.get('video_height', str(config.VIDEO_HEIGHT))
                    saved_promo_scroll_duration = self.current_project_config.get('promo_scroll_duration', 7.0)
                    
                    print(f"âœ… å·²åŠ è½½é¡¹ç›®é…ç½®: PID={saved_pid}, è¯­è¨€={saved_language}, é¢‘é“={saved_channel}")
                    print(f"   è§†é¢‘æ ‡é¢˜: {saved_video_title}")
                    print(f"   è§†é¢‘å°ºå¯¸: {saved_video_width}x{saved_video_height}")
                    print(f"   å®£ä¼ è§†é¢‘æ»šåŠ¨æŒç»­æ—¶é—´: {saved_promo_scroll_duration}ç§’")
                else:
                    print("âš ï¸ é¡¹ç›®é…ç½®ä¸­æ²¡æœ‰æœ‰æ•ˆçš„PIDï¼Œå°†è‡ªåŠ¨ç”Ÿæˆæ–°PID")
            else:
                print("âš ï¸ æ²¡æœ‰å½“å‰é¡¹ç›®é…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
                # ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–æ‰€æœ‰å­—æ®µ
                default_config = self.create_default_config()
                self.apply_config_to_gui(default_config)
            
            # PIDç°åœ¨åœ¨é¡¹ç›®åˆ›å»ºæ—¶è®¾ç½®ï¼Œä¸å†è‡ªåŠ¨ç”Ÿæˆ
            if not config_loaded:
                print("âš ï¸ é¡¹ç›®é…ç½®æ— æ•ˆï¼ŒPID/è¯­è¨€/é¢‘é“å°†ä¿æŒé»˜è®¤å€¼")
                
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
            print("âš ï¸ å°†ä½¿ç”¨é»˜è®¤é…ç½®")
        finally:
            # é‡æ–°å¯ç”¨è‡ªåŠ¨ä¿å­˜
            self._loading_config = False

    def apply_config_to_gui(self, config_data):
        """å°†é…ç½®æ•°æ®åº”ç”¨åˆ°GUIç»„ä»¶"""
        try:
            # åŠ è½½PID (åªè¯»æ ‡ç­¾)
            pid = config_data.get('pid', '')
            if hasattr(self, 'shared_pid'):
                self.shared_pid.config(text=pid)
                
            # åŠ è½½è¯­è¨€ (åªè¯»æ ‡ç­¾)
            language = config_data.get('language', 'tw')
            if hasattr(self, 'shared_language'):
                self.shared_language.config(text=language)
                
            # åŠ è½½é¢‘é“ (åªè¯»æ ‡ç­¾)
            channel = config_data.get('channel', 'strange_zh')
            if hasattr(self, 'shared_channel'):
                self.shared_channel.config(text=channel)
                
            # åŠ è½½è§†é¢‘æ ‡é¢˜
            video_title = config_data.get('video_title', 'é»˜è®¤æ ‡é¢˜')
            if hasattr(self, 'video_title'):
                self.video_title.delete(0, tk.END)
                self.video_title.insert(0, video_title)
                
            # åŠ è½½å…³é”®å­—
            program_keywords = config_data.get('program_keywords', '')
            if hasattr(self, 'project_keywords'):
                self.project_keywords.delete(0, tk.END)
                self.project_keywords.insert(0, program_keywords)
                
            # æ•…äº‹åœºåœ°ç»„
            story_site_entry = config_data.get('story_site', '')
            if hasattr(self, 'story_site_entry'):
                self.story_site_entry.delete(0, tk.END)
                self.story_site_entry.insert(0, story_site_entry)
                

                    
            # åŠ è½½è§†é¢‘å°ºå¯¸
            video_width = config_data.get('video_width', str(config.VIDEO_WIDTH))
            if hasattr(self, 'video_width'):
                self.video_width.delete(0, tk.END)
                self.video_width.insert(0, video_width)
                
            video_height = config_data.get('video_height', str(config.VIDEO_HEIGHT))
            if hasattr(self, 'video_height'):
                self.video_height.delete(0, tk.END)
                self.video_height.insert(0, video_height)
            
            # WAN é€‰é¡¹å·²ç§»åˆ° WanPromptEditorDialog ä¸­ï¼Œä¸å†éœ€è¦åŠ è½½åˆ° GUI
                
            # åŠ è½½å®£ä¼ è§†é¢‘æ»šåŠ¨æŒç»­æ—¶é—´
            promo_scroll_duration = config_data.get('promo_scroll_duration', 7.0)
            self.promo_scroll_duration = promo_scroll_duration
            
            # è‡ªåŠ¨åŠ è½½å®£ä¼ è§†é¢‘è„šæœ¬å†…å®¹
            self.load_promo_script_content()
            
            print(f"âœ… å·²å°†é…ç½®åº”ç”¨åˆ°GUI: é¢‘é“={channel}, è¯­è¨€={language}, PID={pid}")
            
        except Exception as e:
            print(f"âŒ åº”ç”¨é…ç½®åˆ°GUIæ—¶å‡ºé”™: {e}")

    def on_closing(self):
        """å¤„ç†çª—å£å…³é—­äº‹ä»¶"""
        try:
            # æ˜¾ç¤ºä¿å­˜ç¡®è®¤å¯¹è¯æ¡†
            if not self.show_save_confirmation_on_exit():
                return  # ç”¨æˆ·å–æ¶ˆäº†ï¼Œä¸å…³é—­åº”ç”¨
        
            print("ğŸ”„ æ­£åœ¨å…³é—­åº”ç”¨...")
            
            # åœæ­¢åå°è§†é¢‘æ£€æŸ¥çº¿ç¨‹
            self.stop_video_check_thread()
            
            # åœæ­¢çŠ¶æ€æ›´æ–°å®šæ—¶å™¨
            if hasattr(self, 'status_update_timer_id') and self.status_update_timer_id is not None:
                self.root.after_cancel(self.status_update_timer_id)
                self.status_update_timer_id = None
            
            # åœæ­¢è§†é¢‘æ’­æ”¾å¹¶é‡Šæ”¾èµ„æº
            if hasattr(self, 'video_cap') and self.video_cap:
                self.video_cap.release()
            if hasattr(self, 'video_after_id') and self.video_after_id:
                self.root.after_cancel(self.video_after_id)
                
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            self.cleanup_temp_audio_files()
            
            print("âœ… åº”ç”¨å·²æ­£å¸¸å…³é—­")
            
        except Exception as e:
            print(f"âŒ å…³é—­æ—¶å‡ºé”™: {e}")
        finally:
            self.root.destroy()
            
                
    def show_save_confirmation_on_exit(self):
        """é€€å‡ºæ—¶æ˜¾ç¤ºä¿å­˜ç¡®è®¤å¯¹è¯æ¡†"""
        try:
            if self.current_project_config:
                pid = self.current_project_config.get('pid', 'æœªçŸ¥PID')
                title = self.current_project_config.get('video_title', 'æœªçŸ¥æ ‡é¢˜')
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœªä¿å­˜çš„æ›´æ”¹
                current_data = self.get_current_config_data()
                has_changes = current_data != self.current_project_config
                
                if has_changes:
                    result = messagebox.askyesnocancel(
                        "ä¿å­˜é¡¹ç›®é…ç½®", 
                        f"æ˜¯å¦ä¿å­˜å½“å‰é¡¹ç›®çš„é…ç½®ï¼Ÿ\n\né¡¹ç›®: {pid}\næ ‡é¢˜: {title}\n\nç‚¹å‡»'æ˜¯'ä¿å­˜å¹¶é€€å‡º\nç‚¹å‡»'å¦'ä¸ä¿å­˜ç›´æ¥é€€å‡º\nç‚¹å‡»'å–æ¶ˆ'è¿”å›åº”ç”¨",
                        icon='question'
                    )
                    
                    if result is None:  # ç”¨æˆ·ç‚¹å‡»å–æ¶ˆ
                        return False  # ä¸å…³é—­åº”ç”¨
                    elif result:  # ç”¨æˆ·ç‚¹å‡»æ˜¯
                        self.save_config()
                        print(f"âœ… å·²ä¿å­˜é¡¹ç›®é…ç½®: {pid} - {title}")
                    else:  # ç”¨æˆ·ç‚¹å‡»å¦
                        print(f"âš ï¸ é¡¹ç›®é…ç½®æœªä¿å­˜: {pid} - {title}")
                else:
                    print(f"ğŸ“‹ é¡¹ç›®é…ç½®æ— å˜åŒ–ï¼Œæ— éœ€ä¿å­˜: {pid} - {title}")
            else:
                print("âš ï¸ æ²¡æœ‰å½“å‰é¡¹ç›®é…ç½®")
                
            return True  # ç»§ç»­å…³é—­åº”ç”¨
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç¡®è®¤å¯¹è¯æ¡†å‡ºé”™: {e}")
            return True  # å‡ºé”™æ—¶ç»§ç»­å…³é—­åº”ç”¨
    
    def get_current_config_data(self):
        """è·å–å½“å‰çš„é…ç½®æ•°æ®"""
        config_data = {
            'pid': self.get_pid(),
            'language': self.shared_language.cget('text'), 
            'channel': self.shared_channel.cget('text'),
            'video_title': getattr(self, 'video_title', None) and self.video_title.get() or 'é»˜è®¤è§†é¢‘æ ‡é¢˜',
            'program_keywords': getattr(self, 'program_keywords', None) and self.program_keywords.get() or '',
            'story_site': getattr(self, 'story_site_entry', None) and self.story_site_entry.get() or '',
            'video_width': getattr(self, 'video_width', None) and self.video_width.get() or str(config.VIDEO_WIDTH),
            'video_height': getattr(self, 'video_height', None) and self.video_height.get() or str(config.VIDEO_HEIGHT),
            'promo_scroll_duration': getattr(self, 'promo_scroll_duration', None) or 7.0,
            'conversation_content': getattr(self, 'conversation_content', None) or ''
        }

        # Add audio_prepares data if available
        workflow = self.workflow
        if workflow and hasattr(workflow, 'audio_prepares'):
            config_data['audio_prepares'] = workflow.video_prepares

        return config_data


    def cleanup_temp_audio_files(self):
        """æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶"""
        try:
            import glob
            temp_files = glob.glob("temp_audio_*.wav")
            for temp_file in temp_files:
                try:
                    os.remove(temp_file)
                    print(f"ğŸ—‘ï¸ å·²æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {temp_file}")
                except:
                    pass
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def save_config(self):
        """ä¿å­˜å½“å‰é¡¹ç›®é…ç½®"""
        try:
            workflow = self.workflow
            
            config_data = {
                'pid': self.get_pid(),
                'language': self.shared_language.cget('text'),
                'channel': self.shared_channel.cget('text'),
                'video_title': getattr(self, 'video_title', None) and self.video_title.get() or 'è§†é¢‘æ ‡é¢˜',

                'program_keywords': getattr(self, 'program_keywords', None) and self.program_keywords.get() or '',
                'story_site': getattr(self, 'story_site_entry', None) and self.story_site_entry.get() or '',
                'video_width': getattr(self, 'video_width', None) and self.video_width.get() or str(config.VIDEO_WIDTH),
                'video_height': getattr(self, 'video_height', None) and self.video_height.get() or str(config.VIDEO_HEIGHT),
                'promo_scroll_duration': getattr(self, 'promo_scroll_duration', None) or 7.0,
                'conversation_content': getattr(self, 'conversation_content', None) or ''
            }

            # Save audio_prepares data if available
            if workflow and hasattr(workflow, 'audio_prepares'):
                config_data['audio_prepares'] = workflow.video_prepares
            
            # Preserve video_id and other important fields from existing config
            if hasattr(self, 'current_project_config') and self.current_project_config:
                if 'video_id' in self.current_project_config:
                    config_data['video_id'] = self.current_project_config['video_id']
                if 'generated_titles' in self.current_project_config:
                    config_data['generated_titles'] = self.current_project_config['generated_titles']
                if 'generated_tags' in self.current_project_config:
                    config_data['generated_tags'] = self.current_project_config['generated_tags']
            
            # æ›´æ–°å½“å‰é¡¹ç›®é…ç½®
            self.current_project_config = config_data
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            config_manager = ProjectConfigManager(self.get_pid())
            config_manager.project_config = config_data.copy()
            config_manager.save_project_config(config_data)
                
        except Exception as e:
            print(f"âŒ ä¿å­˜é¡¹ç›®é…ç½®å¤±è´¥: {e}")



    def bind_edit_events(self):
        """ç»‘å®šç¼–è¾‘äº‹ä»¶"""
        # ç»‘å®šåœºæ™¯ä¿¡æ¯ç¼–è¾‘å­—æ®µçš„Enteré”®äº‹ä»¶ï¼Œç”¨äºè‡ªåŠ¨ä¿å­˜
        scenario_fields = [
            self.scenario_story_expression,
            self.scenario_era_time,
            self.scenario_location,
            self.scenario_person_in_story,
            self.scenario_speaker_action,
            self.scenario_extra,
            self.scenario_camera_light,
            self.scenario_story_content
        ]
        
        for field in scenario_fields:
            # ç»‘å®šEnteré”®äº‹ä»¶ï¼ˆCtrl+Enteråœ¨ScrolledTextä¸­è§¦å‘ä¿å­˜ï¼‰
            field.bind('<Control-Return>', self.on_scenario_field_enter)
            field.bind('<Control-Enter>', self.on_scenario_field_enter)
            # ä¹Ÿç»‘å®šå¤±å»ç„¦ç‚¹äº‹ä»¶ä½œä¸ºå¤‡é€‰ä¿å­˜æœºåˆ¶
            field.bind('<FocusOut>', self.on_scenario_field_focus_out)
        
        # ä¸ºEntryå’ŒComboboxå­—æ®µå•ç‹¬ç»‘å®šå¤±å»ç„¦ç‚¹äº‹ä»¶
        entry_combobox_fields = [
            self.scenario_speaker,
            self.scenario_mood,
            self.scenario_speaker_position
        ]
        
        for field in entry_combobox_fields:
            field.bind('<FocusOut>', self.on_scenario_field_focus_out)
            field.bind('<<ComboboxSelected>>', self.on_scenario_field_change)
        
        print("ğŸ“ å·²ç»‘å®šåœºæ™¯ç¼–è¾‘å­—æ®µçš„è‡ªåŠ¨ä¿å­˜äº‹ä»¶ (Ctrl+Enter æˆ–å¤±å»ç„¦ç‚¹æ—¶ä¿å­˜)")
    

    def bind_config_change_events(self):
        """ç»‘å®šé…ç½®å˜åŒ–äº‹ä»¶"""
        # PID, è¯­è¨€å’Œé¢‘é“ç°åœ¨éƒ½æ˜¯åªè¯»çš„ï¼Œä¸éœ€è¦ç»‘å®šå˜åŒ–äº‹ä»¶
            
        # ç»‘å®švideo_titleå˜åŒ–äº‹ä»¶
        if hasattr(self, 'video_title'):
            self.video_title.bind('<KeyRelease>', self.on_video_title_change)
            self.video_title.bind('<FocusOut>', self.on_video_title_change)
        
        # ç»‘å®šprogram_keywordså˜åŒ–äº‹ä»¶
        if hasattr(self, 'program_keywords'):
            self.program_keywords.bind('<KeyRelease>', self.on_config_change)
            self.program_keywords.bind('<FocusOut>', self.on_config_change)
            
        # ç»‘å®šstory_siteå˜åŒ–äº‹ä»¶
        if hasattr(self, 'story_site_entry'):
            self.story_site_entry.bind('<KeyRelease>', self.on_config_change)
            self.story_site_entry.bind('<FocusOut>', self.on_config_change)
            

    def on_video_title_change(self, event=None):
        """å½“è§†é¢‘æ ‡é¢˜å‘ç”Ÿå˜åŒ–æ—¶çš„å›è°ƒå‡½æ•°"""
        # å¦‚æœæ­£åœ¨åŠ è½½é…ç½®ï¼Œä¸è¦è‡ªåŠ¨ä¿å­˜
        if hasattr(self, '_loading_config') and self._loading_config:
            return
        
        # ç›´æ¥æ›´æ–°workflowçš„titleå±æ€§
        if hasattr(self, 'workflow') and self.workflow is not None:
            gui_title = self.video_title.get().strip()
            if gui_title and gui_title != "......":
                self.workflow.title = gui_title
                print(f"ğŸ·ï¸ Workflow title updated: {gui_title}")
        
        # ä¿å­˜é…ç½®
        self.save_config()



    def on_config_change(self, event=None):
        """å½“é…ç½®å‘ç”Ÿå˜åŒ–æ—¶çš„å›è°ƒå‡½æ•°"""
        # å¦‚æœæ­£åœ¨åŠ è½½é…ç½®ï¼Œä¸è¦è‡ªåŠ¨ä¿å­˜
        if hasattr(self, '_loading_config') and self._loading_config:
            return
        
        self.save_config()

    def on_scenario_edit(self, event=None):
        """å½“åœºæ™¯ä¿¡æ¯è¢«ç¼–è¾‘æ—¶çš„å›è°ƒï¼ˆç°åœ¨ä¸éœ€è¦ï¼‰"""
        # ä¿å­˜æŒ‰é’®ç°åœ¨æ€»æ˜¯å¯ç”¨
        pass

    def on_scenario_field_enter(self, event=None):
        """å½“åœ¨åœºæ™¯ç¼–è¾‘å­—æ®µä¸­æŒ‰ä¸‹Ctrl+Enteræ—¶çš„å›è°ƒ"""
        # ä¿å­˜å½“å‰åœºæ™¯ä¿¡æ¯åˆ°JSONå¹¶ä¼ æ’­åˆ°ç›¸åŒraw_scenario_indexçš„åœºæ™¯
        self.update_current_scenario()
        return "break"  # é˜»æ­¢é»˜è®¤çš„æ¢è¡Œè¡Œä¸º

    def on_scenario_field_focus_out(self, event=None):
        """å½“åœºæ™¯ç¼–è¾‘å­—æ®µå¤±å»ç„¦ç‚¹æ—¶çš„å›è°ƒ"""
        # å»¶è¿Ÿä¿å­˜ä»¥é¿å…é¢‘ç¹æ“ä½œ
        if hasattr(self, '_save_timer'):
            self.root.after_cancel(self._save_timer)
        self._save_timer = self.root.after(500, lambda: self.update_current_scenario())  # 500mså»¶è¿Ÿ

    def on_scenario_field_change(self, event=None):
        """å½“åœºæ™¯å­—æ®µå€¼å‘ç”Ÿå˜åŒ–æ—¶çš„å›è°ƒï¼ˆå¦‚Comboboxé€‰æ‹©å˜åŒ–ï¼‰"""
        # ç«‹å³ä¿å­˜å½“å‰åœºæ™¯ä¿¡æ¯
        self.update_current_scenario()
        print(f"âœ… åœºæ™¯ {self.current_scenario_index + 1} æƒ…ç»ªå·²æ›´æ–°ä¸º: {self.scenario_mood.get()}")

    def on_volume_change(self, *args):
        """å½“éŸ³é‡æ»‘å—å€¼å‘ç”Ÿå˜åŒ–æ—¶çš„å›è°ƒ"""
        volume = self.track_volume_var.get()
        self.volume_label.config(text=f"{volume:.1f}")

    def on_tab_changed(self, event):
        if not hasattr(self, 'workflow') or self.workflow is None:
            return
        self.refresh_gui_scenarios()


    def setup_drag_and_drop(self):
        self.video_canvas.drop_target_register(DND_FILES)
        self.video_canvas.dnd_bind('<<Drop>>', self.on_media_drop)
        self.video_canvas.dnd_bind('<<DragEnter>>', self.on_video_drag_enter)
        self.video_canvas.dnd_bind('<<DragLeave>>', self.on_video_drag_leave)
        
        # æ·»åŠ åŒå‡»äº‹ä»¶ç»‘å®š
        self.video_canvas.bind('<Double-Button-1>', self.on_video_canvas_double_click)


    def handle_av_replacement(self, av_path, replace_media_audio, media_type, initial_start_time=None, initial_end_time=None):
        """å¤„ç†éŸ³é¢‘æ›¿æ¢"""
        try:
            current_scenario = self.get_current_scenario()
            previous_scenario = self.get_previous_scenario()
            next_scenario = self.get_next_scenario()
            scenarios_same_story = self.workflow.scenarios_in_story(current_scenario)

            print(f"ğŸ¬ æ‰“å¼€åˆå¹¶ç¼–è¾‘å™¨ - åª’ä½“ç±»å‹: {media_type}, æ›¿æ¢éŸ³é¢‘: {replace_media_audio}")
            review_dialog = AVReviewDialog(self, av_path, current_scenario, previous_scenario, next_scenario, media_type, replace_media_audio, initial_start_time, initial_end_time)
            
            # ç­‰å¾…å¯¹è¯æ¡†å…³é—­
            self.root.wait_window(review_dialog.dialog)

            if media_type != "clip" :
                transcribe_way = "" if ('transcribe_way' not in review_dialog.result) else review_dialog.result['transcribe_way']
                if transcribe_way == "multiple":
                    for sss in scenarios_same_story:
                        sss[media_type] = current_scenario[media_type]
                        sss[media_type+"_audio"]  = current_scenario[media_type+"_audio"]
                        sss[media_type+"_image"]  = current_scenario[media_type+"_image"]
                self.workflow.save_scenarios_to_json()
                return

            self.workflow.save_scenarios_to_json()

            # media_type == clip
            if (not review_dialog.result) or ('transcribe_way' not in review_dialog.result) or (review_dialog.result['transcribe_way'] == "none"):
                print("åœºæ™¯å†…å®¹æ— å˜åŒ–")
                return

            transcribe_way = review_dialog.result['transcribe_way']
            audio_json = review_dialog.result['audio_json']

            # WAN å‚æ•°ç°åœ¨ä¿å­˜åœ¨å¯¹è¯æ¡†ä¸­ï¼Œä½¿ç”¨åœºæ™¯ä¸­å·²æœ‰çš„å€¼æˆ–é»˜è®¤å€¼
            if "wan_style" not in current_scenario:
                current_scenario["wan_style"] = ""
            if "wan_shot" not in current_scenario:
                current_scenario["wan_shot"] = ""
            if "wan_angle" not in current_scenario:
                current_scenario["wan_angle"] = ""
            if "wan_color" not in current_scenario:
                current_scenario["wan_color"] = ""

            current_scenario["clip_animation"] = ""

            if transcribe_way == "single":
                current_scenario["content"] = "\n".join([segment["content"] for segment in audio_json])
                self.workflow.refresh_scenario(current_scenario)
            elif transcribe_way == "multiple":
                self.workflow.prepare_scenarios_from_json(  raw_scenario=current_scenario,
                                                            raw_index=self.current_scenario_index,
                                                            audio_json=audio_json, 
                                                            style=current_scenario["wan_style"],
                                                            shot=current_scenario["wan_shot"],
                                                            angle=current_scenario["wan_angle"],
                                                            color=current_scenario["wan_color"] )

            messagebox.showinfo("æˆåŠŸ", f"éŸ³é¢‘å·²æˆåŠŸæ›¿æ¢ï¼\n\n")
                
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"éŸ³é¢‘æ›¿æ¢å¤±è´¥: {str(e)}")


    def handle_image_replacement(self, source_image_path):
        """å¤„ç†å›¾åƒæ›¿æ¢"""
        try:
            # è·å–è§†é¢‘å°ºå¯¸
            video_width = self.video_width.get() or "1920"
            video_height = self.video_height.get() or "1080"
            
            # å¯¼å…¥å›¾åƒåŒºåŸŸé€‰æ‹©å¯¹è¯æ¡†
            from gui.image_area_selector_dialog import show_image_area_selector
            
            # æ˜¾ç¤ºå›¾åƒåŒºåŸŸé€‰æ‹©å¯¹è¯æ¡†
            selected_image_path, vertical_line_position, target_field = show_image_area_selector(
                self, source_image_path, video_width, video_height
            )
            
            if selected_image_path is None:
                return  # ç”¨æˆ·å–æ¶ˆäº†é€‰æ‹©
            
            # å­—æ®µåæ˜ å°„
            field_names = {
                "clip_image": "å½“å‰åœºæ™¯å›¾ç‰‡",
                "clip_image_last": "æœ€ååœºæ™¯å›¾ç‰‡"
            }
            
            # å¼¹å‡ºç¡®è®¤å¯¹è¯æ¡†
            dialog = messagebox.askyesno("ç¡®è®¤æ›¿æ¢åœºæ™¯çš„å›¾åƒ/è§†é¢‘", 
                                       f"ç¡®å®šè¦æ›¿æ¢ {field_names.get(target_field, target_field)} å—ï¼Ÿ\nå‚ç›´åˆ†å‰²çº¿ä½ç½®: {vertical_line_position}")
            if not dialog:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(selected_image_path)
                except:
                    pass
                return
            
            current_scenario = self.get_current_scenario()
            self.workflow.replace_scenario_image(current_scenario, selected_image_path, vertical_line_position, target_field)
            
            # åˆ·æ–°GUIæ˜¾ç¤º
            self.refresh_gui_scenarios()
            
            # è®°å½•æ“ä½œ
            print(f"âœ… å›¾åƒå·²æ›¿æ¢åˆ° {field_names.get(target_field, target_field)}ï¼Œå‚ç›´åˆ†å‰²çº¿ä½ç½®: {vertical_line_position}")
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å›¾åƒæ›¿æ¢å¤±è´¥: {str(e)}")


    # è§†é¢‘æ‹–æ‹½ç›¸å…³æ–¹æ³•
    def on_video_drag_enter(self, event):
        """è§†é¢‘æ‹–æ‹½è¿›å…¥æ—¶çš„è§†è§‰åé¦ˆ"""
        self.video_canvas.create_rectangle(0, 0, self.video_canvas.winfo_width(), 
                                         self.video_canvas.winfo_height(), 
                                         outline="blue", width=3, tags="drag_border")


    def on_video_drag_leave(self, event):
        """è§†é¢‘æ‹–æ‹½ç¦»å¼€æ—¶æ¢å¤è§†è§‰çŠ¶æ€"""
        self.video_canvas.delete("drag_border")


    def on_media_drop(self, event):
        self.video_canvas.delete("drag_border")
        
        files = self.root.tk.splitlist(event.data)
        if not files:
            return
        dropped_file = files[0]
        if not os.path.exists(dropped_file):
            return
        
        if is_image_file(dropped_file):
            self.handle_image_replacement(dropped_file)
        elif is_audio_file(dropped_file) or is_video_file(dropped_file):
            from gui.enhanced_media_editor import MediaTypeSelector
            selector = MediaTypeSelector(self.root, dropped_file, self.get_current_scenario())
            replace_media_audio, media_type = selector.show()
            if not media_type:
                return  # ç”¨æˆ·å–æ¶ˆ
            self.handle_av_replacement(dropped_file, replace_media_audio, media_type)

        self.refresh_gui_scenarios()


    def on_video_canvas_configure(self, event):
        """å½“video canvaså°ºå¯¸æ”¹å˜æ—¶ï¼ŒåŠ¨æ€è°ƒæ•´æç¤ºæ–‡æœ¬ä½ç½®"""
        canvas_width = event.width
        canvas_height = event.height
        center_x = canvas_width // 2
        center_y = canvas_height // 2
        
        # æ›´æ–°æ‹–æ‹½æç¤ºæ–‡æœ¬çš„ä½ç½®åˆ°canvasä¸­å¿ƒ
        self.video_canvas.coords("drag_hint", center_x, center_y)


    def on_video_canvas_double_click(self, event):
        current_scenario = self.get_current_scenario()
        from gui.enhanced_media_editor import MediaTypeSelector
        selector = MediaTypeSelector(self.root, None, current_scenario)
        replace_media_audio, media_type = selector.show()
        if not media_type:
            return  # ç”¨æˆ·å–æ¶ˆ
        elif media_type == 'clip':
            dropped_file = get_file_path(current_scenario, "clip")
        elif media_type == 'zero':
            dropped_file = get_file_path(current_scenario, "zero")
        elif media_type == 'one':
            dropped_file = get_file_path(current_scenario, "one")
        else:
            dropped_file = get_file_path(current_scenario, "second")

        self.handle_av_replacement(dropped_file, replace_media_audio, media_type)

        self.refresh_gui_scenarios()


    def on_clip_animation_change(self, event=None):
        current_scenario = self.get_current_scenario()
        current_scenario["clip_animation"] = self.scenario_main_animate.get()
        self.workflow.save_scenarios_to_json()

    def on_video_clip_animation_change(self, event=None):
        """å½“è§†é¢‘æ ‡ç­¾é¡µå®£ä¼ æ¨¡å¼å‘ç”Ÿå˜åŒ–æ—¶çš„å›è°ƒå‡½æ•°"""
        # ä¿å­˜å½“å‰åœºæ™¯çš„å®£ä¼ æ¨¡å¼åˆ°JSON
        current_scenario = self.get_current_scenario()
        current_scenario["clip_animation"] = self.scenario_main_animate.get()
        self.workflow.save_scenarios_to_json()
        self.log_to_output(self.video_output, f"âœ… å®£ä¼ æ¨¡å¼å·²æ›´æ–°ä¸º: {self.scenario_main_animate.get()}")


    def on_image_type_change(self, event=None):
        """å¤„ç†å›¾åƒç±»å‹é€‰æ‹©å˜åŒ–"""
        selected_image_type = self.scenario_second_animation.get()
        print(f"âœ… åœºæ™¯ {self.current_scenario_index + 1} å›¾åƒç±»å‹å·²è®¾ç½®ä¸º: {selected_image_type}")
        
        # ä¿å­˜å›¾åƒç±»å‹åˆ°scenarios JSONæ–‡ä»¶
        self.save_second_animation_to_scenarios_json(self.current_scenario_index, selected_image_type)
        
        # æ ‡è®°é…ç½®å·²æ›´æ”¹
        self._config_changed = True


    def update_scenario_field(self, scenario_index, field_name, field_value):
        """æ›´æ–°å•ä¸ªåœºæ™¯çš„ç‰¹å®šå­—æ®µ"""
        try:
            workflow = self.workflow
            
            if scenario_index >= len(workflow.scenarios):
                print(f"âŒ åœºæ™¯ç´¢å¼• {scenario_index} è¶…å‡ºèŒƒå›´")
                return False
            
            # è°ƒè¯•ï¼šæ˜¾ç¤ºæ›´æ–°å‰çš„çŠ¶æ€
            old_value = workflow.scenarios[scenario_index].get(field_name, "æœªè®¾ç½®")
            print(f"ğŸ” è°ƒè¯•: åœºæ™¯ {scenario_index + 1} çš„ {field_name} ä» '{old_value}' æ›´æ–°ä¸º '{field_value}'")
            
            # æ›´æ–°workflowå†…å­˜ä¸­çš„æ•°æ®
            workflow.scenarios[scenario_index][field_name] = field_value
            
            # éªŒè¯æ›´æ–°
            new_value = workflow.scenarios[scenario_index].get(field_name)
            print(f"âœ… éªŒè¯: åœºæ™¯ {scenario_index + 1} çš„ {field_name} ç°åœ¨æ˜¯ '{new_value}'")
            
            return self.workflow.save_scenarios_to_json()
            
        except Exception as e:
            print(f"âŒ æ›´æ–°åœºæ™¯å­—æ®µå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False


    def update_scenario_fields(self, scenario_index, field_updates):
        """æ‰¹é‡æ›´æ–°å•ä¸ªåœºæ™¯çš„å¤šä¸ªå­—æ®µ"""
        try:
            workflow = self.workflow
            
            if scenario_index >= len(workflow.scenarios):
                print(f"âŒ åœºæ™¯ç´¢å¼• {scenario_index} è¶…å‡ºèŒƒå›´")
                return False
            
            # æ‰¹é‡æ›´æ–°workflowå†…å­˜ä¸­çš„æ•°æ®
            for field_name, field_value in field_updates.items():
                workflow.scenarios[scenario_index][field_name] = field_value
            # ç«‹å³ä¿å­˜åˆ°JSONæ–‡ä»¶
            field_names = list(field_updates.keys())
            return self.workflow.save_scenarios_to_json()
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ›´æ–°åœºæ™¯å­—æ®µå¤±è´¥: {str(e)}")
            return False

        
    def save_second_animation_to_scenarios_json(self, scenario_index, image_type):
        """ä¿å­˜å•ä¸ªåœºæ™¯çš„å›¾åƒç±»å‹åˆ°scenarios JSONæ–‡ä»¶"""
        return self.update_scenario_field(scenario_index, "second_animation", image_type)
        

    def generate_video(self, scenario, previous_scenario, next_scenario, image_typ):
        image_path = get_file_path(scenario, image_typ+"_image")
        image_last_path = get_file_path(scenario, image_typ+"_image_last")

        animate_mode = scenario.get(image_typ+"_animation", "")
        if animate_mode not in config.ANIMATE_TYPES or animate_mode.strip() == "":
            return

        if animate_mode == "2I2V" and not image_last_path:
            animate_mode = "I2V"

        wan_prompt = scenario.get(image_typ+"_prompt", "")
        
        # å¦‚æœ wan_prompt æ˜¯å­—ç¬¦ä¸²ï¼ˆJSONæ ¼å¼ï¼‰ï¼Œå°è¯•è§£æä¸ºå­—å…¸
        if isinstance(wan_prompt, str) and wan_prompt.strip():
            try:
                import json
                p = json.loads(wan_prompt)
                wan_prompt = p
            except:
                print("none json wan_prompt")
        
        # æ£€æŸ¥ prompt æ˜¯å¦ä¸ºç©ºï¼ˆæ”¯æŒå­—ç¬¦ä¸²å’Œå­—å…¸ä¸¤ç§æ ¼å¼ï¼‰
        if not wan_prompt or (isinstance(wan_prompt, str) and wan_prompt.strip() == "") or (isinstance(wan_prompt, dict) and len(wan_prompt) == 0):
            wan_prompt = self.workflow.build_prompt(scenario, "", "", image_typ, animate_mode)

        action_path = get_file_path(scenario, "clip_action")

        sound_path = get_file_path(scenario, "clip_audio")
        if animate_mode == "PS2V":
            previous_sound = None
            next_sound = None

            if previous_scenario:
                previous_sound = get_file_path(previous_scenario, "clip_audio")
                if previous_sound:
                    previous_sound_duration = self.workflow.ffmpeg_audio_processor.get_duration(previous_sound)
                    if previous_sound_duration > 3.0:
                        previous_sound = self.workflow.ffmpeg_audio_processor.audio_cut_fade(previous_sound, previous_sound_duration-3.0, 3.0)
            
            if next_scenario:
                next_sound = get_file_path(next_scenario, "clip_audio")
                if next_sound:
                    if self.workflow.ffmpeg_audio_processor.get_duration(next_sound) > 3.0:
                        next_sound = self.workflow.ffmpeg_audio_processor.audio_cut_fade(next_sound, 0.0, 3.0)
            
            audio_list = []
            if previous_sound:
                scenario["previous_sound_duration"] = self.workflow.ffmpeg_audio_processor.get_duration(previous_sound)
                audio_list.append(previous_sound)
            else:
                scenario["previous_sound_duration"] = 0.0
            if sound_path:
                audio_list.append(sound_path)
            if next_sound:
                scenario["next_sound_duration"] = self.workflow.ffmpeg_audio_processor.get_duration(next_sound)
                audio_list.append(next_sound)
            else:
                scenario["next_sound_duration"] = 0.0

            sound_path = self.workflow.ffmpeg_audio_processor.concat_audios(audio_list)

        self.workflow.rebuild_scenario_video(scenario, image_typ, animate_mode, image_path, image_last_path, sound_path, action_path, wan_prompt)
        self.workflow.save_scenarios_to_json()


    def regenerate_video(self, track):
        """æ‰“å¼€ WAN æç¤ºè¯ç¼–è¾‘å¯¹è¯æ¡†å¹¶ç”Ÿæˆä¸»è½¨é“è§†é¢‘"""
        if track == None:
            track = self.selected_second_track

        scenario = self.get_current_scenario()
        previous_scenario = self.get_previous_scenario()
        next_scenario = self.get_next_scenario()
        
        # å®šä¹‰ç”Ÿæˆè§†é¢‘çš„å›è°ƒå‡½æ•°
        def generate_callback(wan_prompt):
            # ä¿å­˜æç¤ºè¯
            scenario[track+"_prompt"] = wan_prompt
            # ä½¿ç”¨ç¼–è¾‘åçš„ prompt ç”Ÿæˆè§†é¢‘
            self.generate_video(scenario, previous_scenario, next_scenario, track)
            # ç›‘æ§å·²é›†æˆåˆ°åå°å®šæ—¶å™¨ä¸­ï¼Œæ— éœ€å•ç‹¬è°ƒç”¨ trace_scenario_wan_video
            # åå°æ£€æŸ¥ä¼šè‡ªåŠ¨å¼€å§‹ç›‘æ§æœ‰ clip_animation çš„åœºæ™¯
            self.workflow.save_scenarios_to_json()
            self.refresh_gui_scenarios()
        
        # æ˜¾ç¤ºç¼–è¾‘å¯¹è¯æ¡†
        show_wan_prompt_editor(self, self.workflow, generate_callback, scenario, track)
 

    def regenerate_audio(self):
        """éŸ³é¢‘é‡ç”Ÿ"""
        scenario = self.get_current_scenario()
        t, mix_audio = self.workflow.regenerate_audio_item(scenario, 0, self.workflow.language)

        olda, clip_audio = self.workflow.refresh_scenario_media(scenario, "clip_audio", ".wav", mix_audio)

        clip_video = get_file_path(scenario, "clip")
        if clip_video:
            clip_video = self.workflow.ffmpeg_processor.add_audio_to_video(clip_video, clip_audio)
            oldv, clip_video = self.workflow.refresh_scenario_media(scenario, "clip", ".mp4", clip_video)

        self.refresh_gui_scenarios()


    def promo_load_story_content(self):
        """åŠ è½½æ²‰æµ¸æ•…äº‹å†…å®¹åˆ°æ–‡æœ¬æ¡†"""
        try:
            file_path = config.get_project_path(self.get_pid()) + "/short.json"

            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                self.promo_story_json_widget.delete(1.0, tk.END)
                self.promo_story_json_widget.insert(1.0, content)
                print(f"âœ… å·²åŠ è½½æ•…äº‹å†…å®¹: {file_path}")
            else:
                self.promo_story_json_widget.delete(1.0, tk.END)
                self.promo_story_json_widget.insert(1.0, "[]")  # ç©ºçš„JSONæ•°ç»„
                print(f"â„¹ï¸ æœªæ‰¾åˆ°æ•…äº‹æ–‡ä»¶ï¼Œå·²åŠ è½½ç©ºJSON: {file_path}")
        except Exception as e:
            self.promo_story_json_widget.delete(1.0, tk.END)
            self.promo_story_json_widget.insert(1.0, f"åŠ è½½å¤±è´¥: {str(e)}")
            print(f"âŒ åŠ è½½æ•…äº‹å†…å®¹å¤±è´¥: {str(e)}")


    def promo_on_regenerate_dialog(self):
        """é‡æ–°ç”Ÿæˆæ²‰æµ¸æ•…äº‹å¯¹è¯JSON"""
        # åœ¨åå°çº¿ç¨‹ä¸­é‡æ–°ç”Ÿæˆ
        def regenerate_task():
            try:
                male_actor = self.promo_actor_male_number.get()
                if male_actor == "0":
                    male_actor = ""
                else:
                    male_actor = f"There are {self.promo_actor_male_number.get()} male-actors in the story conversation"

                female_actor = self.promo_actor_female_number.get()
                if female_actor == "0":
                    female_actor = ""
                else:
                    female_actor = f"There are {self.promo_actor_female_number.get()} female-actors in the story conversation"

                format_args = config.SHORT_STORY_PROMPT.get("format_args", {}).copy()  # å¤åˆ¶é¢„è®¾å‚æ•°
                format_args.update({  # æ·»åŠ è¿è¡Œæ—¶å˜é‡
                    "narrator": f"Narrator is {self.promo_actor_narrator.get()}",
                    "actor_male": male_actor,
                    "actor_female": female_actor,
                    "language": self.shared_language.cget('text')
                })
                
                # ä½¿ç”¨åˆå¹¶åçš„å‚æ•°æ ¼å¼åŒ–system_prompt
                formatted_system_prompt = config.SHORT_STORY_PROMPT["system_prompt"].format(**format_args)
                print("ğŸ¤– ç³»ç»Ÿæç¤º:")
                print(formatted_system_prompt)

                formatted_user_prompt = self.workflow.transcriber.fetch_text_from_json(config.get_project_path(self.get_pid()) + "/main.srt.json")
                print("ğŸ¤– ç”¨æˆ·æç¤º:")
                print(formatted_user_prompt)

                # è°ƒç”¨generate_immersive_storyï¼Œä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„æ•…äº‹å†…å®¹å’Œæ ¼å¼åŒ–åçš„prompt
                result = self.workflow.summarizer.generate_json_summary(
                    system_prompt = formatted_system_prompt,
                    user_prompt = formatted_user_prompt,
                    output_path = config.get_project_path(self.get_pid()) + "/short.json"
                )
                    
                if result:
                    self.root.after(0, lambda: self.promo_load_story_content())
                    self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", "é‡æ–°ç”Ÿæˆå®Œæˆï¼"))

            except Exception as e:
                error_msg = f"é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}"
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", error_msg))
        
        import threading
        thread = threading.Thread(target=regenerate_task)
        thread.daemon = True
        thread.start()


    def promo_on_generate_audio(self):
        """ç”Ÿæˆæ²‰æµ¸æ•…äº‹éŸ³é¢‘"""
        try:
            # ä¿å­˜å½“å‰ç¼–è¾‘çš„å†…å®¹
            content = self.promo_story_json_widget.get(1.0, tk.END).strip()
            if not content:
                messagebox.showerror("é”™è¯¯", "æ²‰æµ¸æ•…äº‹å†…å®¹ä¸èƒ½ä¸ºç©º")
                return

            # Use current project path or create temp path
            story_path = config.get_project_path(self.get_pid()) + "/short.json"
            audio_path = config.get_media_path(self.get_pid()) + "/short.wav"

            with open(story_path, 'w', encoding='utf-8') as f:
                f.write(content)

            # éªŒè¯JSONæ ¼å¼
            try:
                import json
                json.loads(content)
            except json.JSONDecodeError as e:
                messagebox.showerror("é”™è¯¯", f"JSONæ ¼å¼é”™è¯¯: {str(e)}")
                return
            
            # Log the audio generation task
            self.log_to_output(self.promo_output, f"ğŸµ å¼€å§‹ç”Ÿæˆæ•…äº‹éŸ³é¢‘...")
            self.log_to_output(self.promo_output, f"ğŸ“ æ•…äº‹æ–‡ä»¶: {story_path}")
            self.log_to_output(self.promo_output, f"ğŸ§ éŸ³é¢‘æ–‡ä»¶: {audio_path}")

            # åœ¨åå°çº¿ç¨‹ä¸­ç”ŸæˆéŸ³é¢‘
            def generate_audio_task():
                try:
                    duration = float(self.promo_duration_entry.get().strip())
                    result = self.workflow.create_story_audio(story_path, audio_path, duration)
                    if result:
                        self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", f"å®£ä¼ æ•…äº‹éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼\næ–‡ä»¶: {result}"))
                    else:
                        self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", "éŸ³é¢‘ç”Ÿæˆå¤±è´¥"))
                except Exception as e:
                    error_msg = f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {str(e)}"
                    self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", error_msg))
            
            import threading
            thread = threading.Thread(target=generate_audio_task)
            thread.daemon = True
            thread.start()
                
        except Exception as e:
            error_msg = f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            self.log_to_output(self.promo_output, f"âŒ {error_msg}")
            messagebox.showerror("é”™è¯¯", error_msg)

    def promo_save_story_json_content(self):
        """ä¿å­˜story_json_widgetçš„å†…å®¹åˆ°å¯¹åº”çš„æ–‡ä»¶"""
        try:
            # è·å–JSONå†…å®¹
            json_content = self.promo_story_json_widget.get(1.0, tk.END).strip()
            
            if not json_content:
                messagebox.showwarning("è­¦å‘Š", "JSONå†…å®¹ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜")
                return
            
            # éªŒè¯JSONæ ¼å¼
            try:
                import json
                json.loads(json_content)
            except json.JSONDecodeError as e:
                messagebox.showerror("é”™è¯¯", f"JSONæ ¼å¼é”™è¯¯: {str(e)}")
                return
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            file_path = config.get_project_path(self.get_pid()) + "/short.json"
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # ä¿å­˜æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(json_content)
            
            print(f"âœ… å·²ä¿å­˜JSONå†…å®¹åˆ°: {file_path}")
            self.log_to_output(self.promo_output, f"âœ… JSONå†…å®¹å·²ä¿å­˜åˆ°: {os.path.basename(file_path)}")
            messagebox.showinfo("æˆåŠŸ", f"JSONå†…å®¹å·²ä¿å­˜åˆ°:\n{os.path.basename(file_path)}")
            
        except Exception as e:
            error_msg = f"ä¿å­˜JSONå†…å®¹å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            self.log_to_output(self.promo_output, f"âŒ {error_msg}")
            messagebox.showerror("é”™è¯¯", error_msg)

    def promo_undo_action(self, event=None):
        """Perform undo operation on promo story editor"""
        try:
            self.promo_story_json_widget.edit_undo()
        except tk.TclError:
            pass  # No more undo operations available
        return "break"  # Prevent default handling

    def promo_redo_action(self, event=None):
        """Perform redo operation on promo story editor"""
        try:
            self.promo_story_json_widget.edit_redo()
        except tk.TclError:
            pass  # No more redo operations available
        return "break"  # Prevent default handling


    def update_scenario_buttons_state(self):
        """æ›´æ–°åœºæ™¯æ’å…¥æŒ‰é’®çš„çŠ¶æ€"""
        current_scenario = self.get_current_scenario()
        
        # æ›´æ–°å‰æ’æŒ‰é’®çŠ¶æ€
        if not current_scenario or self.workflow.first_scenario_of_story(current_scenario):
            self.insert_scenario_button.config(state="normal")
        else:
            self.insert_scenario_button.config(state="disabled")
        
        # æ›´æ–°åæ’æŒ‰é’®çŠ¶æ€
        if current_scenario and self.workflow.last_scenario_of_story(current_scenario):
            self.append_scenario_button.config(state="normal")
        else:
            self.append_scenario_button.config(state="disabled")







def main():
    root = TkinterDnD.Tk()

    app = WorkflowGUI(root)
    root.mainloop()

if __name__ == "__main__":
    main()

