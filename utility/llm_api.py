import json
import re
from typing import List, Dict, Union, Any, Generator
from openai import OpenAI
import time
import os
import httpx
import tkinter as tk
import tkinter.scrolledtext as scrolledtext
import tkinter.ttk as ttk


OLLAMA = "gemma3:12b-it-qat"
GPT_MINI = "gpt-5-nano"
#GPT_MINI = "gpt-4o-mini"
GEMINI_2_0_FLASH = "gemini-2.0-flash"  # å…è´¹
#GEMINI_2_5_FLASH = "gemini-2.5-pro-preview-06-05"  # ä»˜è´¹
MANUAL = "manual"

MODELS = {
    GPT_MINI : {
        "url": "https://api.openai.com/v1"
    },
    GEMINI_2_0_FLASH : {
        "url": "https://generativelanguage.googleapis.com/v1beta/openai/"
    },
    OLLAMA : {
        "url": "http://10.0.0.216:11434/v1"
    },
    MANUAL: {
        "url": "http://10.0.0.238:11434/v1"
    }
}


class LLMApi:

    def __init__(self, model: str = None):
        self.model = model

        self.openai_client = OpenAI(
            api_key = os.getenv("OPENAI_API_KEY", ""),
            base_url = MODELS[GPT_MINI]["url"],
            http_client = httpx.Client(timeout=httpx.Timeout(180.0))
        )
        self.google_client = OpenAI(
            api_key = os.getenv("GOOGLE_API_KEY", ""),
            base_url =  MODELS[GPT_MINI]["url"],
            http_client = httpx.Client(timeout=httpx.Timeout(180.0))
        )
        self.ollama_client = OpenAI(
            api_key="ollama",
            base_url =  MODELS[OLLAMA]["url"],
            http_client = httpx.Client(timeout=httpx.Timeout(180.0))
        )
        self.manal_client = OpenAI(
            api_key="ollama",
            base_url =  MODELS[MANUAL]["url"],
            http_client = httpx.Client(timeout=httpx.Timeout(180.0))
        )
    

    def parse_response(self, response: Any) -> str:
        try:
            return response.choices[0].message.content
        except (AttributeError, IndexError) as e:
            return None
    

    def get_json_element(self, json_data: Union[Dict, List], 
                        path: str, 
                        default: Any = None) -> Any:
        """
        ä»JSONæ•°æ®ä¸­è·å–æŒ‡å®šè·¯å¾„çš„å…ƒç´ 
        """
        try:
            current = json_data
            
            # åˆ†å‰²è·¯å¾„
            path_parts = path.split('.')
            
            for part in path_parts:
                if isinstance(current, dict):
                    current = current[part]
                elif isinstance(current, list):
                    # å°è¯•å°†è·¯å¾„éƒ¨åˆ†è½¬æ¢ä¸ºç´¢å¼•
                    try:
                        index = int(part)
                        current = current[index]
                    except (ValueError, IndexError):
                        return default
                else:
                    return default
            
            return current
            
        except (KeyError, TypeError, IndexError):
            return default
    

    def create_message(self, role: str, content: Union[str, List]) -> Dict[str, Union[str, List]]:
        """åˆ›å»ºæ¶ˆæ¯å¯¹è±¡ï¼Œæ”¯æŒæ–‡æœ¬ï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–åŒ…å«å›¾ç‰‡çš„å†…å®¹ï¼ˆåˆ—è¡¨ï¼‰"""
        return {"role": role, "content": content}


    def generate_json_summary(self, system_prompt, user_prompt, output_path=None, expect_list=True) -> Union[Dict, List]:
        max_retries = 3
        for attempt in range(max_retries):
            try:
                content = self.generate_text(system_prompt, user_prompt)
                if not content:
                    return [] if expect_list else {}

                if content and content.strip():
                    # Step 1: Clean the response content
                    content_string = content.strip()
                    content_string = content_string.replace("```json", "").replace("```", "")
                    # æ–¹æ³•1ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ¢è¡Œç¬¦
                    content_string = re.sub(r'\s+', ' ', content_string)  # å°†æ‰€æœ‰è¿ç»­ç©ºç™½å­—ç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼

                    # æ–¹æ³•2ï¼šå¤„ç†æ‰€æœ‰ç±»å‹çš„æ¢è¡Œç¬¦
                    content_string = content_string.replace("\r\n", " ")  # å…ˆå¤„ç†Windowsæ¢è¡Œç¬¦
                    content_string = content_string.replace("\n", " ")    # å†å¤„ç†Unixæ¢è¡Œç¬¦
                    content_string = content_string.replace("\r", " ")    # æœ€åå¤„ç†Macæ¢è¡Œç¬¦

                    # æ–¹æ³•3ï¼šä½¿ç”¨å­—ç¬¦ä¸²çš„splitlines()å’Œjoin()æ–¹æ³•
                    content_string = " ".join(content_string.splitlines())
                    # Step 2: Save cleaned content to file if path provided
                    if output_path:
                        try:
                            with open(output_path, "w", encoding="utf-8") as f:
                                f.write(content_string)
                        except Exception as e:
                            print(f"è­¦å‘Šï¼šæ— æ³•ä¿å­˜JSONæ–‡ä»¶åˆ° {output_path}: {e}")

                    return self.parse_json( content_string=content_string, expect_list=expect_list )

            except Exception as e:
                print(f"ç”ŸæˆJSONæ‘˜è¦å¤±è´¥: {str(e)}")

            if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                print(f"ç­‰å¾… 7 ç§’åé‡è¯•...")
                time.sleep(2)
            else:
                print("æ‰€æœ‰é‡è¯•å°è¯•å·²ç”¨å°½")
                return [] if expect_list else {}


    def parse_json(self, content_string: str, expect_list: bool = False) -> Union[Dict, List]:
        """
        è§£æJSONå­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œæ¸…ç†æ“ä½œ
        
        Args:
            content_string: è¦è§£æçš„JSONå­—ç¬¦ä¸²
            expect_list: æ˜¯å¦æœŸæœ›è¿”å›åˆ—è¡¨æ ¼å¼ã€‚å¦‚æœä¸ºTrueï¼Œä¼šå°†å­—å…¸è‡ªåŠ¨è½¬æ¢ä¸ºåˆ—è¡¨
            
        Returns:
            è§£æåçš„JSONå¯¹è±¡ï¼ˆDictæˆ–Listï¼‰
        """
        
        def validate_and_convert_type(parsed_result: Any) -> Union[Dict, List]:
            """æ ¹æ®expect_listå‚æ•°éªŒè¯å’Œè½¬æ¢ç±»å‹"""
            if expect_list:
                if isinstance(parsed_result, list):
                    return parsed_result
                elif isinstance(parsed_result, dict):
                    print(f"è­¦å‘Šï¼šè¿”å›äº† {type(parsed_result)} è€Œä¸æ˜¯æœŸæœ›çš„åˆ—è¡¨æ ¼å¼ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºåˆ—è¡¨")
                    return [parsed_result]
                else:
                    print(f"è­¦å‘Šï¼šè¿”å›äº† {type(parsed_result)} è€Œä¸æ˜¯æœŸæœ›çš„JSONæ ¼å¼")
                    return []
            else:
                return parsed_result
        
        # Step 1: ç§»é™¤<think>æ ‡ç­¾åŠå…¶å†…å®¹
        if content_string is None or content_string.strip() == "":
            return [] if expect_list else {}
        
        content_string = re.sub(r'<think>.*?</think>', '', content_string, flags=re.DOTALL)
        
        # Step 2: ç§»é™¤é¦–å°¾ç©ºç™½
        content_string = content_string.strip()
        
        # Step 3: é¦–å…ˆå°è¯•ä» ```json ... ``` ä»£ç å—ä¸­æå–JSON
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content_string, re.DOTALL)
        if matches:
            try:
                json_content = matches[0].strip()
                parsed_result = json.loads(json_content)
                return validate_and_convert_type(parsed_result)
            except json.JSONDecodeError as e:
                print(f"ä»ä»£ç å—è§£æJSONå¤±è´¥: {e}")
                # ç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•
        
        # Step 4: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”ï¼ˆæœ€å¸¸è§æƒ…å†µï¼‰
        try:
            parsed_result = json.loads(content_string)
            return validate_and_convert_type(parsed_result)
        except json.JSONDecodeError as e:
            print(f"ç›´æ¥è§£æå¤±è´¥: {e}")
            # ç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•
        
        # Step 5: å°è¯•æå–JSONæ•°ç»„æˆ–å¯¹è±¡ï¼ˆä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å¼ï¼‰
        # æŸ¥æ‰¾ä»¥ [ æˆ– { å¼€å¤´çš„JSONç»“æ„
        json_start = -1
        bracket_count = 0
        brace_count = 0
        in_string = False
        escape_next = False
        
        for i, char in enumerate(content_string):
            if escape_next:
                escape_next = False
                continue
                
            if char == '\\':
                escape_next = True
                continue
                
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
                
            if not in_string:
                if char in '[{':
                    if json_start == -1:
                        json_start = i
                    if char == '[':
                        bracket_count += 1
                    else:
                        brace_count += 1
                elif char in ']}':
                    if char == ']':
                        bracket_count -= 1
                    else:
                        brace_count -= 1
                    
                    # å¦‚æœæ‰€æœ‰æ‹¬å·éƒ½åŒ¹é…äº†ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†å®Œæ•´çš„JSON
                    if json_start != -1 and bracket_count == 0 and brace_count == 0:
                        json_str = content_string[json_start:i+1]
                        try:
                            parsed_result = json.loads(json_str)
                            return validate_and_convert_type(parsed_result)
                        except json.JSONDecodeError:
                            # é‡ç½®è®¡æ•°å™¨ï¼Œå¯»æ‰¾ä¸‹ä¸€ä¸ªå¯èƒ½çš„JSON
                            json_start = -1
                            bracket_count = 0
                            brace_count = 0
        
        # Step 6: æœ€åçš„å°è¯• - è½»é‡çº§æ¸…ç†ï¼ˆä»…ç”¨äºæ˜æ˜¾æŸåçš„JSONï¼‰
        try:
            # ç§»é™¤æ§åˆ¶å­—ç¬¦ï¼ˆé™¤äº†æ¢è¡Œã€å›è½¦ã€åˆ¶è¡¨ç¬¦ï¼‰
            cleaned = ''.join(char for char in content_string if ord(char) >= 32 or char in '\n\r\t')
            
            # ç§»é™¤é¦–å°¾çš„å¼•å·ï¼ˆå¦‚æœæ•´ä¸ªå­—ç¬¦ä¸²è¢«å¼•å·åŒ…è£¹ï¼‰
            if cleaned.startswith('"') and cleaned.endswith('"'):
                cleaned = cleaned[1:-1]
                # å¤„ç†è½¬ä¹‰çš„å¼•å·
                cleaned = cleaned.replace('\\"', '"')
            
            # ä¿®å¤å¤šä½™çš„é€—å·ï¼ˆåªåœ¨æ˜æ˜¾é”™è¯¯çš„æƒ…å†µä¸‹ï¼‰
            cleaned = re.sub(r',\s*([}\]])', r'\1', cleaned)
            
            parsed_result = json.loads(cleaned)
            return validate_and_convert_type(parsed_result)
        except json.JSONDecodeError as e:
            print(f"è½»é‡çº§æ¸…ç†åè§£æå¤±è´¥: {e}")
        
        # Step 7: å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        preview = content_string[:500] if len(content_string) > 500 else content_string
        print(f"JSONè§£æå¤±è´¥ï¼Œå­—ç¬¦ä¸²é¢„è§ˆï¼š\n{preview}")
        raise Exception(f"æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSONã€‚åŸå§‹é•¿åº¦: {len(content_string)} å­—ç¬¦")



    def generate_text(self, system_prompt, user_prompt) -> str:
        if user_prompt is None:
            messages=[
                self.create_message("system", system_prompt)
            ]
        else:
            messages=[
                self.create_message("system", system_prompt),
                self.create_message("user", user_prompt)
            ]

        try:
            # popup dialog to ask user choose from GPT_MINI, GEMINI_2_0_FLASH, or MANUAL, return choice as model
            if self.model == MANUAL or self.model is None:
                model, manual_response = self._show_model_dialog(system_prompt, user_prompt)
                if model == MANUAL:
                    return manual_response
            else:
                model = self.model

            # å‡†å¤‡è¯·æ±‚å‚æ•°ï¼ˆåœ¨ç¡®å®šæ¨¡å‹åè®¾ç½®ï¼‰
            if model == GPT_MINI:
                
                request_params = {
                    "model": model,  # ä½¿ç”¨ç¡®å®šçš„æ¨¡å‹åç§°
                    "messages": messages,
                    "max_completion_tokens": 64000,
                    "stream": False
                }
                response = self.openai_client.chat.completions.create(**request_params)
                return self.parse_response(response)

            elif model == GEMINI_2_0_FLASH:

                request_params = {
                    "model": model,  # ä½¿ç”¨ç¡®å®šçš„æ¨¡å‹åç§°
                    "messages": messages,
                    "temperature": 0.5, # Low (0.0â€“0.3) predictable;  Medium (0.4â€“0.7) creativity & reliability;  High (0.8â€“1.0) very creative
                    "top_p": 0.9,
                    "max_tokens": 64000,
                    "stream": False
                }
                response = self.google_client.chat.completions.create(**request_params)
                return self.parse_response(response)

            else: # model == OLLAMA or model == "gemma3:27b-it-qat":

                request_params = {
                    "model": model,  # ä½¿ç”¨ç¡®å®šçš„æ¨¡å‹åç§°
                    "messages": messages,
                    "max_tokens": 256000,
                    "stream": False
                }
                # OLLAMA æ¨¡å‹ä½¿ç”¨å®é™…çš„æ¨¡å‹åç§°ï¼ˆå¦‚ "gemma3:27b-it-qat"ï¼‰
                with open("ollama_request_params.json", "w", encoding="utf-8") as f:
                    json.dump(request_params, f, ensure_ascii=False, indent=2)

                print(f"ğŸ”„ ä½¿ç”¨ OLLAMA æ¨¡å‹ ({model}) ç”Ÿæˆæ–‡æœ¬...")
                response = self.ollama_client.chat.completions.create(**request_params)
                return self.parse_response(response)

        except Exception as e:
            return None


    def _show_model_dialog(self, system_prompt, user_prompt) -> tuple:
        """å¼¹å‡ºå¯¹è¯æ¡†è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹å¹¶æŸ¥çœ‹/ç¼–è¾‘è¯·æ±‚å’Œå“åº”"""
        # åˆ›å»ºæ ¹çª—å£ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        root = None
        try:
            root = tk._default_root
            if root is None:
                root = tk.Tk()
                root.withdraw()  # éšè—ä¸»çª—å£
        except:
            root = tk.Tk()
            root.withdraw()
        
        # åˆ›å»ºå¯¹è¯æ¡†
        dialog = tk.Toplevel(root)
        dialog.title("é€‰æ‹© LLM æ¨¡å‹")
        dialog.geometry("1000x800")
        dialog.transient(root)
        dialog.grab_set()
        
        # å±…ä¸­æ˜¾ç¤º
        dialog.update_idletasks()
        x = (dialog.winfo_screenwidth() - 1000) // 2
        y = (dialog.winfo_screenheight() - 800) // 2
        dialog.geometry(f"1000x800+{x}+{y}")
        
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(dialog, padding=10)
        main_frame.pack(fill=tk.BOTH, expand=True)
        
        # æ¨¡å‹é€‰æ‹©åŒºåŸŸ
        model_frame = ttk.LabelFrame(main_frame, text="é€‰æ‹© LLM æ¨¡å‹", padding=10)
        model_frame.pack(fill=tk.X, pady=(0, 10))
        
        # ç”¨äºå­˜å‚¨é€‰æ‹©çš„å˜é‡
        selected_model = tk.StringVar(value=MANUAL)  # é»˜è®¤é€‰æ‹© GPT_MINI
        
        # åˆ›å»ºå•é€‰æŒ‰é’®
        ttk.Radiobutton(model_frame, text=f"GPT Mini ({GPT_MINI})", variable=selected_model, value=GPT_MINI).pack(anchor='w', pady=2)
        ttk.Radiobutton(model_frame, text=f"Gemini 2.0 Flash ({GEMINI_2_0_FLASH})", variable=selected_model, value=GEMINI_2_0_FLASH).pack(anchor='w', pady=2)
        ttk.Radiobutton(model_frame, text=f"OLLAMA ({OLLAMA})", variable=selected_model, value=OLLAMA).pack(anchor='w', pady=2)
        ttk.Radiobutton(model_frame, text=f"Manual ({MANUAL})", variable=selected_model, value=MANUAL).pack(anchor='w', pady=2)
        
        # è¯·æ±‚å†…å®¹åŒºåŸŸï¼ˆåˆ†æˆä¸¤éƒ¨åˆ†ï¼‰
        request_frame = ttk.LabelFrame(main_frame, text="è¯·æ±‚å†…å®¹ (Request)", padding=10)
        request_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 10))
        
        # ä¸Šéƒ¨ï¼šSystem Prompt
        ttk.Label(request_frame, text="System Prompt:", font=('TkDefaultFont', 9, 'bold')).pack(anchor='w', pady=(0, 5))
        system_text = scrolledtext.ScrolledText(request_frame, wrap=tk.WORD, height=8)
        system_text.pack(fill=tk.BOTH, expand=True, pady=(0, 10))
        if isinstance(system_prompt, str):
            system_text.insert('1.0', system_prompt)
        
        # åˆ†éš”çº¿
        separator = ttk.Separator(request_frame, orient='horizontal')
        separator.pack(fill=tk.X, pady=5)
        
        # ä¸‹éƒ¨ï¼šUser Prompt
        ttk.Label(request_frame, text="User Prompt:", font=('TkDefaultFont', 9, 'bold')).pack(anchor='w', pady=(5, 5))
        user_text = scrolledtext.ScrolledText(request_frame, wrap=tk.WORD, height=8)
        user_text.pack(fill=tk.BOTH, expand=True)
        if isinstance(user_prompt, str):
            user_text.insert('1.0', user_prompt)
        
        # å“åº”å†…å®¹åŒºåŸŸï¼ˆåªåœ¨ Manual æ¨¡å¼æ—¶æ˜¾ç¤ºï¼‰
        response_frame = ttk.LabelFrame(main_frame, text="å“åº”å†…å®¹ (Response) - ä»… Manual æ¨¡å¼", padding=10)
        ttk.Label(response_frame, text="å“åº” (Response):", font=('TkDefaultFont', 9, 'bold')).pack(anchor='w', pady=(0, 5))
        response_text = scrolledtext.ScrolledText(response_frame, wrap=tk.WORD, height=8)
        response_text.pack(fill=tk.BOTH, expand=True)
        response_text.insert('1.0', '')
        
        # ç”¨äºå­˜å‚¨ç»“æœ
        result_model = [None]
        result_response = [None]

        def update_response_visibility():
            """æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ˜¾ç¤º/éšè—å“åº”åŒºåŸŸ"""
            if selected_model.get() == MANUAL:
                response_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 10))
            else:
                response_frame.pack_forget()
        
        # ç»‘å®šæ¨¡å‹é€‰æ‹©å˜åŒ–äº‹ä»¶
        selected_model.trace('w', lambda *args: update_response_visibility())
        update_response_visibility()  # åˆå§‹æ›´æ–°ï¼ˆé»˜è®¤é€‰æ‹© GPT_MINIï¼Œæ‰€ä»¥å“åº”åŒºåŸŸä¼šè¢«éšè—ï¼‰
        

        def on_ok():
            model = selected_model.get()
            result_model[0] = model
            
            # åªæœ‰åœ¨ Manual æ¨¡å¼æ—¶æ‰è·å–å“åº”å†…å®¹
            if model == MANUAL:
                response_content = response_text.get('1.0', tk.END).strip()
                result_response[0] = response_content
                
                # åªæœ‰åœ¨ Manual æ¨¡å¼æ—¶æ‰åˆå¹¶å¹¶å¤åˆ¶åˆ°å‰ªè´´æ¿
                content = ""
                if isinstance(system_prompt, str):
                    content = content + system_prompt
                if isinstance(user_prompt, str):
                    content = content + " \n\n ----- user-promt ----\n\n" + user_prompt
                dialog.clipboard_clear()
                dialog.clipboard_append(content)
                dialog.update()
            else:
                result_response[0] = None
            
            dialog.destroy()
        

        def on_cancel():
            # å–æ¶ˆæ—¶è¿”å› MANUAL å’Œ None
            result_model[0] = MANUAL
            result_response[0] = None
            dialog.destroy()


        def on_copy():
            content = system_text.get('1.0', tk.END).strip() + " \n\n ----- user-promt ----\n\n" + user_text.get('1.0', tk.END).strip()
            dialog.clipboard_clear()
            dialog.clipboard_append(content)
            dialog.update()


        # æŒ‰é’®æ¡†æ¶
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill=tk.X)
        
        ttk.Button(button_frame, text="ç¡®å®š", command=on_ok).pack(side=tk.RIGHT, padx=5)
        ttk.Button(button_frame, text="å–æ¶ˆ", command=on_cancel).pack(side=tk.RIGHT, padx=5)

        on_copy()

        # ç­‰å¾…å¯¹è¯æ¡†å…³é—­
        dialog.wait_window()
        
        # è¿”å›æ¨¡å‹å’Œå“åº”ï¼ˆå¦‚æœé€‰æ‹©çš„æ˜¯ Manualï¼‰
        model = result_model[0] if result_model[0] is not None else GPT_MINI
        response = result_response[0] if result_response[0] is not None else None
        return model, response


