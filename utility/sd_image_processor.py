import json
import base64
import requests
from PIL import Image
from io import BytesIO
from rembg import remove
import os
import config
# VIDEO_WIDTH and VIDEO_HEIGHT are now obtained from project config via ffmpeg_processor
from typing import Dict, Any
import config_prompt
from . import llm_api


GEN_CONFIG = {
        #"Story":{"url": "http://10.0.0.179:8188", "model": "banana", "seed": 1234567890, "steps": 4, "cfg": 1.0, "workflow":"\\\\10.0.0.179\\wan22\\ComfyUI\\user\\default\\workflows\\nano_banana.json"},
        #"Story":{"url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image-preview:generateContent", "model": "banana", "seed": 1234567890, "steps": 4, "cfg": 1.0},
        "Story":{"url": "http://10.0.0.x:8188",                        "face": "flux","seed": 1234567890, "steps": 4, "cfg": 1.0, "workflow":"\\\\10.0.0.179\\wan22\\ComfyUI\\user\\default\\workflows\\flux_workflow.json"},
        "Host": {"url": "http://10.0.0.x:8188",                        "face": "flux","seed": 1234567890, "steps": 4, "cfg": 1.0, "workflow":"\\\\10.0.0.179\\wan22\\ComfyUI\\user\\default\\workflows\\flux_workflow_figure.json"},
        "SD":   {"url": "http://10.0.0.x:7860/sdapi/v1/txt2img",       "face": "sd",  "seed": 1234567890, "steps": 30,"cfg": 7.0},

        "I2V":    {"url": "http://10.0.0.231:9001/wan/image2video",    "face": "66", "seed": 1234567890, "steps": 4, "cfg": 0.5, "motion_frame":16, "frame_rate":15, "max_frames":91,  "image_width":704, "image_height":400},
        "2I2V":   {"url": "http://10.0.0.231:9001/wan/imagesss2video", "face": "66", "seed": 1234567890, "steps": 4, "cfg": 0.5, "motion_frame":4,  "frame_rate":15, "max_frames":91,  "image_width":704, "image_height":400},

        "S2V":    {"url": "http://10.0.0.222:9001/wan/infinite_s2v",   "face": "66", "seed": 1234567890, "steps": 4, "cfg": 0.5, "motion_frame":5,  "frame_rate":15, "max_frames":196, "image_width":720, "image_height":405},
        "FS2V":   {"url": "http://10.0.0.222:9001/wan/infinite_s2v",   "face": "66", "seed": 1234567890, "steps": 4, "cfg": 0.5, "motion_frame":4,  "frame_rate":15, "max_frames":226, "image_width":672, "image_height":378},
        "WS2V":   {"url": "http://10.0.0.222:9001/wan/infinite_s2v",   "face": "66", "seed": 1234567890, "steps": 4, "cfg": 0.5, "motion_frame":5,  "frame_rate":15, "max_frames":91,  "image_width":468, "image_height":480},
        #"FS2V": {"url": "http://10.0.0.222:9001/wan/infinite_s2v",   "model": "wan", "seed": 1234567890, "steps": 4, "cfg": 1.0, "motion_frame":5,  "frame_rate":15, "max_frames":121, "image_width":683, "image_height":384},
        "AI2V":   {"url": "http://10.0.0.231:9001/wan/action_transfer","face": "66", "seed": 1234567890, "steps": 4, "cfg": 0.5, "motion_frame":5,  "frame_rate":15, "max_frames":121, "image_width":853, "image_height":480}
}


class SDProcessor:


    """
    ÂõæÂÉèÂ§ÑÁêÜÊµÅÊ∞¥Á∫øÁ±ªÔºåÊèê‰æõÂõæÂÉèÂç°ÈÄöÂåñ„ÄÅËÉåÊôØÁßªÈô§Á≠âÂäüËÉΩ
    """
    def __init__(self, workflow):
        self.prompt_url = ""
        self.prompt_model = ""


        self.workflow = workflow
        # Get video dimensions from ffmpeg_processor (will be set after workflow initialization)
        # For now, use default values - they will be updated when workflow is created
        
        self.llm_api = llm_api.LLMApi()

        # Set default image dimensions to match video dimensions
        self.wan_vidoe_count = 0
        self.infinite_vidoe_count = 0


    def resize_image(self, image, width, height):
        """Ë∞ÉÊï¥ÂõæÂÉèÂ§ßÂ∞èÂπ∂Â§ÑÁêÜEXIFÊñπÂêë"""
        # È¶ñÂÖàÂ∞Übase64Â≠óÁ¨¶‰∏≤Ëß£Á†Å‰∏∫‰∫åËøõÂà∂Êï∞ÊçÆ
        if isinstance(image, str):
            # Â¶ÇÊûúÊòØbase64ÁºñÁ†ÅÁöÑÂ≠óÁ¨¶‰∏≤ÔºåÂÖàËß£Á†Å
            image_data = base64.b64decode(image)
        else:
            image_data = image
            
        # ÊâìÂºÄÂõæÂÉè
        img = Image.open(BytesIO(image_data))
        
        try:
            exif = img._getexif()
            if exif:
                # EXIFÊñπÂêëÊ†áÁ≠æ
                orientation_tag = 274  # 0x0112
                if orientation_tag in exif:
                    orientation = exif[orientation_tag]
                    # Ê†πÊçÆ‰∏çÂêåÁöÑÊñπÂêëÂÄºÊóãËΩ¨ÂõæÂÉè
                    if orientation == 3:
                        img = img.rotate(180, expand=True)
                    elif orientation == 6:
                        img = img.rotate(270, expand=True)
                    elif orientation == 8:
                        img = img.rotate(90, expand=True)
        except (AttributeError, KeyError, IndexError):
            pass
        
        # ËΩ¨Êç¢‰∏∫RGBAÂπ∂Ë∞ÉÊï¥Â§ßÂ∞è
        img = img.convert("RGBA")
        resized_img = img.resize(
            (int(width), int(height)),
            Image.LANCZOS
        )
        return resized_img


    def cartoonizeImage(self, image_b64, image_dimen, description, denoising):
        """Â∞ÜÂõæÂÉèÂç°ÈÄöÂåñÂ§ÑÁêÜ"""
        if image_dimen[0] > image_dimen[1]:
            width = 512
            height = 512*image_dimen[1]/image_dimen[0]
        else:
            width = 512*image_dimen[0]/image_dimen[1]
            height = 512

        positive = "pixar art style \n\n---------------\n\n" + description
        negative = "worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name)"
        payload = {
            "init_images": [image_b64],
            "prompt": positive,
            "negative_prompt": negative,
            "steps": 30,
            "denoising_strength": denoising,  # 0.3‚Äì0.7 is typical
            "cfg_scale": 7.0,
            "width": width,
            "height": height,
            "seed": 1234567890,
            "sampler_name": "Euler a"  #"DPM++ 2M" "DPM++ 2M SDE Heun" 
            #"sd_model_checkpoint": "cartoon_model.ckpt",  # Optional if already loaded
        }

        # Generate curl command for debugging
        self._save_curl_command(GEN_CONFIG['SD']['url'], payload, "img2img")
        
        # Send request to AUTOMATIC1111 API
        response = requests.post(GEN_CONFIG['SD']['url'], json=payload, timeout=60)

        # Get and decode result
        r = response.json()

        resized_img = self.resize_image(r['images'][0], image_dimen[0], image_dimen[1])

        buffer = BytesIO()
        resized_img.save(buffer, format="PNG")
        return buffer.getvalue()


    def text2Image_sd(self, positive, negative, url, cfg, seed, steps, width, height):
        print(f"üñºÔ∏è ÂáÜÂ§áÂèëÈÄÅÂà∞IMAGEÊúçÂä°Âô®{url}ÁöÑÂõæÂÉèÂ∞∫ÂØ∏: {width}x{height}")
        
        # Â¶ÇÊûú prompt ÊòØÂ≠óÂÖ∏ÔºåËΩ¨Êç¢‰∏∫ JSON Â≠óÁ¨¶‰∏≤
        if isinstance(positive, dict):
            import json
            positive = json.dumps(positive, ensure_ascii=False)
        if isinstance(negative, dict):
            import json
            negative = json.dumps(negative, ensure_ascii=False)
        
        payload = {
            "prompt": positive,
            "negative_prompt": negative,
            "cfg_scale": cfg,
            "width": width,
            "height": height,
            "steps": steps,
            "seed": seed,
            "sampler_name": "Euler a"
        }
        # Generate curl command for debugging
        self._save_curl_command(url, payload, "txt2img")

        try:
            response = requests.post(url, json=payload, timeout=90)
            # Get and decode result
            r = response.json()
            image_b64 = r['images'][0]
            # Ëß£Á†Åbase64ÂõæÂÉèÊï∞ÊçÆ
            print(f"üîç ÂºÄÂßãËß£Á†Åbase64ÂõæÂÉèÊï∞ÊçÆÔºåÈïøÂ∫¶: {len(image_b64)}")
            return base64.b64decode(image_b64)
        except Exception as e:
            print(f"‚ùå ÂõæÂÉèÁº©ÊîæÂ§±Ë¥•: {str(e)}")
            return None

    
    def text2Image_banana(self, url, workflow, positive, negative, image_list=None, width=None, height=None, cfg=None, seed=None, steps=None):
        """‰ΩøÁî® Banana Ê®°ÂûãÁîüÊàêÊñáÊú¨Âà∞ÂõæÂÉè
        Returns:
            bytes: ÁîüÊàêÁöÑÂõæÂÉèÊï∞ÊçÆÔºåÂ§±Ë¥•Êó∂ËøîÂõû None
        """
        pass


    def png_to_base64(self, image_path):
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
            return f"data:image/png;base64,{encoded_string}"


    def remove_background(self, image_data):
        """ÂéªÈô§ÂõæÂÉèËÉåÊôØ"""
        removed = remove(image_data)
        # reduce the size to get ride of empty top bottom left right 
        
        # ËΩ¨Êç¢‰∏∫PILÂõæÂÉè
        img = Image.open(BytesIO(removed))
        
        # Ëé∑ÂèñÈùûÈÄèÊòéÂå∫ÂüüÁöÑËæπÁïå
        # ÂàõÂª∫ÂõæÂÉèÁöÑalphaÈÄöÈÅì
        alpha = img.getchannel('A')
        
        # ÊâæÂà∞ÈùûÈÄèÊòéÂÉèÁ¥†ÁöÑËæπÁïå
        bbox = alpha.getbbox()
        
        if bbox:
            # Ë£ÅÂâ™ÂõæÂÉèÔºåÂè™‰øùÁïôÈùûÈÄèÊòéÈÉ®ÂàÜ
            cropped_img = img.crop(bbox)
            
            # Â∞ÜË£ÅÂâ™ÂêéÁöÑÂõæÂÉè‰øùÂ≠òÂà∞ÂÜÖÂ≠ò‰∏≠
            output = BytesIO()
            cropped_img.save(output, format='PNG')
            output.seek(0)
            
            return output.getvalue()
        
        # Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞ÈùûÈÄèÊòéÂå∫ÂüüÔºåÂàôËøîÂõûÂéüÂßãÂõæÂÉè
        return removed


    def save_image(self, image, filename, format="WEBP"):
        if os.path.exists(filename):
            os.remove(filename)
        # if image instanceof Image, then save it
        if isinstance(image, Image.Image):
            image.save(filename, format=format)
            return filename
        
        img = Image.open(BytesIO(image))
        img.save(filename, format=format)
        return filename


    def read_image(self, image_path):
        with open(image_path, "rb") as input_file:
            return input_file.read()


    def add_image_to_image(self, top_image, background_image, position):
        try:
            from PIL import Image
            from io import BytesIO
            
            # Load both images
            bg_img = Image.open(BytesIO(background_image))
            top_img = Image.open(BytesIO(top_image))
            
            # Get background image dimensions
            bg_width, bg_height = bg_img.size
            
            # Calculate target height for top image (3/4 of background height)
            target_height = int(bg_height * 5 / 6)
            
            # Calculate target width to maintain aspect ratio
            top_original_width, top_original_height = top_img.size
            aspect_ratio = top_original_width / top_original_height
            target_width = int(target_height * aspect_ratio)
            
            # Convert top image to binary data for resize_image method
            top_buffer = BytesIO()
            top_img.save(top_buffer, format='PNG')
            top_buffer.seek(0)
            top_binary = top_buffer.getvalue()
            
            # Resize top image to 3/4 of background height while keeping aspect ratio
            top_img = self.resize_image(top_binary, target_width, target_height)
            
            # Convert background to RGBA if it's not already
            if bg_img.mode != 'RGBA':
                bg_img = bg_img.convert('RGBA')
            
            # Convert top image to RGBA if it's not already
            if top_img.mode != 'RGBA':
                top_img = top_img.convert('RGBA')
            
            # Get dimensions (top_img has already been resized)
            top_width, top_height = top_img.size
            
            # Calculate position
            if position.lower() == "right":
                x = bg_width - top_width - 20  # 20px margin from right edge
                y = (bg_height - top_height)  # Center vertically
            elif position.lower() == "left":
                x = 20  # 20px margin from left edge
                y = (bg_height - top_height)  # Center vertically
            elif position.lower() == "center":
                x = (bg_width - top_width) // 2  # Center horizontally
                y = (bg_height - top_height)  # Center vertically
            else:
                # Default to center if position is not recognized
                x = (bg_width - top_width) // 2
                y = (bg_height - top_height) // 2
            
            # Ensure the top image doesn't go outside the background bounds
            x = max(0, min(x, bg_width - top_width))
            y = max(0, min(y, bg_height - top_height))
            
            # Create a copy of the background image
            result_img = bg_img.copy()
            
            # Paste the top image onto the background
            result_img.paste(top_img, (x, y), top_img)
            
            # Convert to binary data
            output = BytesIO()
            result_img.save(output, format='PNG')
            output.seek(0)
            
            return output.getvalue()
            
        except Exception as e:
            print(f"‚ùå Error adding image to image: {str(e)}")
            # Return the background image if there's an error
            return background_image


    def _save_curl_command(self, url, payload, api_type):
        """ÁîüÊàêÂπ∂‰øùÂ≠òcurlÂëΩ‰ª§Áî®‰∫éË∞ÉËØï"""
        try:
            debug_dir = os.path.join(config.get_temp_path(self.workflow.pid), "debug_curls")
            os.makedirs(debug_dir, exist_ok=True)
            
            # ÁîüÊàêÊó∂Èó¥Êà≥Áî®‰∫éÊñá‰ª∂Âêç
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ÊØ´ÁßíÁ≤æÂ∫¶
            
            # ÁîüÊàêcurlÂëΩ‰ª§ - Ê†πÊçÆAPIÁ±ªÂûãÈÄâÊã©Ê†ºÂºè
            if api_type == "txt2img" and isinstance(payload, dict) and "prompt" in payload:
                # flux API‰ΩøÁî®multipart/form-dataÊ†ºÂºè
                curl_command = f'curl --location "{url}" \\\n'
                for key, value in payload.items():
                    curl_command += f'  --form \'{key}="{value}"\' \\\n'
                curl_command = curl_command.rstrip(' \\\n')  # ÁßªÈô§ÊúÄÂêéÁöÑÂèçÊñúÊù†
            else:
                # ÂÖ∂‰ªñAPI‰ΩøÁî®JSONÊ†ºÂºè
                curl_command = f'curl -X POST "{url}" \\\n'
                curl_command += '  -H "Content-Type: application/json" \\\n'
                curl_command += f'  -d \'{json.dumps(payload, indent=2, ensure_ascii=False)}\''
            
            # ‰øùÂ≠òÂà∞Êñá‰ª∂
            filename = f"{api_type}_{timestamp}.txt"
            filepath = os.path.join(debug_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"# Stable Diffusion API Debug - {api_type.upper()}\n")
                f.write(f"# Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# URL: {url}\n\n")
                f.write("# CURL Command:\n")
                f.write(curl_command)
                if api_type == "txt2img" and isinstance(payload, dict) and "prompt" in payload:
                    f.write("\n\n# Form Data:\n")
                    for key, value in payload.items():
                        f.write(f"{key}: {value}\n")
                else:
                    f.write("\n\n# Payload JSON (formatted):\n")
                    f.write(json.dumps(payload, indent=2, ensure_ascii=False))
                
            print(f"üîß Ë∞ÉËØïcurlÂëΩ‰ª§Â∑≤‰øùÂ≠òÂà∞: {filepath}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ‰øùÂ≠òcurlÂëΩ‰ª§Êó∂Âá∫Èîô: {str(e)}")


    def open_image_as_base64(self, image_path):
        import base64
        from io import BytesIO
        
        # ÊâìÂºÄÂπ∂ËΩ¨Êç¢ÂõæÁâá‰∏∫ base64
        image = Image.open(image_path)
        
        # Â¶ÇÊûúÂõæÁâáÂ§™Â§ßÔºåÂÖàË∞ÉÊï¥Â§ßÂ∞è‰ª•ËäÇÁúÅ token
        max_size = 1024
        if max(image.size) > max_size:
            image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
        
        # Â§ÑÁêÜ RGBA Ê®°ÂºèÔºàPNG ÈÄèÊòéÂ∫¶ÔºâÔºöÂêàÊàêÂà∞ÁôΩËâ≤ËÉåÊôØ
        if image.mode == 'RGBA':
            background = Image.new('RGB', image.size, (255, 255, 255))
            background.paste(image, mask=image.split()[-1])  # ‰ΩøÁî® alpha ÈÄöÈÅì‰Ωú‰∏∫ mask
            image = background
        elif image.mode not in ('RGB',):
            # ÂÖ∂‰ªñÊ®°ÂºèËΩ¨Êç¢‰∏∫ RGB
            image = image.convert('RGB')
        
        # ËΩ¨Êç¢‰∏∫ base64ÔºàJPEG Ê†ºÂºèÔºâ
        buffered = BytesIO()
        image.save(buffered, format="JPEG", quality=85)
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        return img_base64


    def describe_image(self, img_input):
        """
        ‰ΩøÁî® OpenAI/Gemini API ÊèèËø∞ÂõæÁâá
        
        Args:
            img_input: ÂèØ‰ª•ÊòØÊñá‰ª∂Ë∑ØÂæÑÔºàstrÔºâÊàñ base64 Â≠óÁ¨¶‰∏≤ÔºàstrÔºâ
        
        Returns:
            dict: ÂõæÁâáÊèèËø∞Êï∞ÊçÆÔºåÂ§±Ë¥•Êó∂ËøîÂõû None
        """
        try:
            # Â¶ÇÊûúËæìÂÖ•ÊòØÊñá‰ª∂Ë∑ØÂæÑÔºåÂÖàËΩ¨Êç¢‰∏∫ base64
            if isinstance(img_input, str):
                # Ê£ÄÊü•ÊòØÂê¶ÊòØÊñá‰ª∂Ë∑ØÂæÑÔºàÊñá‰ª∂Â≠òÂú®ÔºåÊàñÂåÖÂê´Ë∑ØÂæÑÂàÜÈöîÁ¨¶Ôºâ
                if os.path.exists(img_input):
                    # Á°ÆËÆ§ÊòØÊñá‰ª∂Ë∑ØÂæÑÔºåËΩ¨Êç¢‰∏∫ base64
                    img_base64 = self.open_image_as_base64(img_input)
                elif '/' in img_input or '\\' in img_input:
                    # ÂåÖÂê´Ë∑ØÂæÑÂàÜÈöîÁ¨¶‰ΩÜÊñá‰ª∂‰∏çÂ≠òÂú®ÔºåÂ∞ùËØï‰Ωú‰∏∫Êñá‰ª∂Ë∑ØÂæÑÂ§ÑÁêÜ
                    # Â¶ÇÊûúÂ§±Ë¥•‰ºöÂú® open_image_as_base64 ‰∏≠ÊäõÂá∫ÂºÇÂ∏∏
                    img_base64 = self.open_image_as_base64(img_input)
                else:
                    # ÂÅáËÆæÊòØ base64 Â≠óÁ¨¶‰∏≤
                    img_base64 = img_input
            else:
                raise ValueError("img_input ÂøÖÈ°ªÊòØÊñá‰ª∂Ë∑ØÂæÑÔºàstrÔºâÊàñ base64 Â≠óÁ¨¶‰∏≤ÔºàstrÔºâ")
            
            # Ê∏ÖÁêÜ base64 Â≠óÁ¨¶‰∏≤ÔºàÁßªÈô§ÂèØËÉΩÁöÑÊç¢Ë°åÁ¨¶„ÄÅÁ©∫Ê†ºÂíå data URI ÂâçÁºÄÔºâ
            img_base64 = img_base64.strip()
            # Â¶ÇÊûúÂåÖÂê´ data URI ÂâçÁºÄÔºåÁßªÈô§ÂÆÉ
            if img_base64.startswith('data:image'):
                img_base64 = img_base64.split(',', 1)[1] if ',' in img_base64 else img_base64
            # ÁßªÈô§ÊâÄÊúâÁ©∫ÁôΩÂ≠óÁ¨¶
            img_base64 = img_base64.replace('\n', '').replace('\r', '').replace(' ', '').replace('\t', '')
            
            system_prompt = config_prompt.IMAGE_DESCRIPTION_SYSTEM_PROMPT
            user_prompt = [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_base64}"
                    }
                }
            ]
            scene_data = self.llm_api.generate_json_summary(system_prompt, user_prompt, "describe_image_response.txt", False)
            return scene_data
        except Exception as e:
            print(f"‚ùå ÂõæÁâáÊèèËø∞Â§±Ë¥•: {str(e)}")
            return None


    def two_image_to_video(self, prompt, file_prefix, first_frame, last_frame, sound_path, animate_mode) :
        server_config = GEN_CONFIG[animate_mode]
        num_frames = server_config["frame_rate"] * self.workflow.ffmpeg_audio_processor.get_duration(sound_path) + 1
        if num_frames > server_config["max_frames"]:
            num_frames = server_config["max_frames"]

        # Â¶ÇÊûú prompt ÊòØÂ≠óÂÖ∏ÔºåËΩ¨Êç¢‰∏∫ JSON Â≠óÁ¨¶‰∏≤
        if isinstance(prompt, dict):
            import json
            prompt = json.dumps(prompt, ensure_ascii=False)

        data = {
            'prompt': prompt,
            "negative_prompt": "",
            'filename_prefix': file_prefix + "_2I2V_",

            'image_width': server_config["image_width"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_height"],
            'image_height': server_config["image_height"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_width"],

            "cfg_scale": server_config["cfg"],
            "steps": server_config["steps"],
            "seed": server_config["seed"],

            'motion_frame': server_config["motion_frame"],
            'frame_rate': server_config["frame_rate"],
            'num_frames': int(num_frames)
        }

        files = {
            'first_frame': first_frame,
            'last_frame': last_frame
        }
        self.post_multipart(
            data=data,
            files=files,
            full_url=server_config["url"]
        )
        self.wan_vidoe_count += 1


    def action_transfer_video(self, prompt, file_prefix, image_path, sound_path, action_path, animate_mode) :
        duration = self.workflow.ffmpeg_audio_processor.get_duration(sound_path)
        if duration <= 0.0:
            print(f"üî¥ Èü≥È¢ëÊó∂Èïø‰∏∫0")
            return

        if isinstance(prompt, dict):
            import json
            prompt = json.dumps(prompt, ensure_ascii=False)

        server_config = GEN_CONFIG[animate_mode]
        fps = server_config["frame_rate"]

        action_path = self.workflow.ffmpeg_processor.refps_video(action_path, str(fps))

        num_frames = int(duration * fps)
        max_frames = server_config["max_frames"]
        if num_frames > max_frames:
            num_frames = max_frames

        data = {
            'prompt': prompt,
            "negative_prompt": "",
            'filename_prefix': file_prefix + "_AI2V_",

            'image_width': server_config["image_width"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_height"],
            'image_height': server_config["image_height"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_width"],

            "cfg_scale": server_config["cfg"],
            "steps": server_config["steps"],
            "seed": server_config["seed"],

            'motion_frame': server_config["motion_frame"],
            'frame_rate': fps,
            'num_frames': int(num_frames)
        }

        files = {
            'image': image_path,
            'action': action_path
        }
        self.post_multipart(
            data=data,
            files=files,
            full_url=server_config["url"]
        )
        self.infinite_vidoe_count += 1


    def sound_to_video(self, prompt, file_prefix, image_path, sound_path, next_sound_path, animate_mode, silence=False) :
        # Â¶ÇÊûú prompt ÊòØÂ≠óÂÖ∏ÔºåËΩ¨Êç¢‰∏∫ JSON Â≠óÁ¨¶‰∏≤
        if isinstance(prompt, dict):
            import json
            prompt = json.dumps(prompt, ensure_ascii=False)

        server_config = GEN_CONFIG[animate_mode]

        if not silence:
            fps = server_config["frame_rate"]
            max_frames = server_config["max_frames"]
            duration = self.workflow.ffmpeg_audio_processor.get_duration(sound_path)
            if int(duration*fps)+1 <= max_frames:
                max_frames = int(duration*fps)+1
                if max_frames % fps == 0:
                    max_frames += 1
            elif next_sound_path:
                batch_sec = (max_frames-1.0)/fps
                batches = int(duration/batch_sec)
                remind_sec = duration - batches*batch_sec
                add_sec = batch_sec - remind_sec - 0.06
                if add_sec > 0.0:
                    next_sound_path = self.workflow.ffmpeg_audio_processor.audio_cut_fade(next_sound_path, 0, add_sec)
                    sound_path = self.workflow.ffmpeg_audio_processor.concat_audios([sound_path, next_sound_path])
                    duration = self.workflow.ffmpeg_audio_processor.get_duration(sound_path)
        else:    
            fps = server_config["frame_rate"]//2
            max_frames = int(server_config["max_frames"]//2)
            if max_frames % 2 == 0:
                max_frames += 1
            duration = self.workflow.ffmpeg_audio_processor.get_duration(sound_path)
            sound_path = self.workflow.ffmpeg_audio_processor.make_silence(duration)

        #num_frames = int(duration * fps)
        #if num_frames % 2 == 0:
        #    num_frames += 1
        #if num_frames > max_frames:
        #    num_frames = max_frames

        if animate_mode in config.ANIMATE_WS2V:
            amode = "_WS2V"
        else:
            amode = "_S2V"

        data = {
            'prompt': prompt,
            "negative_prompt": "",
            'filename_prefix': file_prefix + amode + "_",

            'image_width': server_config["image_width"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_height"],
            'image_height': server_config["image_height"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_width"],

            "cfg_scale": server_config["cfg"],
            "steps": server_config["steps"],
            "seed": server_config["seed"],

            'motion_frame': server_config["motion_frame"],
            'frame_rate': fps,
            'num_frames': int(max_frames)
        }

        files = {
            'image': image_path,
            'sound': sound_path
        }
        self.post_multipart(
            data=data,
            files=files,
            full_url=server_config["url"]
        )
        self.infinite_vidoe_count += 1


    def image_to_video(self, prompt, file_prefix, image_path, sound_path, animate_mode) :
        server_config = GEN_CONFIG[animate_mode]
        num_frames = server_config["frame_rate"] * self.workflow.ffmpeg_audio_processor.get_duration(sound_path) + 1
        if num_frames > server_config["max_frames"]:
            num_frames = server_config["max_frames"]
        
        # Â¶ÇÊûú prompt ÊòØÂ≠óÂÖ∏ÔºåËΩ¨Êç¢‰∏∫ JSON Â≠óÁ¨¶‰∏≤
        if isinstance(prompt, dict):
            import json
            prompt = json.dumps(prompt, ensure_ascii=False)
        
        data = {
            'prompt': prompt,
            "negative_prompt": "",
            'filename_prefix': file_prefix + "_I2V_",

            'image_width': server_config["image_width"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_height"],
            'image_height': server_config["image_height"] if self.workflow.ffmpeg_processor.width > self.workflow.ffmpeg_processor.height else server_config["image_width"],
            
            "cfg_scale": server_config["cfg"],
            "steps": server_config["steps"],
            "seed": server_config["seed"],
            
            'motion_frame': server_config["motion_frame"],
            'frame_rate': server_config["frame_rate"],
            'num_frames': int(num_frames)
        }
        files = {
            'first_frame': image_path
        }

        self.post_multipart(
            data=data,
            files=files,
            full_url=server_config["url"]
        )
        self.wan_vidoe_count += 1


    def post_multipart(self, 
                      full_url: str, 
                      data: Dict[str, Any] = None,
                      files: Dict[str, str] = None) -> requests.Response:
        # Prepare form data
        form_data = data.copy() if data else {}
        
        # Prepare files for upload
        files_to_upload = {}
        if files:
            for field_name, file_path in files.items():
                if not os.path.exists(file_path):
                    raise FileNotFoundError(f"File not found: {file_path}")
                # Open file and add to upload
                files_to_upload[field_name] = open(file_path, 'rb')
        
        try:
            response = requests.post(
                full_url,
                data=form_data,
                files=files_to_upload,
                timeout=60
            )
            
            return response
            
        finally:
            # Close all opened files
            for file_obj in files_to_upload.values():
                file_obj.close()

