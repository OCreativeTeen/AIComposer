Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser




--------------------------



python -m venv venv
      specify  python version  
            (If Python is installed via Windows Store or py launcher)
                py -3.10 -m venv myenv310
                py -3.11 -m venv myenv310
            else 
                C:\Python310\python.exe -m venv myenv310-path
     

venv\Scripts\activate.bat

or  ps
.\venv\Scripts\Activate.ps1



check CUDA version
nvidia-smi



pip install -r requirements.txt


--------------------------

Ctrl + ,  
            Search:
                terminal activate environment
    
                    Python: Terminal Activate Environment is checked (set to true).
                        This setting makes Cursor automatically run the venv\Scripts\activate (or equivalent) command when a new terminal is opened in a workspace with a selected virtual environment interpreter.





Ctrl-Shift-P    
   >   Python: Select Interpreter
            Choose the Python interpreter from your virtual environment (e.g., ./venv/Scripts/python.exe on Windows or ./venv/bin/python on Linux/macOS). This tells Cursor to use the virtual environmentâ€™s Python interpreter.








https://aistudio.google.com/apikey



Great! Now I can see the issue clearly:
MoviePy v2.1.2 vs v2.2.1: There's a version mismatch (pip showed 2.2.1 but runtime shows 2.1.2)
Missing Pillow: This is a critical dependency for image processing
No moviepy.editor module: In newer versions of MoviePy, the structure has changed
The main issues are:
Missing Pillow dependency
Incompatible MoviePy version - The newer versions don't have moviepy.editor




check ,  if some effect on image to video can take benefit of nvidia GPU  process (cuda) ?? if yes, try to use GUP boost.

also is there any other effects besides these lines of code provided ,  which based on nvidia GPU ?



good, help me to add the new effect into this list (to use them)


fo rthe new effect you added to effect_image_to_vidie, please add it to GUI create_image_tab ,  radiobutton for the effect setting & regenerated the video for the effect on image




---------------------------------
Speaker Diarization
---------------------------------
https://github.com/pyannote/pyannote-audio
---------------------------------



pip install yt-dlp openai-whisper ffmpeg-python

or

pip install yt-dlp faster-whisper ffmpeg-python


pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121


        pip uninstall torch -y
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118


pip install --upgrade google-auth-oauthlib google-auth google-api-python-client




 yt-dlp --list-subs https://www.youtube.com/watch?v=xHACoGA275g  




IF USE  CUDA 12.X
    https://developer.nvidia.com/cuda-12-1-0-download-archive
        ä¸‹è½½å¯¹åº”ä½ ç³»ç»Ÿçš„ç‰ˆæœ¬ï¼ˆWindows Installerï¼‰ï¼Œå®‰è£…æ—¶å‹¾é€‰ï¼š
            cuBLAS
            cuDNNï¼ˆå¯é€‰ï¼‰


------------------------------------------------------------------
Youtube Upload 

æ³¨å†Œ Google Cloud é¡¹ç›®
    å‰å¾€ï¼šGoogle Cloud Console
    å¯ç”¨ YouTube Data API v3

åˆ›å»º OAuth 2.0 å‡­æ®
    é€‰æ‹©ã€ŒOAuth å®¢æˆ·ç«¯ IDã€
    ç±»å‹ï¼šDesktop app
    ä¸‹è½½ client_secrets.json


    categoryId="22" æ˜¯ã€ŒPeople & Blogsã€ï¼Œå¯æ›´æ”¹ï¼š
        1: Film & Animation
        10: Music
        22: People & Blogs
        24: Entertainment


stable-Diffusion

IP-Adapter
    https://huggingface.co/h94/IP-Adapter/tree/main/models

------------------------------------------------------------------

from pathlib import Path

path = Path("sc/bs/c.mp3") 
without_ext = str(path.with_suffix(''))
print(without_ext)  # Output: sc/bs/c (or sc\bs\c on Windows)


------------------------------------------------------------------


å¸¸ç”¨ç¬¦å·å­—ç¬¦åˆ—è¡¨
åª’ä½“æ§åˆ¶ç¬¦å·
æ’­æ”¾æ§åˆ¶: â–¶ â—€ â¸ â¹ âº â­ â® â¯
éŸ³é‡: ï¿½ï¿½ ï¿½ï¿½ ğŸ”ˆ ï¿½ï¿½ ğŸ”Š ğŸ”‰ ğŸ”ˆ ï¿½ï¿½
æ—¶é—´: â° â± â² â³ âŒš âŒ›
ç¼–è¾‘å·¥å…·ç¬¦å·
å‰ªåˆ‡: âœ‚ï¸ âœ‚ âœ„ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½
å¤åˆ¶: ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ âœï¸ âœ âœ’ ğŸ–Š ï¿½ï¿½
ç²˜è´´: ï¿½ï¿½ ğŸ“„ ğŸ“
åˆ é™¤: ğŸ—‘ï¸ ï¿½ï¿½ âŒ â âœ– âœ—
åª’ä½“ç›¸å…³ç¬¦å·
è§†é¢‘: ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ğŸ¬ ï¿½ï¿½ ï¿½ï¿½
éŸ³é¢‘: ï¿½ï¿½ ğŸ¶ ğŸ”Š ğŸ”‰ ï¿½ï¿½ ğŸ¤ ï¿½ï¿½ ï¿½ï¿½
å›¾ç‰‡: ï¿½ï¿½ï¸ ï¿½ï¿½ ï¿½ï¿½ï¸ ğŸ“· ğŸ“¸ ğŸ–¼ï¸
æ“ä½œç¬¦å·
åˆ·æ–°/é‡ç½®: ï¿½ï¿½ â†» â†º ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½
è®¾ç½®: âš™ï¸ âš™ ğŸ”§ ğŸ”¨ ï¿½ï¿½ï¸ ï¿½ï¿½
ä¿å­˜: ï¿½ï¿½ ğŸ’¾ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½
åŠ è½½: ï¿½ï¿½ ï¿½ï¿½ ğŸ“‚ ï¿½ï¿½ ğŸ“‚ ğŸ“
å¯¼èˆªç¬¦å·
æ–¹å‘: â¬… â¡ â¬† â¬‡ â†– â†— â†˜ â†™
ç®­å¤´: â† â†’ â†‘ â†“ â†” â†• â†© â†ª
é¡µé¢: â—€ â–¶ â— â–· â—‚ â–¸
çŠ¶æ€ç¬¦å·
æˆåŠŸ: âœ… âœ“ âœ” â˜‘ âœ… âœ…
é”™è¯¯: âŒ â âœ– âœ— âš ï¸ âš  ğŸš« ï¿½ï¿½
ä¿¡æ¯: â„¹ï¸ â„¹ ï¿½ï¿½ ğŸ’¡ ğŸ’¡ ï¿½ï¿½
è­¦å‘Š: âš ï¸ âš  âš ï¸ âš  âš ï¸ âš 
æ•°å­¦ç¬¦å·
åŸºæœ¬: + - Ã— Ã· = â‰  â‰ˆ Â±
æ¯”è¾ƒ: < > â‰¤ â‰¥ â‰¦ â‰§
å…¶ä»–: âˆ âˆ‘ âˆ âˆš âˆ› âˆœ âˆ« âˆ‚
ç‰¹æ®Šç¬¦å·
æ˜Ÿå·: â˜… â˜† â­ ï¿½ï¿½ âœ¨ ğŸ’«
å¿ƒå½¢: â¤ ï¿½ï¿½ ğŸ’š ï¿½ï¿½ ï¿½ï¿½ ğŸ–¤ ï¿½ï¿½ ï¿½ï¿½
å‡ ä½•: â— â—‹ â–  â–¡ â–² â–³ â–¼ â–½ â—† â—‡
çº¿æ¡: â”€ â”‚ â”Œ â” â”” â”˜ â”œ â”¤ â”¬ â”´ â”¼
è¡¨æƒ…ç¬¦å·ï¼ˆé€‚åˆæŒ‰é’®ï¼‰
å¸¸ç”¨: ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ğŸ˜… ğŸ˜‚
å·¥å…·: ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ï¸ âš™ï¸ ğŸ”© ğŸ”« ğŸ’£ ï¿½ï¿½
æ‰‹åŠ¿: ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ âœŒ ï¿½ï¿½ ï¿½ï¿½ ğŸ¤˜ ï¿½ï¿½ ğŸ‘‰
åœ¨ä½ çš„ä»£ç ä¸­å·²ç»ä½¿ç”¨çš„ç¬¦å·ï¼š
â—€ - åé€€
â–¶ - å‰è¿›/æ’­æ”¾
ï¿½ï¿½ - é‡ç½®
âœ‚ï¸ - å‰ªåˆ‡
ï¿½ï¿½ - è§†é¢‘/PIP
â¹ - åœæ­¢
âš ï¸ - è­¦å‘Š
Ã— - ä¹˜å·
ï¿½ï¿½ - æç¤º
ä½ å¯ä»¥æ ¹æ®æŒ‰é’®çš„åŠŸèƒ½é€‰æ‹©åˆé€‚çš„ç¬¦å·ã€‚æ¯”å¦‚ï¼š
æ’­æ”¾æŒ‰é’®ç”¨ â–¶
åœæ­¢æŒ‰é’®ç”¨ â¹
è®¾ç½®æŒ‰é’®ç”¨ âš™ï¸
ä¿å­˜æŒ‰é’®ç”¨ ğŸ’¾
åˆ é™¤æŒ‰é’®ç”¨ ğŸ—‘ï¸
è¿™äº›ç¬¦å·åœ¨å¤§å¤šæ•°ç°ä»£å­—ä½“ä¸­éƒ½èƒ½æ­£ç¡®æ˜¾ç¤ºï¼Œéå¸¸é€‚åˆç”¨äºGUIç•Œé¢çš„æŒ‰é’®æ–‡æœ¬ã€‚






    def _check_output_folder(self, scene_index, scene):
        """æ£€æŸ¥ X:\output æ–‡ä»¶å¤¹ä¸­çš„æ–°è§†é¢‘æ–‡ä»¶"""
        import glob
        import time
        
        clip_animation = scene.get("clip_animation", "")
        if clip_animation not in config.ANIMATE_SOURCE:
            # ä¸éœ€è¦ç›‘æ§çš„åœºæ™¯ï¼Œæ¸…ç†ç›‘æ§è®°å½•
            if scene_index in self.monitoring_scenes:
                del self.monitoring_scenes[scene_index]
            return
        
        output_folder = "X:\\output"
        if not os.path.exists(output_folder):
            return
        
        scene_id = scene.get('id', '')
        
        # åˆå§‹åŒ–ç›‘æ§è®°å½•
        if scene_index not in self.monitoring_scenes:
            self.monitoring_scenes[scene_index] = {
                "found_files": [],
                "start_time": time.time()
            }
        
        monitor_info = self.monitoring_scenes[scene_index]
        
        # æŒç»­ç›‘æ§ï¼Œä¸è®¾ç½®è¶…æ—¶é™åˆ¶ï¼Œç›´åˆ°GUIé€€å‡ºæˆ–æ‰¾åˆ°æ–‡ä»¶
        
        try:
            if clip_animation == "WS2V":
                pattern = os.path.join(output_folder, f"{self.get_pid()}_{scene_id}_L_WS2V_*-audio.mp4")
                left_files = glob.glob(pattern)

                pattern = os.path.join(output_folder, f"{self.get_pid()}_{scene_id}_R_WS2V_*-audio.mp4")
                right_files = glob.glob(pattern)
                
                # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ–‡ä»¶
                new_left_files = [f for f in left_files if f not in self.processed_output_files]
                new_right_files = [f for f in right_files if f not in self.processed_output_files]
                
                # æ£€æŸ¥æ˜¯å¦ä¸¤è¾¹éƒ½æœ‰æ–‡ä»¶
                if new_left_files and new_right_files:
                    # æ’åºç¡®ä¿é…å¯¹çš„ä¸€è‡´æ€§
                    new_left_files.sort()
                    new_right_files.sort()
                    
                    # å–æ¯ç»„çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶
                    left_file = new_left_files[0]
                    right_file = new_right_files[0]
                    
                    print(f"ğŸ¬ å‘ç°å·¦ä¾§è§†é¢‘: {os.path.basename(left_file)}")
                    print(f"ğŸ¬ å‘ç°å³ä¾§è§†é¢‘: {os.path.basename(right_file)}")
                    
                    # å°†è¿™ä¸¤ä¸ªæ–‡ä»¶æ”¾å…¥ found_files
                    files_to_process = [left_file, right_file]
                    
                    # æ ‡è®°æ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶ä¸ºå·²å¤„ç†ï¼ˆä¸ä»…æ˜¯é…å¯¹çš„ä¸¤ä¸ªï¼‰
                    for file_path in left_files + right_files:
                        self.processed_output_files.add(file_path)
                    
                    # åœ¨ä¸»çº¿ç¨‹ä¸­å¤„ç†æ–‡ä»¶
                    self.root.after(0, lambda idx=scene_index, files=files_to_process: 
                        self._process_output_files(idx, files, "dual"))
                    
                    # å¤„ç†å®Œæˆï¼Œç§»é™¤ç›‘æ§
                    del self.monitoring_scenes[scene_index]

            elif clip_animation in config.ANIMATE_TARGET: # without WS2V
                # æŸ¥æ‰¾ä»¥åœºæ™¯IDå¼€å¤´çš„mp4æ–‡ä»¶
                if clip_animation == "I2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scene_id}_I2V_*.mp4")
                elif clip_animation == "2I2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scene_id}_2I2V_*.mp4")
                elif clip_animation == "S2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scene_id}_S2V_*-audio.mp4")
                elif clip_animation == "FS2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scene_id}_FS2V_*-audio.mp4")
                elif clip_animation == "AI2V":
                    pattern = os.path.join(output_folder, f"{self.get_pid()}_{scene_id}_AI2V_*.mp4")

                left_files = glob.glob(pattern)
                
                if not monitor_info["found_files"]:
                    monitor_info["found_files"] = left_files
                    return
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶
                new_files = [f for f in left_files if f not in monitor_info["found_files"] and f not in self.processed_output_files]
                if new_files:
                    for file_path in new_files:
                        print(f"ğŸ¬ å‘ç°æ–°è§†é¢‘æ–‡ä»¶: {os.path.basename(file_path)}")
                        monitor_info["found_files"].append(file_path)
                        self.processed_output_files.add(file_path)
                    
                    # åœ¨ä¸»çº¿ç¨‹ä¸­å¤„ç†æ–‡ä»¶
                    self.root.after(0, lambda idx=scene_index, files=new_files: 
                        self._process_output_files(idx, files, "single"))
                    
                    # å¤„ç†å®Œæˆï¼Œç§»é™¤ç›‘æ§
                    del self.monitoring_scenes[scene_index]
            
        
        except Exception as e:
            print(f"âŒ æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")


    
    def _process_output_files(self, scene_index, files, file_type):
        """å¤„ç†ä» X:\output å‘ç°çš„æ–‡ä»¶"""
        try:
            if scene_index >= len(self.workflow.scenes):
                return
            
            scene = self.workflow.scenes[scene_index]
            
            if file_type == "single":
                self.workflow._process_single_files(scene, files)
            elif file_type == "dual":
                self.workflow._process_dual_files(scene, files)
            
            # å¤„ç†å®Œæˆååˆ·æ–°GUI
            self.root.after(0, lambda: self.refresh_gui_scenes())
            
        except Exception as e:
            print(f"âŒ å¤„ç†è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    





    def load_scenes(self):
        self.scenes = []
        scenes_file = config.get_scenes_path(self.pid)
        if not os.path.exists(scenes_file):
            return

        with open(scenes_file, "r", encoding="utf-8") as f:
            self.scenes = json.load(f)

        if len(self.scenes) == 0:
            #background_image = self.find_default_background_media("jpeg")
            #background_music = self.find_default_background_music("mp3")
            #background_video = self.ffmpeg_processor.image_audio_to_video(background_image, background_music, 1)
            #self.add_root_scene(0, self.story_site, background_image, background_music, background_video, False)
            #self.save_scenes_to_json()
            return
            

        changed = False    
        for scene in self.scenes:
            zero_video = get_file_path(scene, "zero")
            zero_audio = get_file_path(scene, "zero_audio")
            zero_image = get_file_path(scene, "zero_image")

            if not zero_audio:
                if zero_video:
                    oldv, zero_audio = self.refresh_scene_media(scene, "zero_audio", ".wav", self.ffmpeg_audio_processor.extract_audio_from_video(zero_video))
                else:
                    olda, zero_audio = self.refresh_scene_media(scene, "zero_audio", ".wav", self.find_default_background_music("mp3"))
                ss = self.scenes_in_story(scene)
                for s in ss:
                    s["zero_audio"] = zero_audio
                changed = True
            if not zero_image:
                zero_image = self.find_default_background_media("jpeg")
                oldi, zero_image = self.refresh_scene_media(scene, "zero_image", ".webp", zero_image)
                ss = self.scenes_in_story(scene)
                for s in ss:
                    s["zero_image"] = zero_image
                changed = True
            if not zero_video:
                zero_video = self.ffmpeg_processor.image_audio_to_video(zero_image, zero_audio, 1)
                oldv, zero_video = self.refresh_scene_media(scene, "zero", ".mp4", zero_video)
                ss = self.scenes_in_story(scene)
                for s in ss:
                    s["zero"] = zero_video
                changed = True


        for scene in self.scenes:
            clip_audio = get_file_path(scene, "clip_audio")
            clip_video = get_file_path(scene, "clip")
            clip_image = get_file_path(scene, "clip_image")
            if not clip_audio:
                if clip_video:
                    olda, clip_audio = self.refresh_scene_media(scene, "clip_audio", ".wav", self.ffmpeg_audio_processor.extract_audio_from_video(clip_video))
                else:
                    olda, clip_audio = self.refresh_scene_media(scene, "clip_audio", ".wav", self.find_default_background_music("mp3"))
                changed = True
            if not clip_image:
                oldi, clip_image = self.refresh_scene_media(scene, "clip_image", ".webp", self.find_default_background_media("jpeg"))
                changed = True
            if not clip_video:
                clip_video = self.ffmpeg_processor.image_audio_to_video(clip_image, clip_audio, 1)
                oldv, clip_video = self.refresh_scene_media(scene, "clip", ".mp4", clip_video)
                changed = True

            second_audio = get_file_path(scene, "second_audio")
            second_image = get_file_path(scene, "second_image")
            second_video = get_file_path(scene, "second")
            if not second_audio:
                if second_video:
                    olda, second_audio = self.refresh_scene_media(scene, "second_audio", ".wav", self.ffmpeg_audio_processor.extract_audio_from_video(second_video))
                else:
                    olda, second_audio = self.refresh_scene_media(scene, "second_audio", ".wav", self.find_default_background_music("mp3"))
                changed = True
            if not second_image:
                oldi, second_image = self.refresh_scene_media(scene, "second_image", ".webp", self.find_default_background_media("jpeg"))
                changed = True
            if not second_video:
                second_video = self.ffmpeg_processor.image_audio_to_video(second_image, second_audio, 1)
                oldv, second_video = self.refresh_scene_media(scene, "second", ".mp4", second_video)
                changed = True

        for scene in self.scenes:
            start_time_in_story, clip_duration, story_duration, indx, count, is_story_last_clip = self.get_scene_detail(scene)
            if is_story_last_clip:
                zero_audio = get_file_path(scene, "zero_audio")
                clip_video = get_file_path(scene, "clip")
                clip_audio = get_file_path(scene, "clip_audio")
                if zero_audio:
                    zero_audio_duration = self.ffmpeg_audio_processor.get_duration(zero_audio)
                    if zero_audio_duration > start_time_in_story + clip_duration + 0.1: # need to fix
                        a = self.ffmpeg_audio_processor.extend_audio(clip_audio, 0, zero_audio_duration-start_time_in_story)
                        olda, a = self.refresh_scene_media(scene, "clip_audio", ".wav", a)
                        v = self.ffmpeg_processor.add_audio_to_video(clip_video, a)
                        self.refresh_scene_media(scene, "clip", ".mp4", v)

        if changed:
            self.save_scenes_to_json()




    def sync_scene_audio(self, scene, force=False):
        #clip_image = get_file_path(scene, "clip_image")
        # second = scene.get("second")
        zero = get_file_path(scene, "zero")
        if not zero:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°zeroè§†é¢‘")
            return None

        zero_audio = get_file_path(scene, "zero_audio")
        if not zero_audio:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°zeroéŸ³é¢‘")
            return None

        zero_image = get_file_path(scene, "zero_image")
        if not zero_image:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°zeroå›¾ç‰‡")
            return None

        clip_video = get_file_path(scene, "clip")
        if not clip_video or force:
            oldv, clip_video = self.refresh_scene_media(scene, "clip", ".mp4", zero, True)

        clip_audio = get_file_path(scene, "clip_audio")
        if not clip_audio or force:
            olda, clip_audio = self.refresh_scene_media(scene, "clip_audio", ".wav", zero_audio, True)

        clip_image = get_file_path(scene, "clip_image")
        if not clip_image or force:
            oldi, clip_image = self.refresh_scene_media(scene, "clip_image", ".webp", zero_image, True)

        return clip_audio










    def visualize_scenes(self, audio_path, audio_json, general_location, style, shot, angle, color):
        system_prompt = config_prompt.VISUAL_STORY_SUMMARIZATION_SYSTEM_PROMPT.format(
            language=config.LANGUAGES[self.language],
            length=512
        )

        text_summary = self.llm_api.generate_text_summary(
                            system_prompt, 
                            "\n".join([segment["content"] for segment in audio_json])
                        )
        text_summary = text_summary + "\nThe story end like ... " + audio_json[-1]["content"]

        raw_json_path = f"{config.get_project_path(self.pid)}/{Path(audio_path).stem}.json"

        system_prompt = config_prompt.SCENE_SUMMARY_SYSTEM_PROMPT
        system_prompt = system_prompt + f"\n***FYI*** Generally, video/image is in \'{style}\' style &  \'{color}\' colors; the camera using \'{shot}\' shot, in \'{angle}\' angle."

        user_prompt = json.dumps(audio_json, ensure_ascii=False, indent=2)

        raw_scenes = self.llm_api.generate_json_summary(system_prompt, user_prompt, raw_json_path)

        for i, scene_data in enumerate(raw_scenes):
            scene_data.update({
                # "effect": config.get_next_special_effect(),
                # "raw_scene_index": f"{audio_stem}_raw_{i}",
                "clip_animation": "",
                "second_animation": "",
                "main_audio": audio_path,
                "story_summary": text_summary
            })

        with open(raw_json_path, "w", encoding="utf-8") as f:
            json.dump(raw_scenes, f, ensure_ascii=False, indent=2)

        print(f"raw scenes summary done for {audio_path}...")
        return raw_scenes, raw_json_path






        system_prompt = config_prompt.VISUAL_STORY_SUMMARIZATION_SYSTEM_PROMPT.format(
            language=config.LANGUAGES[self.language],
            length=512
        )
        text_summary = self.llm_api.generate_text(
                            system_prompt, 
                            "\n".join([segment["content"] for segment in audio_json])
                        )
        text_summary = text_summary + "\nThe story end like ... " + audio_json[-1]["content"]











Complete List of Chinese Voice IDs (Speech-02 HD / System Voices)

These IDs are usable via the API (i.e. â€œsystem voice_idâ€, not clone voices).

Style / Label	Voice ID
é’æ¶©é’å¹´ (young male, fresh)	male-qn-qingse 
resource.ppio.com

ç²¾è‹±é’å¹´ (elite youth male)	male-qn-jingying 
resource.ppio.com

éœ¸é“é’å¹´ (domineering youth male)	male-qn-badao 
resource.ppio.com

é’å¹´å¤§å­¦ç”Ÿ (college youth male)	male-qn-daxuesheng 
resource.ppio.com

å°‘å¥³éŸ³è‰² (young girl)	female-shaonv 
resource.ppio.com

å¾¡å§éŸ³è‰² (cool-mature young woman)	female-yujie 
resource.ppio.com

æˆç†Ÿå¥³æ€§ (mature female)	female-chengshu 
resource.ppio.com

ç”œç¾å¥³æ€§ (sweet female)	female-tianmei 
resource.ppio.com

ç”·æ€§ä¸»æŒäºº (male presenter / host)	presenter_male 
resource.ppio.com

å¥³æ€§ä¸»æŒäºº (female presenter / host)	presenter_female 
resource.ppio.com

ç”·æ€§æœ‰å£°ä¹¦ 1 (audiobook male style 1)	audiobook_male_1 
resource.ppio.com

ç”·æ€§æœ‰å£°ä¹¦ 2 (audiobook male style 2)	audiobook_male_2 
resource.ppio.com

å¥³æ€§æœ‰å£°ä¹¦ 1 (audiobook female style 1)	audiobook_female_1 
resource.ppio.com

å¥³æ€§æœ‰å£°ä¹¦ 2 (audiobook female style 2)	audiobook_female_2 
resource.ppio.com

é’æ¶©é’å¹´-beta	male-qn-qingse-jingpin 
resource.ppio.com

ç²¾è‹±é’å¹´-beta	male-qn-jingying-jingpin 
resource.ppio.com

éœ¸é“é’å¹´-beta	male-qn-badao-jingpin 
resource.ppio.com

é’å¹´å¤§å­¦ç”Ÿ-beta	male-qn-daxuesheng-jingpin 
resource.ppio.com

å°‘å¥³-beta	female-shaonv-jingpin 
resource.ppio.com

å¾¡å§-beta	female-yujie-jingpin 
resource.ppio.com

æˆç†Ÿå¥³æ€§-beta	female-chengshu-jingpin 
resource.ppio.com

ç”œç¾å¥³æ€§-beta	female-tianmei-jingpin 
resource.ppio.com

èªæ˜ç”·ç«¥ (smart boy)	clever_boy 
resource.ppio.com

å¯çˆ±ç”·ç«¥ (cute boy)	cute_boy 
resource.ppio.com

èŒèŒå¥³ç«¥ (cute girl)	lovely_girl 
resource.ppio.com

å¡é€šçŒªå°çª (cartoon pig â€œXiao Qiâ€)	cartoon_pig 
resource.ppio.com

ç—…å¨‡å¼Ÿå¼Ÿ (sickly cute little brother)	bingjiao_didi 
resource.ppio.com

ä¿Šæœ—ç”·å‹ (handsome boyfriend)	junlang_nanyou 
resource.ppio.com

çº¯çœŸå­¦å¼Ÿ (innocent junior schoolboy)	chunzhen_xuedi 
resource.ppio.com

å†·æ·¡å­¦é•¿ (â€œaloof senior studentâ€)	lengdan_xiongzhang 
resource.ppio.com

éœ¸é“å°‘çˆ· (domineering young master)	badao_shaoye 
resource.ppio.com

ç”œå¿ƒå°ç² (sweetheart â€œXiaolingâ€)	tianxin_xiaoling 
resource.ppio.com

ä¿çš®èŒå¦¹ (playful cute girl)	qiaopi_mengmei 
resource.ppio.com

å¦©åªšå¾¡å§ (seductive older sister style)	wumei_yujie 
resource.ppio.com

å—²å—²å­¦å¦¹ (â€œcoquettish younger female studentâ€)	diadia_xuemei 
resource.ppio.com

æ·¡é›…å­¦å§ (elegant senior female student)	danya_xuejie 
resource.ppio.com