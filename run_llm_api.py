#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
LLM API æµ‹è¯•ç¨‹åº
æµ‹è¯• utility.llm_api.py ä¸­çš„æ‰€æœ‰æ¨¡å‹å’ŒåŠŸèƒ½
"""

import os
import time
import json
from typing import Dict, List, Any
from utility.llm_api import LLMApi

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
# os.environ["OPENAI_API_KEY"] = "ä½ çš„OpenAI API Key"
# os.environ["GOOGLE_API_KEY"] = "ä½ çš„Google API Key"

class LLMApiTester:
    """LLM API æµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.test_results = {}
        self.test_message = [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Œå¹¶å›ç­”ï¼š1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
        ]
        self.json_test_message = [
            {"role": "user", "content": "è¯·ä»¥JSONæ ¼å¼è¿”å›ä½ çš„ä¿¡æ¯ï¼ŒåŒ…å«nameï¼ˆåå­—ï¼‰ã€versionï¼ˆç‰ˆæœ¬ï¼‰ã€featuresï¼ˆç‰¹æ€§åˆ—è¡¨ï¼‰ä¸‰ä¸ªå­—æ®µã€‚"}
        ]
    
    def print_separator(self, title: str):
        """æ‰“å°åˆ†éš”çº¿"""
        print("\n" + "="*60)
        print(f" {title} ")
        print("="*60)
    
    def print_test_header(self, test_name: str):
        """æ‰“å°æµ‹è¯•å¤´éƒ¨"""
        print(f"\nğŸ§ª æµ‹è¯•ï¼š{test_name}")
        print("-" * 40)
    
    def test_model(self, model_name: str) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        self.print_test_header(f"æ¨¡å‹ {model_name}")
        
        test_result = {
            "model": model_name,
            "basic_chat": {"success": False, "response": "", "error": ""},
            "json_response": {"success": False, "response": "", "error": ""},
            "stream_response": {"success": False, "response": "", "error": ""},
            "response_time": 0
        }
        
        try:
            # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
            api = LLMApi(model=model_name)
            print(f"âœ… æˆåŠŸåˆå§‹åŒ–æ¨¡å‹ï¼š{model_name}")
            
            # æµ‹è¯•1ï¼šåŸºç¡€èŠå¤©
            print("\nğŸ“ æµ‹è¯•åŸºç¡€èŠå¤©åŠŸèƒ½...")
            start_time = time.time()
            
            response_text = api.generate_text(self.test_message, "")
            test_result["response_time"] = time.time() - start_time
            test_result["basic_chat"]["success"] = True
            test_result["basic_chat"]["response"] = response_text[:200] + "..." if len(response_text) > 200 else response_text
            
            print(f"âœ… åŸºç¡€èŠå¤©æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ“„ å“åº”å†…å®¹ï¼š{test_result['basic_chat']['response']}")
            print(f"â±ï¸ å“åº”æ—¶é—´ï¼š{test_result['response_time']:.2f}ç§’")
            
        except Exception as e:
            test_result["basic_chat"]["error"] = str(e)
            print(f"âŒ åŸºç¡€èŠå¤©æµ‹è¯•å¤±è´¥ï¼š{e}")
        
        # æµ‹è¯•2ï¼šJSONå“åº”
        try:
            print("\nğŸ”„ æµ‹è¯•JSONå“åº”åŠŸèƒ½...")
            

            
            json_response = self.call_with_json_response(
                messages=self.json_test_message,
                temperature=0.3,
                max_tokens=300
            )
            
            test_result["json_response"]["success"] = True
            test_result["json_response"]["response"] = json_response
            
            print(f"âœ… JSONå“åº”æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ“„ JSONå†…å®¹ï¼š{json.dumps(json_response, ensure_ascii=False, indent=2)}")
            
        except Exception as e:
            test_result["json_response"]["error"] = str(e)
            print(f"âŒ JSONå“åº”æµ‹è¯•å¤±è´¥ï¼š{e}")
        
        return test_result
    

    def call_with_json_response(self, 
                               messages: List[Dict[str, str]], 
                               extract_json: bool = True,
                               expect_list: bool = False,
                               allow_dict_to_list: bool = True,
                               output_file_path: Optional[str] = None,
                               **kwargs) -> Union[Dict, List, str]:
        response = self.create_completion(messages, **kwargs)
        response_text = self.parse_response(response)
        print("------------ text ------------")
        print(response_text)
        print("--------------------------------")
        if extract_json:
            try:
                json_data = self.parse_and_save_json(
                    response_content=response_text,
                    output_file_path=output_file_path,
                    expect_list=expect_list,
                    allow_dict_to_list=allow_dict_to_list
                )
                print("--------enhanced json parsing------------")
                print(json_data)
                print("--------------------------------")
                return json_data
            except Exception as e:
                print(f"Enhanced JSON parsing failed: {e}")
                print("Falling back to basic extraction...")
                # Fallback to old method if enhanced parsing fails
                json_data = self.extract_json_from_response(response_text)
                print("--------fallback json extraction------------")
                print(json_data)
                print("--------------------------------")
                return json_data if json_data is not None else response_text
        else:
            return response_text

    
    def test_all_models(self):
        """æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        self.print_separator("å¼€å§‹æµ‹è¯•æ‰€æœ‰LLMæ¨¡å‹")
        
        model_name = LLMApi.GPT_OSS
        api = LLMApi(model_name)
        
        try:
            result = self.test_model(model_name)
            self.test_results[model_name] = result
        except Exception as e:
            print(f"âŒ æ¨¡å‹ {model_name} æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼š{e}")
            self.test_results[model_name] = {
                "model": model_name,
                "basic_chat": {"success": False, "error": str(e)},
                "json_response": {"success": False, "error": str(e)},
                "stream_response": {"success": False, "error": str(e)},
                "response_time": 0
            }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ LLM API æµ‹è¯•ç¨‹åº")
    print("ğŸ“ æµ‹è¯•å†…å®¹ï¼šutility.llm_api.py ä¸­çš„æ‰€æœ‰æ¨¡å‹å’ŒåŠŸèƒ½")
    
    tester = LLMApiTester()
    
    try:
        # æµ‹è¯•æ‰€æœ‰æ¨¡å‹
        tester.test_all_models()
        
        # æµ‹è¯•å·¥å…·å‡½æ•°
        tester.test_utility_functions()
        
        # ç”ŸæˆæŠ¥å‘Š
        tester.generate_report()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")
    
    print("\nğŸ æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()
