#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
LLM API æµ‹è¯•ç¨‹åº
æµ‹è¯• utility.llm_api.py ä¸­çš„æ‰€æœ‰æ¨¡å‹å’ŒåŠŸèƒ½
"""

import os
import time
import json
from typing import Dict, List, Any
from utility.llm_api import LLMApi

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
# os.environ["OPENAI_API_KEY"] = "ä½ çš„OpenAI API Key"
# os.environ["GOOGLE_API_KEY"] = "ä½ çš„Google API Key"

class LLMApiTester:
    """LLM API æµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.test_results = {}
        self.test_message = [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Œå¹¶å›ç­”ï¼š1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
        ]
        self.json_test_message = [
            {"role": "user", "content": "è¯·ä»¥JSONæ ¼å¼è¿”å›ä½ çš„ä¿¡æ¯ï¼ŒåŒ…å«nameï¼ˆåå­—ï¼‰ã€versionï¼ˆç‰ˆæœ¬ï¼‰ã€featuresï¼ˆç‰¹æ€§åˆ—è¡¨ï¼‰ä¸‰ä¸ªå­—æ®µã€‚"}
        ]
    
    def print_separator(self, title: str):
        """æ‰“å°åˆ†éš”çº¿"""
        print("\n" + "="*60)
        print(f" {title} ")
        print("="*60)
    
    def print_test_header(self, test_name: str):
        """æ‰“å°æµ‹è¯•å¤´éƒ¨"""
        print(f"\nğŸ§ª æµ‹è¯•ï¼š{test_name}")
        print("-" * 40)
    
    def test_model(self, model_name: str) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        self.print_test_header(f"æ¨¡å‹ {model_name}")
        
        test_result = {
            "model": model_name,
            "basic_chat": {"success": False, "response": "", "error": ""},
            "json_response": {"success": False, "response": "", "error": ""},
            "stream_response": {"success": False, "response": "", "error": ""},
            "response_time": 0
        }
        
        try:
            # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
            api = LLMApi(model=model_name)
            print(f"âœ… æˆåŠŸåˆå§‹åŒ–æ¨¡å‹ï¼š{model_name}")
            
            # æµ‹è¯•1ï¼šåŸºç¡€èŠå¤©
            print("\nğŸ“ æµ‹è¯•åŸºç¡€èŠå¤©åŠŸèƒ½...")
            start_time = time.time()
            
            response = api.openai_completion(
                messages=self.test_message,
                temperature=0.7,
                max_tokens=200
            )
            
            response_text = api.parse_response(response)
            test_result["response_time"] = time.time() - start_time
            test_result["basic_chat"]["success"] = True
            test_result["basic_chat"]["response"] = response_text[:200] + "..." if len(response_text) > 200 else response_text
            
            print(f"âœ… åŸºç¡€èŠå¤©æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ“„ å“åº”å†…å®¹ï¼š{test_result['basic_chat']['response']}")
            print(f"â±ï¸ å“åº”æ—¶é—´ï¼š{test_result['response_time']:.2f}ç§’")
            
        except Exception as e:
            test_result["basic_chat"]["error"] = str(e)
            print(f"âŒ åŸºç¡€èŠå¤©æµ‹è¯•å¤±è´¥ï¼š{e}")
        
        # æµ‹è¯•2ï¼šJSONå“åº”
        try:
            print("\nğŸ”„ æµ‹è¯•JSONå“åº”åŠŸèƒ½...")
            

            
            json_response = self.call_with_json_response(
                messages=self.json_test_message,
                temperature=0.3,
                max_tokens=300
            )
            
            test_result["json_response"]["success"] = True
            test_result["json_response"]["response"] = json_response
            
            print(f"âœ… JSONå“åº”æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ“„ JSONå†…å®¹ï¼š{json.dumps(json_response, ensure_ascii=False, indent=2)}")
            
        except Exception as e:
            test_result["json_response"]["error"] = str(e)
            print(f"âŒ JSONå“åº”æµ‹è¯•å¤±è´¥ï¼š{e}")
        
        # æµ‹è¯•3ï¼šæµå¼å“åº”
        try:
            print("\nğŸŒŠ æµ‹è¯•æµå¼å“åº”åŠŸèƒ½...")
            
            stream_response = api.openai_completion(
                messages=self.test_message,
                temperature=0.7,
                max_tokens=150,
                stream=True
            )
            
            collected_text = ""
            for chunk in api.parse_response(stream_response, stream=True):
                collected_text += chunk
                print(chunk, end="", flush=True)
            
            test_result["stream_response"]["success"] = True
            test_result["stream_response"]["response"] = collected_text[:200] + "..." if len(collected_text) > 200 else collected_text
            
            print(f"\nâœ… æµå¼å“åº”æµ‹è¯•æˆåŠŸ")
            
        except Exception as e:
            test_result["stream_response"]["error"] = str(e)
            print(f"âŒ æµå¼å“åº”æµ‹è¯•å¤±è´¥ï¼š{e}")
        
        return test_result
    

    def call_with_json_response(self, 
                               messages: List[Dict[str, str]], 
                               extract_json: bool = True,
                               expect_list: bool = False,
                               allow_dict_to_list: bool = True,
                               output_file_path: Optional[str] = None,
                               **kwargs) -> Union[Dict, List, str]:
        response = self.create_completion(messages, **kwargs)
        response_text = self.parse_response(response)
        print("------------ text ------------")
        print(response_text)
        print("--------------------------------")
        if extract_json:
            try:
                json_data = self.parse_and_save_json(
                    response_content=response_text,
                    output_file_path=output_file_path,
                    expect_list=expect_list,
                    allow_dict_to_list=allow_dict_to_list
                )
                print("--------enhanced json parsing------------")
                print(json_data)
                print("--------------------------------")
                return json_data
            except Exception as e:
                print(f"Enhanced JSON parsing failed: {e}")
                print("Falling back to basic extraction...")
                # Fallback to old method if enhanced parsing fails
                json_data = self.extract_json_from_response(response_text)
                print("--------fallback json extraction------------")
                print(json_data)
                print("--------------------------------")
                return json_data if json_data is not None else response_text
        else:
            return response_text

    
    def test_all_models(self):
        """æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        self.print_separator("å¼€å§‹æµ‹è¯•æ‰€æœ‰LLMæ¨¡å‹")
        
        model_name = LLMApi.GPT_OSS
        api = LLMApi(model_name)
        
        try:
            result = self.test_model(model_name)
            self.test_results[model_name] = result
        except Exception as e:
            print(f"âŒ æ¨¡å‹ {model_name} æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼š{e}")
            self.test_results[model_name] = {
                "model": model_name,
                "basic_chat": {"success": False, "error": str(e)},
                "json_response": {"success": False, "error": str(e)},
                "stream_response": {"success": False, "error": str(e)},
                "response_time": 0
            }


    def test_utility_functions(self):
        """æµ‹è¯•å·¥å…·å‡½æ•°"""
        self.print_separator("æµ‹è¯•å·¥å…·å‡½æ•°")
        
        api = LLMApi()
        
        # æµ‹è¯•æ¶ˆæ¯åˆ›å»º
        self.print_test_header("æ¶ˆæ¯åˆ›å»ºåŠŸèƒ½")
        try:
            message = api.create_message("user", "æµ‹è¯•æ¶ˆæ¯")
            print(f"âœ… åˆ›å»ºæ¶ˆæ¯æˆåŠŸï¼š{message}")
            
            messages = api.create_messages(
                ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"),
                ("user", "ä½ å¥½")
            )
            print(f"âœ… åˆ›å»ºæ¶ˆæ¯åˆ—è¡¨æˆåŠŸï¼š{messages}")
        except Exception as e:
            print(f"âŒ æ¶ˆæ¯åˆ›å»ºæµ‹è¯•å¤±è´¥ï¼š{e}")
        
        # æµ‹è¯•JSONå¤„ç†
        self.print_test_header("JSONå¤„ç†åŠŸèƒ½")
        try:
            test_json_text = '{"name": "æµ‹è¯•", "value": 123, "items": [1, 2, 3]}'
            json_data = api.parse_json_response(test_json_text)
            print(f"âœ… JSONè§£ææˆåŠŸï¼š{json_data}")
            
            element = api.get_json_element(json_data, "name")
            print(f"âœ… JSONå…ƒç´ è·å–æˆåŠŸï¼š{element}")
            
            array_element = api.get_json_element(json_data, "items.1")
            print(f"âœ… JSONæ•°ç»„å…ƒç´ è·å–æˆåŠŸï¼š{array_element}")
        except Exception as e:
            print(f"âŒ JSONå¤„ç†æµ‹è¯•å¤±è´¥ï¼š{e}")
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        self.print_separator("æµ‹è¯•æŠ¥å‘Š")
        
        total_models = len(self.test_results)
        successful_models = 0
        
        print(f"ğŸ“Š æµ‹è¯•ç»Ÿè®¡ï¼š")
        print(f"   æ€»æ¨¡å‹æ•°ï¼š{total_models}")
        
        for model_name, result in self.test_results.items():
            basic_success = result.get("basic_chat", {}).get("success", False)
            json_success = result.get("json_response", {}).get("success", False)
            stream_success = result.get("stream_response", {}).get("success", False)
            
            if basic_success:
                successful_models += 1
            
            print(f"\nğŸ” {model_name}:")
            print(f"   åŸºç¡€èŠå¤©ï¼š{'âœ…' if basic_success else 'âŒ'}")
            print(f"   JSONå“åº”ï¼š{'âœ…' if json_success else 'âŒ'}")
            print(f"   æµå¼å“åº”ï¼š{'âœ…' if stream_success else 'âŒ'}")
            print(f"   å“åº”æ—¶é—´ï¼š{result.get('response_time', 0):.2f}ç§’")
            
            if not basic_success:
                error = result.get("basic_chat", {}).get("error", "æœªçŸ¥é”™è¯¯")
                print(f"   é”™è¯¯ä¿¡æ¯ï¼š{error}")
        
        print(f"\nğŸ“ˆ æˆåŠŸç‡ï¼š{successful_models}/{total_models} ({successful_models/total_models*100:.1f}%)" if total_models > 0 else "")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        try:
            with open("llm_test_report.json", "w", encoding="utf-8") as f:
                json.dump(self.test_results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ è¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼šllm_test_report.json")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥ï¼š{e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ LLM API æµ‹è¯•ç¨‹åº")
    print("ğŸ“ æµ‹è¯•å†…å®¹ï¼šutility.llm_api.py ä¸­çš„æ‰€æœ‰æ¨¡å‹å’ŒåŠŸèƒ½")
    
    tester = LLMApiTester()
    
    try:
        # æµ‹è¯•æ‰€æœ‰æ¨¡å‹
        tester.test_all_models()
        
        # æµ‹è¯•å·¥å…·å‡½æ•°
        tester.test_utility_functions()
        
        # ç”ŸæˆæŠ¥å‘Š
        tester.generate_report()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")
    
    print("\nğŸ æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()
